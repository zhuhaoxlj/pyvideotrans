# LLMå­—å¹•ç¿»è¯‘åŠŸèƒ½
def openwin():
    import json
    from pathlib import Path

    from PySide6.QtCore import QThread, Signal, QUrl
    from PySide6.QtGui import QDesktopServices, QTextCursor
    from PySide6.QtWidgets import QFileDialog, QMessageBox

    from videotrans.configure import config
    from videotrans.util import tools
    
    RESULT_DIR = config.HOME_DIR + "/LLMTranslate"
    Path(RESULT_DIR).mkdir(exist_ok=True)

    class LLMTranslateThread(QThread):
        uito = Signal(str)

        def __init__(self, *, parent=None, srt_file=None, source_lang='auto', target_lang='en',
                     llm_provider='openai', llm_api_key='', llm_model='gpt-4o-mini', 
                     llm_base_url='', batch_size=10, proxy='', bilingual=False):
            super().__init__(parent=parent)
            self.srt_file = srt_file
            self.source_lang = source_lang
            self.target_lang = target_lang
            
            # LLM é…ç½®
            self.llm_provider = llm_provider
            self.llm_api_key = llm_api_key
            self.llm_model = llm_model
            self.llm_base_url = llm_base_url
            self.batch_size = batch_size
            self.proxy = proxy
            self.bilingual = bilingual  # æ˜¯å¦ç”ŸæˆåŒè¯­å­—å¹•
            
            bilingual_suffix = "_bilingual" if bilingual else ""
            self.result_file = RESULT_DIR + "/" + Path(srt_file).stem + f"_translated_{target_lang}{bilingual_suffix}.srt"
            self.stop_flag = False

        def post(self, type='logs', text=""):
            self.uito.emit(json.dumps({"type": type, "text": text}))
        
        def stop(self):
            self.stop_flag = True
        
        def run(self):
            try:
                self.post(type='logs', text='â³ å¼€å§‹ç¿»è¯‘...')
                
                # è¯»å–å­—å¹•æ–‡ä»¶
                self.post(type='logs', text=f'ğŸ“– è¯»å–å­—å¹•æ–‡ä»¶: {Path(self.srt_file).name}')
                subtitles = self.parse_srt(self.srt_file)
                
                if not subtitles:
                    self.post(type='error', text='âŒ å­—å¹•æ–‡ä»¶ä¸ºç©ºæˆ–æ ¼å¼ä¸æ­£ç¡®')
                    return
                
                self.post(type='set_source', text=Path(self.srt_file).read_text(encoding='utf-8'))
                self.post(type='clear_target')
                
                self.post(type='logs', text=f'ğŸ“ å…± {len(subtitles)} æ¡å­—å¹•å¾…ç¿»è¯‘')
                
                # åˆå§‹åŒ– LLM ç¿»è¯‘å™¨
                translator = self.init_translator()
                if not translator:
                    self.post(type='error', text='âŒ åˆå§‹åŒ–ç¿»è¯‘å™¨å¤±è´¥')
                    return
                
                # åˆ†æ‰¹ç¿»è¯‘
                translated_subtitles = []
                total_batches = (len(subtitles) + self.batch_size - 1) // self.batch_size
                
                for i in range(0, len(subtitles), self.batch_size):
                    if self.stop_flag:
                        self.post(type='logs', text='â¹ ç¿»è¯‘å·²åœæ­¢')
                        return
                    
                    batch = subtitles[i:i + self.batch_size]
                    batch_num = i // self.batch_size + 1
                    
                    self.post(type='logs', text=f'ğŸ”„ æ­£åœ¨ç¿»è¯‘ç¬¬ {batch_num}/{total_batches} æ‰¹...')
                    
                    # æå–æ–‡æœ¬è¿›è¡Œç¿»è¯‘
                    texts_to_translate = [sub['text'] for sub in batch]
                    
                    try:
                        translated_texts = self.translate_batch(translator, texts_to_translate)
                        
                        # æ›´æ–°å­—å¹•
                        for j, translated_text in enumerate(translated_texts):
                            if j < len(batch):
                                translated_sub = batch[j].copy()
                                original_text = translated_sub['text']
                                
                                # æ ¹æ®æ˜¯å¦åŒè¯­å­—å¹•æ¥å†³å®šæ–‡æœ¬æ ¼å¼
                                if self.bilingual:
                                    # åŒè¯­å­—å¹•ï¼šåŸæ–‡ + æ¢è¡Œ + è¯‘æ–‡
                                    translated_sub['text'] = f"{original_text}\n{translated_text}"
                                else:
                                    # å•è¯­å­—å¹•ï¼šåªä¿ç•™è¯‘æ–‡
                                    translated_sub['text'] = translated_text
                                
                                translated_subtitles.append(translated_sub)
                                
                                # å®æ—¶æ˜¾ç¤ºç¿»è¯‘ç»“æœ
                                self.post(type='subtitle', text=f"{translated_sub['index']}\n{translated_sub['time']}\n{translated_sub['text']}\n\n")
                        
                        progress = int((batch_num / total_batches) * 100)
                        self.post(type='logs', text=f'âœ… ç¬¬ {batch_num}/{total_batches} æ‰¹å®Œæˆ ({progress}%)')
                        
                    except Exception as e:
                        error_msg = f'âŒ ç¬¬ {batch_num} æ‰¹ç¿»è¯‘å¤±è´¥: {str(e)}'
                        self.post(type='logs', text=error_msg)
                        config.logger.error(error_msg)
                        # å¤±è´¥æ—¶ä¿ç•™åŸæ–‡
                        for sub in batch:
                            translated_subtitles.append(sub)
                
                if self.stop_flag:
                    self.post(type='logs', text='â¹ ç¿»è¯‘å·²åœæ­¢')
                    return
                
                # ä¿å­˜ç»“æœ
                self.post(type='logs', text=f'ğŸ’¾ ä¿å­˜ç¿»è¯‘ç»“æœ: {Path(self.result_file).name}')
                self.save_srt(translated_subtitles, self.result_file)
                
                self.post(type='succeed', text=f'âœ… ç¿»è¯‘å®Œæˆï¼ç»“æœå·²ä¿å­˜åˆ°: {self.result_file}')
                
            except Exception as e:
                error_msg = f'âŒ ç¿»è¯‘è¿‡ç¨‹å‡ºé”™: {str(e)}'
                self.post(type='error', text=error_msg)
                config.logger.error(error_msg, exc_info=True)
        
        def parse_srt(self, srt_file):
            """è§£æ SRT æ–‡ä»¶"""
            try:
                content = Path(srt_file).read_text(encoding='utf-8')
                subtitles = []
                
                # æŒ‰ç©ºè¡Œåˆ†å‰²
                blocks = content.strip().split('\n\n')
                
                for block in blocks:
                    lines = block.strip().split('\n')
                    if len(lines) >= 3:
                        try:
                            index = lines[0].strip()
                            time = lines[1].strip()
                            text = '\n'.join(lines[2:]).strip()
                            
                            subtitles.append({
                                'index': index,
                                'time': time,
                                'text': text
                            })
                        except Exception as e:
                            config.logger.warning(f'è§£æå­—å¹•å—å¤±è´¥: {block}, é”™è¯¯: {e}')
                            continue
                
                return subtitles
            except Exception as e:
                config.logger.error(f'è§£æ SRT æ–‡ä»¶å¤±è´¥: {e}', exc_info=True)
                return []
        
        def save_srt(self, subtitles, output_file):
            """ä¿å­˜ä¸º SRT æ–‡ä»¶"""
            try:
                with open(output_file, 'w', encoding='utf-8') as f:
                    for sub in subtitles:
                        f.write(f"{sub['index']}\n")
                        f.write(f"{sub['time']}\n")
                        f.write(f"{sub['text']}\n\n")
            except Exception as e:
                config.logger.error(f'ä¿å­˜ SRT æ–‡ä»¶å¤±è´¥: {e}', exc_info=True)
                raise
        
        def init_translator(self):
            """åˆå§‹åŒ–ç¿»è¯‘å™¨"""
            try:
                if self.llm_provider == 'openai':
                    return self.init_openai_translator()
                elif self.llm_provider in ['claude', 'anthropic']:
                    return self.init_claude_translator()
                elif self.llm_provider == 'gemini':
                    return self.init_gemini_translator()
                elif self.llm_provider == 'deepseek':
                    return self.init_deepseek_translator()
                elif self.llm_provider == 'siliconflow':
                    return self.init_siliconflow_translator()
                else:
                    self.post(type='error', text=f'âŒ ä¸æ”¯æŒçš„LLMæä¾›å•†: {self.llm_provider}')
                    return None
            except Exception as e:
                config.logger.error(f'åˆå§‹åŒ–ç¿»è¯‘å™¨å¤±è´¥: {e}', exc_info=True)
                return None
        
        def init_openai_translator(self):
            """åˆå§‹åŒ– OpenAI ç¿»è¯‘å™¨"""
            import httpx
            from openai import OpenAI
            
            api_url = self.llm_base_url if self.llm_base_url else "https://api.openai.com/v1"
            
            # è‡ªåŠ¨ä¿®æ­£ API åœ°å€ï¼šç§»é™¤æœ«å°¾çš„ /chat/completionsï¼ˆå¦‚æœæœ‰ï¼‰
            # å› ä¸º OpenAI SDK ä¼šè‡ªåŠ¨æ·»åŠ è¿™ä¸ªè·¯å¾„
            if api_url.endswith('/chat/completions'):
                api_url = api_url[:-len('/chat/completions')]
                config.logger.info(f'è‡ªåŠ¨ä¿®æ­£ API åœ°å€: {api_url}')
            
            proxy = self.proxy if self.proxy else None
            
            http_client = httpx.Client(proxy=proxy, timeout=300) if proxy else httpx.Client(timeout=300)
            
            client = OpenAI(
                api_key=self.llm_api_key,
                base_url=api_url,
                http_client=http_client
            )
            
            return {
                'type': 'openai',
                'client': client,
                'model': self.llm_model
            }
        
        def init_claude_translator(self):
            """åˆå§‹åŒ– Claude ç¿»è¯‘å™¨"""
            import anthropic
            
            client = anthropic.Anthropic(
                api_key=self.llm_api_key,
            )
            
            return {
                'type': 'claude',
                'client': client,
                'model': self.llm_model
            }
        
        def init_gemini_translator(self):
            """åˆå§‹åŒ– Gemini ç¿»è¯‘å™¨"""
            import google.generativeai as genai
            
            genai.configure(api_key=self.llm_api_key)
            model = genai.GenerativeModel(self.llm_model)
            
            return {
                'type': 'gemini',
                'model': model
            }
        
        def init_deepseek_translator(self):
            """åˆå§‹åŒ– DeepSeek ç¿»è¯‘å™¨"""
            import httpx
            from openai import OpenAI
            
            api_url = self.llm_base_url if self.llm_base_url else "https://api.deepseek.com/v1"
            
            # è‡ªåŠ¨ä¿®æ­£ API åœ°å€ï¼šç§»é™¤æœ«å°¾çš„ /chat/completionsï¼ˆå¦‚æœæœ‰ï¼‰
            # å› ä¸º OpenAI SDK ä¼šè‡ªåŠ¨æ·»åŠ è¿™ä¸ªè·¯å¾„
            if api_url.endswith('/chat/completions'):
                api_url = api_url[:-len('/chat/completions')]
                config.logger.info(f'è‡ªåŠ¨ä¿®æ­£ DeepSeek API åœ°å€: {api_url}')
            
            proxy = self.proxy if self.proxy else None
            
            http_client = httpx.Client(proxy=proxy, timeout=300) if proxy else httpx.Client(timeout=300)
            
            client = OpenAI(
                api_key=self.llm_api_key,
                base_url=api_url,
                http_client=http_client
            )
            
            return {
                'type': 'deepseek',
                'client': client,
                'model': self.llm_model
            }
        
        def init_siliconflow_translator(self):
            """åˆå§‹åŒ– SiliconFlow ç¿»è¯‘å™¨"""
            import httpx
            from openai import OpenAI
            
            api_url = self.llm_base_url if self.llm_base_url else "https://api.siliconflow.cn/v1"
            
            # è‡ªåŠ¨ä¿®æ­£ API åœ°å€ï¼šç§»é™¤æœ«å°¾çš„ /chat/completionsï¼ˆå¦‚æœæœ‰ï¼‰
            # å› ä¸º OpenAI SDK ä¼šè‡ªåŠ¨æ·»åŠ è¿™ä¸ªè·¯å¾„
            if api_url.endswith('/chat/completions'):
                api_url = api_url[:-len('/chat/completions')]
                config.logger.info(f'è‡ªåŠ¨ä¿®æ­£ SiliconFlow API åœ°å€: {api_url}')
            
            proxy = self.proxy if self.proxy else None
            
            http_client = httpx.Client(proxy=proxy, timeout=300) if proxy else httpx.Client(timeout=300)
            
            client = OpenAI(
                api_key=self.llm_api_key,
                base_url=api_url,
                http_client=http_client
            )
            
            return {
                'type': 'siliconflow',
                'client': client,
                'model': self.llm_model
            }
        
        def translate_batch(self, translator, texts):
            """æ‰¹é‡ç¿»è¯‘æ–‡æœ¬"""
            if translator['type'] in ['openai', 'deepseek', 'siliconflow']:
                return self.translate_with_openai(translator, texts)
            elif translator['type'] in ['claude', 'anthropic']:
                return self.translate_with_claude(translator, texts)
            elif translator['type'] == 'gemini':
                return self.translate_with_gemini(translator, texts)
            else:
                raise ValueError(f'ä¸æ”¯æŒçš„ç¿»è¯‘å™¨ç±»å‹: {translator["type"]}')
        
        def translate_with_openai(self, translator, texts):
            """ä½¿ç”¨ OpenAI API ç¿»è¯‘"""
            # æ„å»ºæç¤ºè¯
            source_lang_name = self.get_language_name(self.source_lang)
            target_lang_name = self.get_language_name(self.target_lang)
            
            prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å­—å¹•ç¿»è¯‘åŠ©æ‰‹ã€‚è¯·å°†ä»¥ä¸‹å­—å¹•ä»{source_lang_name}ç¿»è¯‘æˆ{target_lang_name}ã€‚

è¦æ±‚ï¼š
1. ä¿æŒåŸæœ‰çš„è¡Œæ•°å’Œæ ¼å¼
2. ç¿»è¯‘è¦å‡†ç¡®ã€æµç•…ã€è‡ªç„¶
3. ä¿ç•™ä¸“æœ‰åè¯çš„åŸæ–‡
4. æ¯è¡Œç¿»è¯‘ç»“æœç”¨æ¢è¡Œç¬¦åˆ†éš”
5. ä¸è¦æ·»åŠ ä»»ä½•åºå·ã€æ³¨é‡Šæˆ–é¢å¤–çš„è¯´æ˜

å¾…ç¿»è¯‘çš„å­—å¹•ï¼ˆæ¯è¡Œä¸€æ¡ï¼‰ï¼š
"""
            
            for i, text in enumerate(texts, 1):
                prompt += f"{text}\n"
            
            prompt += "\nè¯·ç›´æ¥è¾“å‡ºç¿»è¯‘ç»“æœï¼Œæ¯è¡Œå¯¹åº”ä¸€æ¡ç¿»è¯‘ï¼Œä¸è¦åŒ…å«ä»»ä½•å…¶ä»–å†…å®¹ï¼š"
            
            # è°ƒç”¨ API
            client = translator['client']
            model = translator['model']
            
            try:
                response = client.chat.completions.create(
                    model=model,
                    messages=[
                        {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å­—å¹•ç¿»è¯‘åŠ©æ‰‹ï¼Œæ“…é•¿å‡†ç¡®ã€æµç•…åœ°ç¿»è¯‘å­—å¹•ã€‚"},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=0.3,
                    max_tokens=4096
                )
                
                result = response.choices[0].message.content.strip()
                
                # è§£æç»“æœ
                translated_lines = result.split('\n')
                translated_lines = [line.strip() for line in translated_lines if line.strip()]
                
                # ç¡®ä¿ç»“æœè¡Œæ•°åŒ¹é…
                if len(translated_lines) < len(texts):
                    translated_lines += [''] * (len(texts) - len(translated_lines))
                elif len(translated_lines) > len(texts):
                    translated_lines = translated_lines[:len(texts)]
                
                return translated_lines
                
            except Exception as e:
                config.logger.error(f'OpenAI ç¿»è¯‘å¤±è´¥: {e}', exc_info=True)
                raise
        
        def translate_with_claude(self, translator, texts):
            """ä½¿ç”¨ Claude API ç¿»è¯‘"""
            source_lang_name = self.get_language_name(self.source_lang)
            target_lang_name = self.get_language_name(self.target_lang)
            
            prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å­—å¹•ç¿»è¯‘åŠ©æ‰‹ã€‚è¯·å°†ä»¥ä¸‹å­—å¹•ä»{source_lang_name}ç¿»è¯‘æˆ{target_lang_name}ã€‚

è¦æ±‚ï¼š
1. ä¿æŒåŸæœ‰çš„è¡Œæ•°å’Œæ ¼å¼
2. ç¿»è¯‘è¦å‡†ç¡®ã€æµç•…ã€è‡ªç„¶
3. ä¿ç•™ä¸“æœ‰åè¯çš„åŸæ–‡
4. æ¯è¡Œç¿»è¯‘ç»“æœç”¨æ¢è¡Œç¬¦åˆ†éš”
5. ä¸è¦æ·»åŠ ä»»ä½•åºå·ã€æ³¨é‡Šæˆ–é¢å¤–çš„è¯´æ˜

å¾…ç¿»è¯‘çš„å­—å¹•ï¼ˆæ¯è¡Œä¸€æ¡ï¼‰ï¼š
"""
            
            for i, text in enumerate(texts, 1):
                prompt += f"{text}\n"
            
            prompt += "\nè¯·ç›´æ¥è¾“å‡ºç¿»è¯‘ç»“æœï¼Œæ¯è¡Œå¯¹åº”ä¸€æ¡ç¿»è¯‘ï¼Œä¸è¦åŒ…å«ä»»ä½•å…¶ä»–å†…å®¹ï¼š"
            
            # è°ƒç”¨ API
            client = translator['client']
            model = translator['model']
            
            try:
                response = client.messages.create(
                    model=model,
                    max_tokens=4096,
                    messages=[
                        {"role": "user", "content": prompt}
                    ],
                    temperature=0.3
                )
                
                result = response.content[0].text.strip()
                
                # è§£æç»“æœ
                translated_lines = result.split('\n')
                translated_lines = [line.strip() for line in translated_lines if line.strip()]
                
                # ç¡®ä¿ç»“æœè¡Œæ•°åŒ¹é…
                if len(translated_lines) < len(texts):
                    translated_lines += [''] * (len(texts) - len(translated_lines))
                elif len(translated_lines) > len(texts):
                    translated_lines = translated_lines[:len(texts)]
                
                return translated_lines
                
            except Exception as e:
                config.logger.error(f'Claude ç¿»è¯‘å¤±è´¥: {e}', exc_info=True)
                raise
        
        def translate_with_gemini(self, translator, texts):
            """ä½¿ç”¨ Gemini API ç¿»è¯‘"""
            source_lang_name = self.get_language_name(self.source_lang)
            target_lang_name = self.get_language_name(self.target_lang)
            
            prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å­—å¹•ç¿»è¯‘åŠ©æ‰‹ã€‚è¯·å°†ä»¥ä¸‹å­—å¹•ä»{source_lang_name}ç¿»è¯‘æˆ{target_lang_name}ã€‚

è¦æ±‚ï¼š
1. ä¿æŒåŸæœ‰çš„è¡Œæ•°å’Œæ ¼å¼
2. ç¿»è¯‘è¦å‡†ç¡®ã€æµç•…ã€è‡ªç„¶
3. ä¿ç•™ä¸“æœ‰åè¯çš„åŸæ–‡
4. æ¯è¡Œç¿»è¯‘ç»“æœç”¨æ¢è¡Œç¬¦åˆ†éš”
5. ä¸è¦æ·»åŠ ä»»ä½•åºå·ã€æ³¨é‡Šæˆ–é¢å¤–çš„è¯´æ˜

å¾…ç¿»è¯‘çš„å­—å¹•ï¼ˆæ¯è¡Œä¸€æ¡ï¼‰ï¼š
"""
            
            for i, text in enumerate(texts, 1):
                prompt += f"{text}\n"
            
            prompt += "\nè¯·ç›´æ¥è¾“å‡ºç¿»è¯‘ç»“æœï¼Œæ¯è¡Œå¯¹åº”ä¸€æ¡ç¿»è¯‘ï¼Œä¸è¦åŒ…å«ä»»ä½•å…¶ä»–å†…å®¹ï¼š"
            
            # è°ƒç”¨ API
            model = translator['model']
            
            try:
                response = model.generate_content(prompt)
                result = response.text.strip()
                
                # è§£æç»“æœ
                translated_lines = result.split('\n')
                translated_lines = [line.strip() for line in translated_lines if line.strip()]
                
                # ç¡®ä¿ç»“æœè¡Œæ•°åŒ¹é…
                if len(translated_lines) < len(texts):
                    translated_lines += [''] * (len(texts) - len(translated_lines))
                elif len(translated_lines) > len(texts):
                    translated_lines = translated_lines[:len(texts)]
                
                return translated_lines
                
            except Exception as e:
                config.logger.error(f'Gemini ç¿»è¯‘å¤±è´¥: {e}', exc_info=True)
                raise
        
        def get_language_name(self, lang_code):
            """è·å–è¯­è¨€åç§°"""
            lang_map = {
                'auto': 'è‡ªåŠ¨æ£€æµ‹',
                'zh': 'ä¸­æ–‡',
                'en': 'è‹±è¯­',
                'ja': 'æ—¥è¯­',
                'ko': 'éŸ©è¯­',
                'fr': 'æ³•è¯­',
                'de': 'å¾·è¯­',
                'es': 'è¥¿ç­ç‰™è¯­',
                'it': 'æ„å¤§åˆ©è¯­',
                'pt': 'è‘¡è„ç‰™è¯­',
                'ru': 'ä¿„è¯­',
                'ar': 'é˜¿æ‹‰ä¼¯è¯­',
                'th': 'æ³°è¯­',
                'vi': 'è¶Šå—è¯­',
                'id': 'å°åº¦å°¼è¥¿äºšè¯­',
                'tr': 'åœŸè€³å…¶è¯­',
                'pl': 'æ³¢å…°è¯­',
                'nl': 'è·å…°è¯­',
            }
            return lang_map.get(lang_code, lang_code)

    def feed(d):
        if winobj.has_done:
            return
        d = json.loads(d)
        
        if d['type'] == 'error':
            winobj.has_done = True
            winobj.progress_label.setStyleSheet("QLabel { color: #f44336; font-weight: bold; padding: 5px; }")
            winobj.progress_label.setText(d['text'])
            winobj.start_btn.setDisabled(False)
            winobj.stop_btn.setDisabled(True)
            QMessageBox.critical(winobj, "é”™è¯¯" if config.defaulelang == 'zh' else "Error", d['text'])
        
        elif d['type'] == 'subtitle':
            # å®æ—¶æ˜¾ç¤ºç¿»è¯‘ç»“æœ
            winobj.target_text.moveCursor(QTextCursor.End)
            winobj.target_text.insertPlainText(d['text'])
        
        elif d['type'] == 'set_source':
            winobj.source_text.setPlainText(d['text'])
        
        elif d['type'] == 'clear_target':
            winobj.target_text.clear()
        
        elif d['type'] == 'succeed':
            winobj.has_done = True
            winobj.progress_label.setStyleSheet("QLabel { color: #4caf50; font-weight: bold; padding: 5px; }")
            winobj.progress_label.setText(d['text'])
            winobj.start_btn.setDisabled(False)
            winobj.stop_btn.setDisabled(True)
            QMessageBox.information(winobj, "æˆåŠŸ" if config.defaulelang == 'zh' else "Success", d['text'])
        
        elif d['type'] == 'logs':
            winobj.progress_label.setStyleSheet("QLabel { color: #2196f3; font-weight: bold; padding: 5px; }")
            winobj.progress_label.setText(d['text'])

    def select_file_fun():
        """é€‰æ‹©å­—å¹•æ–‡ä»¶"""
        fname, _ = QFileDialog.getOpenFileName(
            winobj,
            "é€‰æ‹©å­—å¹•æ–‡ä»¶" if config.defaulelang == 'zh' else "Select Subtitle File",
            config.params.get('last_opendir', ''),
            "Subtitle files (*.srt)"
        )
        
        if fname:
            winobj.selected_file = fname
            config.params['last_opendir'] = str(Path(fname).parent)
            winobj.selected_file_label.setText(f"å·²é€‰æ‹©: {Path(fname).name}")
            winobj.selected_file_label.setStyleSheet("QLabel { color: #4caf50; padding: 5px; }")
            
            # è¯»å–å¹¶æ˜¾ç¤ºåŸæ–‡
            try:
                content = Path(fname).read_text(encoding='utf-8')
                winobj.source_text.setPlainText(content)
            except Exception as e:
                QMessageBox.warning(winobj, "è­¦å‘Š" if config.defaulelang == 'zh' else "Warning", 
                                  f"è¯»å–æ–‡ä»¶å¤±è´¥: {str(e)}")

    def start_translate_fun():
        """å¼€å§‹ç¿»è¯‘"""
        # éªŒè¯è¾“å…¥
        if not hasattr(winobj, 'selected_file') or not winobj.selected_file:
            QMessageBox.warning(winobj, "è­¦å‘Š" if config.defaulelang == 'zh' else "Warning",
                              "è¯·å…ˆé€‰æ‹©å­—å¹•æ–‡ä»¶" if config.defaulelang == 'zh' else "Please select a subtitle file first")
            return
        
        api_key = winobj.api_key_input.text().strip()
        if not api_key:
            QMessageBox.warning(winobj, "è­¦å‘Š" if config.defaulelang == 'zh' else "Warning",
                              "è¯·è¾“å…¥ API Key" if config.defaulelang == 'zh' else "Please enter API Key")
            return
        
        target_lang = winobj.target_lang_combo.currentData()
        if not target_lang or target_lang == 'auto':
            QMessageBox.warning(winobj, "è­¦å‘Š" if config.defaulelang == 'zh' else "Warning",
                              "è¯·é€‰æ‹©ç›®æ ‡è¯­è¨€" if config.defaulelang == 'zh' else "Please select target language")
            return
        
        # æ¸…ç©ºç»“æœ
        winobj.target_text.clear()
        winobj.has_done = False
        
        # è·å–åŒè¯­å­—å¹•é€‰é¡¹
        bilingual = winobj.bilingual_checkbox.isChecked()
        
        # åˆ›å»ºç¿»è¯‘çº¿ç¨‹
        winobj.translate_thread = LLMTranslateThread(
            parent=winobj,
            srt_file=winobj.selected_file,
            source_lang=winobj.source_lang_combo.currentData(),
            target_lang=target_lang,
            llm_provider=winobj.provider_combo.currentData(),
            llm_api_key=api_key,
            llm_model=winobj.model_combo.currentText(),
            llm_base_url=winobj.base_url_input.text().strip(),
            batch_size=winobj.batch_size_spin.value(),
            proxy=winobj.proxy_input.text().strip(),
            bilingual=bilingual
        )
        
        winobj.translate_thread.uito.connect(feed)
        winobj.translate_thread.start()
        
        winobj.start_btn.setDisabled(True)
        winobj.stop_btn.setDisabled(False)
        winobj.progress_label.setText("ç¿»è¯‘ä¸­..." if config.defaulelang == 'zh' else "Translating...")

    def stop_translate_fun():
        """åœæ­¢ç¿»è¯‘"""
        if hasattr(winobj, 'translate_thread') and winobj.translate_thread.isRunning():
            winobj.translate_thread.stop()
            winobj.start_btn.setDisabled(False)
            winobj.stop_btn.setDisabled(True)

    def open_result_fun():
        """æ‰“å¼€ç»“æœæ–‡ä»¶å¤¹"""
        QDesktopServices.openUrl(QUrl.fromLocalFile(RESULT_DIR))

    def save_api_key_to_env():
        """ä¿å­˜ API Key åˆ° .env æ–‡ä»¶ï¼Œå¹¶ä¿å­˜é…ç½®åˆ° config.params"""
        import os
        provider = winobj.provider_combo.currentData()
        api_key = winobj.api_key_input.text().strip()
        if not api_key:
            return
        
        env_file = os.path.join(config.ROOT_DIR, '.env')
        
        # æ ¹æ®æä¾›å•†ç¡®å®šç¯å¢ƒå˜é‡åç§°
        env_key_map = {
            'openai': 'OPENAI_API_KEY',
            'anthropic': 'ANTHROPIC_API_KEY',
            'gemini': 'GEMINI_API_KEY',
            'deepseek': 'DEEPSEEK_API_KEY',
            'siliconflow': 'SILICONFLOW_API_KEY',
        }
        env_key_name = env_key_map.get(provider, 'LLM_API_KEY')
        
        # è¯»å–ç°æœ‰çš„ .env æ–‡ä»¶å†…å®¹
        lines = []
        key_exists = False
        
        if os.path.exists(env_file):
            try:
                with open(env_file, 'r', encoding='utf-8') as f:
                    lines = f.readlines()
                
                # æŸ¥æ‰¾å¹¶æ›´æ–°å¯¹åº”çš„ API Key
                for i, line in enumerate(lines):
                    if line.strip().startswith(f'{env_key_name}='):
                        lines[i] = f'{env_key_name}={api_key}\n'
                        key_exists = True
                        break
            except Exception as e:
                config.logger.warning(f"è¯»å– .env æ–‡ä»¶å¤±è´¥: {e}")
        
        # å¦‚æœ key ä¸å­˜åœ¨ï¼Œæ·»åŠ åˆ°æ–‡ä»¶æœ«å°¾
        if not key_exists:
            if lines and not lines[-1].endswith('\n'):
                lines.append('\n')
            lines.append(f'{env_key_name}={api_key}\n')
        
        # å†™å›æ–‡ä»¶
        try:
            with open(env_file, 'w', encoding='utf-8') as f:
                f.writelines(lines)
            config.logger.info(f"API Key å·²ä¿å­˜åˆ° {env_file}")
        except Exception as e:
            config.logger.error(f"ä¿å­˜ API Key å¤±è´¥: {e}")
    
    def save_llm_config():
        """ä¿å­˜ LLM é…ç½®åˆ° config.paramsï¼Œä¸æ™ºèƒ½åˆ†å‰²å­—å¹•å…±äº«"""
        provider = winobj.provider_combo.currentData()
        model = winobj.model_combo.currentText()
        base_url = winobj.base_url_input.text().strip()
        
        # ä¿å­˜åˆ° config.paramsï¼Œä¸æ™ºèƒ½åˆ†å‰²å­—å¹•å…±äº«
        config.params['llm_provider'] = provider
        config.params['llm_model'] = model
        config.params['llm_base_url'] = base_url
        config.getset_params(config.params)
    
    def save_bilingual_config():
        """ä¿å­˜åŒè¯­å­—å¹•é…ç½®"""
        config.params['llm_translate_bilingual'] = winobj.bilingual_checkbox.isChecked()
        config.getset_params(config.params)
    
    def load_api_key_from_env():
        """ä» .env æ–‡ä»¶åŠ è½½ API Key"""
        import os
        provider = winobj.provider_combo.currentData()
        
        # æ ¹æ®æä¾›å•†ç¡®å®šç¯å¢ƒå˜é‡åç§°
        env_key_map = {
            'openai': 'OPENAI_API_KEY',
            'anthropic': 'ANTHROPIC_API_KEY',
            'gemini': 'GEMINI_API_KEY',
            'deepseek': 'DEEPSEEK_API_KEY',
            'siliconflow': 'SILICONFLOW_API_KEY',
        }
        env_key_name = env_key_map.get(provider, 'LLM_API_KEY')
        
        api_key = ""
        # é¦–å…ˆå°è¯•ä»ç¯å¢ƒå˜é‡è¯»å–
        api_key = os.environ.get(env_key_name, '')
        
        # å¦‚æœç¯å¢ƒå˜é‡æ²¡æœ‰ï¼Œå°è¯•ä» .env æ–‡ä»¶è¯»å–
        if not api_key:
            env_file = os.path.join(config.ROOT_DIR, '.env')
            if os.path.exists(env_file):
                try:
                    with open(env_file, 'r', encoding='utf-8') as f:
                        for line in f:
                            line = line.strip()
                            if line and not line.startswith('#'):
                                if '=' in line:
                                    key, value = line.split('=', 1)
                                    key = key.strip()
                                    value = value.strip().strip('"').strip("'")
                                    if key == env_key_name:
                                        api_key = value
                                        break
                except Exception as e:
                    config.logger.warning(f"è¯»å– .env æ–‡ä»¶å¤±è´¥: {e}")
        
        # è®¾ç½®åˆ°è¾“å…¥æ¡†
        if api_key:
            winobj.api_key_input.setText(api_key)
    
    class TestLLMThread(QThread):
        """å¼‚æ­¥æµ‹è¯•LLMè¿æ¥çš„çº¿ç¨‹"""
        finished = Signal(str, bool)  # ä¿¡å·ï¼š(æ¶ˆæ¯, æ˜¯å¦æˆåŠŸ)
        progress = Signal(str)  # è¿›åº¦ä¿¡å·
        
        def __init__(self, provider, api_key, model, base_url):
            super().__init__()
            self.provider = provider
            self.api_key = api_key
            self.model = model
            self.base_url = base_url
        
        def run(self):
            try:
                import requests
                
                # å‘é€è¿›åº¦æ›´æ–°
                self.progress.emit('â³ æ­£åœ¨æ„å»ºæµ‹è¯•è¯·æ±‚...' if config.defaulelang == 'zh' else 'â³ Building test request...')
                
                # æ„å»ºæµ‹è¯•è¯·æ±‚
                test_prompt = "è¯·å›å¤'OK'ï¼Œè¿™æ˜¯ä¸€ä¸ªè¿æ¥æµ‹è¯•ã€‚" if config.defaulelang == 'zh' else "Reply 'OK', this is a connection test."
                
                if self.provider == 'openai':
                    url = self.base_url if self.base_url else 'https://api.openai.com/v1/chat/completions'
                    headers = {
                        'Authorization': f'Bearer {self.api_key}',
                        'Content-Type': 'application/json'
                    }
                    data = {
                        'model': self.model,
                        'messages': [{'role': 'user', 'content': test_prompt}],
                        'max_tokens': 10
                    }
                
                elif self.provider == 'anthropic':
                    url = 'https://api.anthropic.com/v1/messages'
                    headers = {
                        'x-api-key': self.api_key,
                        'Content-Type': 'application/json',
                        'anthropic-version': '2023-06-01'
                    }
                    data = {
                        'model': self.model,
                        'messages': [{'role': 'user', 'content': test_prompt}],
                        'max_tokens': 10
                    }
                
                elif self.provider == 'deepseek':
                    url = 'https://api.deepseek.com/v1/chat/completions'
                    headers = {
                        'Authorization': f'Bearer {self.api_key}',
                        'Content-Type': 'application/json'
                    }
                    data = {
                        'model': self.model,
                        'messages': [{'role': 'user', 'content': test_prompt}],
                        'max_tokens': 10
                    }
                
                elif self.provider == 'siliconflow':
                    url = self.base_url if self.base_url else 'https://api.siliconflow.cn/v1/chat/completions'
                    headers = {
                        'Authorization': f'Bearer {self.api_key}',
                        'Content-Type': 'application/json'
                    }
                    data = {
                        'model': self.model,
                        'messages': [{'role': 'user', 'content': test_prompt}],
                        'max_tokens': 10
                    }
                
                else:
                    self.finished.emit(f'âŒ ä¸æ”¯æŒçš„æä¾›å•†: {self.provider}', False)
                    return
                
                # å‘é€è¿›åº¦æ›´æ–°
                self.progress.emit(f'ğŸŒ æ­£åœ¨è¿æ¥åˆ° {self.provider} API...' if config.defaulelang == 'zh' else f'ğŸŒ Connecting to {self.provider} API...')
                
                # å‘é€è¯·æ±‚
                response = requests.post(url, headers=headers, json=data, timeout=30)
                
                # æ£€æŸ¥å“åº”
                if response.status_code == 200:
                    result = response.json()
                    # éªŒè¯å“åº”æ ¼å¼
                    if self.provider in ['openai', 'deepseek', 'siliconflow']:
                        if 'choices' in result and len(result['choices']) > 0:
                            success_msg = f'âœ… è¿æ¥æˆåŠŸï¼æä¾›å•†: {self.provider} | æ¨¡å‹: {self.model} | å“åº”æ­£å¸¸' if config.defaulelang == 'zh' else f'âœ… Connection Successful! Provider: {self.provider} | Model: {self.model} | Response OK'
                            self.finished.emit(success_msg, True)
                        else:
                            self.finished.emit('å“åº”æ ¼å¼ä¸æ­£ç¡®' if config.defaulelang == 'zh' else 'Invalid response format', False)
                    
                    elif self.provider in ['anthropic', 'claude']:
                        if 'content' in result:
                            success_msg = f'âœ… è¿æ¥æˆåŠŸï¼æä¾›å•†: {self.provider} | æ¨¡å‹: {self.model} | å“åº”æ­£å¸¸' if config.defaulelang == 'zh' else f'âœ… Connection Successful! Provider: {self.provider} | Model: {self.model} | Response OK'
                            self.finished.emit(success_msg, True)
                        else:
                            self.finished.emit('å“åº”æ ¼å¼ä¸æ­£ç¡®' if config.defaulelang == 'zh' else 'Invalid response format', False)
                    
                    elif self.provider == 'gemini':
                        # Gemini çš„å“åº”æ ¼å¼ä¸åŒï¼Œä½†200çŠ¶æ€ç è¡¨ç¤ºæˆåŠŸ
                        success_msg = f'âœ… è¿æ¥æˆåŠŸï¼æä¾›å•†: {self.provider} | æ¨¡å‹: {self.model} | å“åº”æ­£å¸¸' if config.defaulelang == 'zh' else f'âœ… Connection Successful! Provider: {self.provider} | Model: {self.model} | Response OK'
                        self.finished.emit(success_msg, True)
                else:
                    error_msg = f'âŒ è¿æ¥å¤±è´¥ï¼HTTP {response.status_code}: {response.text[:200]}' if config.defaulelang == 'zh' else f'âŒ Connection Failed! HTTP {response.status_code}: {response.text[:200]}'
                    self.finished.emit(error_msg, False)
            
            except requests.exceptions.Timeout:
                self.finished.emit(
                    'âŒ è¿æ¥è¶…æ—¶ï¼è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥' if config.defaulelang == 'zh' else 'âŒ Connection Timeout! Please check network connection',
                    False
                )
            
            except requests.exceptions.ConnectionError:
                self.finished.emit(
                    'âŒ æ— æ³•è¿æ¥åˆ°æœåŠ¡å™¨ï¼è¯·æ£€æŸ¥ç½‘ç»œæˆ– Base URL' if config.defaulelang == 'zh' else 'âŒ Cannot connect to server! Please check network or Base URL',
                    False
                )
            
            except Exception as e:
                error_msg = f'âŒ æµ‹è¯•å¤±è´¥ï¼{str(e)}' if config.defaulelang == 'zh' else f'âŒ Test Failed! {str(e)}'
                self.finished.emit(error_msg, False)
    
    def test_llm_connection():
        """æµ‹è¯• LLM è¿æ¥æ˜¯å¦æ­£å¸¸ï¼ˆå¼‚æ­¥ï¼‰"""
        # è·å–é…ç½®
        provider = winobj.provider_combo.currentData()
        api_key = winobj.api_key_input.text()
        model = winobj.model_combo.currentText()
        base_url = winobj.base_url_input.text()
        
        # éªŒè¯å¿…å¡«é¡¹
        if not api_key:
            msg = 'âŒ è¯·è¾“å…¥ API Key' if config.defaulelang == 'zh' else 'âŒ Please enter API Key'
            winobj.progress_label.setText(msg)
            winobj.progress_label.setStyleSheet("QLabel { color: #f44336; font-weight: bold; padding: 5px; }")
            return
        
        if not model:
            msg = 'âŒ è¯·é€‰æ‹©æ¨¡å‹' if config.defaulelang == 'zh' else 'âŒ Please select model'
            winobj.progress_label.setText(msg)
            winobj.progress_label.setStyleSheet("QLabel { color: #f44336; font-weight: bold; padding: 5px; }")
            return
        
        # ç¦ç”¨æŒ‰é’®
        winobj.test_btn.setDisabled(True)
        winobj.test_btn.setText('â³ æµ‹è¯•ä¸­' if config.defaulelang == 'zh' else 'â³ Testing')
        
        # åˆ›å»ºå¹¶å¯åŠ¨æµ‹è¯•çº¿ç¨‹
        test_thread = TestLLMThread(provider, api_key, model, base_url)
        
        def on_test_progress(message):
            """è¿›åº¦æ›´æ–°çš„å›è°ƒ"""
            winobj.progress_label.setText(message)
            winobj.progress_label.setStyleSheet("QLabel { color: #2196f3; font-weight: bold; padding: 5px; }")
        
        def on_test_finished(message, success):
            """æµ‹è¯•å®Œæˆçš„å›è°ƒ"""
            winobj.progress_label.setText(message)
            if success:
                winobj.progress_label.setStyleSheet("QLabel { color: #4caf50; font-weight: bold; padding: 5px; }")
            else:
                winobj.progress_label.setStyleSheet("QLabel { color: #f44336; font-weight: bold; padding: 5px; }")
            
            # æ¢å¤æŒ‰é’®çŠ¶æ€
            winobj.test_btn.setDisabled(False)
            winobj.test_btn.setText('ğŸ” æµ‹è¯•è¿æ¥' if config.defaulelang == 'zh' else 'ğŸ” Test Connection')
        
        test_thread.progress.connect(on_test_progress)
        test_thread.finished.connect(on_test_finished)
        test_thread.start()
        
        # ä¿å­˜çº¿ç¨‹å¼•ç”¨ï¼Œé¿å…è¢«åƒåœ¾å›æ”¶
        winobj._test_thread = test_thread
    
    def provider_changed(index):
        """LLMæä¾›å•†æ”¹å˜æ—¶æ›´æ–°æ¨¡å‹åˆ—è¡¨å’Œé…ç½®"""
        provider = winobj.provider_combo.currentData()
        winobj.model_combo.clear()
        
        if provider == 'openai':
            models = ['gpt-4o', 'gpt-4o-mini', 'gpt-4-turbo', 'gpt-3.5-turbo']
            winobj.base_url_input.setPlaceholderText("https://api.openai.com/v1")
            winobj.base_url_input.setText("")
        elif provider == 'anthropic':
            models = ['claude-3-5-sonnet-20241022', 'claude-3-opus-20240229', 'claude-3-sonnet-20240229', 'claude-3-haiku-20240307']
            winobj.base_url_input.setPlaceholderText("ç•™ç©ºä½¿ç”¨é»˜è®¤åœ°å€" if config.defaulelang == 'zh' else "Leave blank for default")
            winobj.base_url_input.setText("")
        elif provider == 'gemini':
            models = ['gemini-2.0-flash-exp', 'gemini-1.5-pro', 'gemini-1.5-flash']
            winobj.base_url_input.setPlaceholderText("ç•™ç©ºä½¿ç”¨é»˜è®¤åœ°å€" if config.defaulelang == 'zh' else "Leave blank for default")
            winobj.base_url_input.setText("")
        elif provider == 'deepseek':
            models = ['deepseek-chat', 'deepseek-coder']
            winobj.base_url_input.setPlaceholderText("https://api.deepseek.com/v1")
            winobj.base_url_input.setText("")
        elif provider == 'siliconflow':
            models = ['deepseek-ai/DeepSeek-V3.1-Terminus', 'Qwen/Qwen2.5-72B-Instruct', 'Qwen/Qwen2.5-7B-Instruct']
            winobj.base_url_input.setPlaceholderText("https://api.siliconflow.cn/v1")
            winobj.base_url_input.setText("https://api.siliconflow.cn/v1/chat/completions")
        else:
            models = []
        
        winobj.model_combo.addItems(models)
        if models:
            winobj.model_combo.setCurrentIndex(0)
        
        # åŠ è½½å¯¹åº”æä¾›å•†çš„ API Key
        load_api_key_from_env()
        
        # ä¿å­˜é…ç½®
        save_llm_config()

    from videotrans.component import LLMTranslateForm
    try:
        winobj = config.child_forms.get('llmtransform')

        if winobj is not None:
            winobj.show()
            winobj.raise_()
            winobj.activateWindow()
            return

        winobj = LLMTranslateForm()
        config.child_forms['llmtransform'] = winobj
        
        # åˆå§‹åŒ– LLM æä¾›å•†
        providers = [
            ('OpenAI', 'openai'),
            ('Claude/Anthropic', 'anthropic'),
            ('Gemini', 'gemini'),
            ('DeepSeek', 'deepseek'),
            ('SiliconFlow', 'siliconflow'),
        ]
        
        for name, value in providers:
            winobj.provider_combo.addItem(name, value)
        
        # ä» config.params åŠ è½½ä¿å­˜çš„é…ç½®
        saved_provider = config.params.get('llm_provider', 'openai')
        for i in range(winobj.provider_combo.count()):
            if winobj.provider_combo.itemData(i) == saved_provider:
                winobj.provider_combo.setCurrentIndex(i)
                break
        
        # åˆå§‹åŒ–è¯­è¨€åˆ—è¡¨
        languages = [
            ('è‡ªåŠ¨æ£€æµ‹' if config.defaulelang == 'zh' else 'Auto', 'auto'),
            ('ä¸­æ–‡', 'zh'),
            ('è‹±è¯­', 'en'),
            ('æ—¥è¯­', 'ja'),
            ('éŸ©è¯­', 'ko'),
            ('æ³•è¯­', 'fr'),
            ('å¾·è¯­', 'de'),
            ('è¥¿ç­ç‰™è¯­', 'es'),
            ('æ„å¤§åˆ©è¯­', 'it'),
            ('è‘¡è„ç‰™è¯­', 'pt'),
            ('ä¿„è¯­', 'ru'),
            ('é˜¿æ‹‰ä¼¯è¯­', 'ar'),
            ('æ³°è¯­', 'th'),
            ('è¶Šå—è¯­', 'vi'),
        ]
        
        for name, value in languages:
            winobj.source_lang_combo.addItem(name, value)
            if value != 'auto':  # ç›®æ ‡è¯­è¨€ä¸èƒ½æ˜¯è‡ªåŠ¨æ£€æµ‹
                winobj.target_lang_combo.addItem(name, value)
        
        # è®¾ç½®é»˜è®¤å€¼
        winobj.source_lang_combo.setCurrentIndex(0)  # è‡ªåŠ¨æ£€æµ‹
        winobj.target_lang_combo.setCurrentIndex(0)  # é»˜è®¤ä¸­æ–‡
        
        # åŠ è½½åŒè¯­å­—å¹•é€‰é¡¹
        bilingual_enabled = config.params.get('llm_translate_bilingual', False)
        winobj.bilingual_checkbox.setChecked(bilingual_enabled)
        
        # è®¾ç½®ä»£ç†
        if config.proxy:
            winobj.proxy_input.setText(config.proxy)
        
        # è¿æ¥ä¿¡å·
        winobj.select_file_btn.clicked.connect(select_file_fun)
        winobj.start_btn.clicked.connect(start_translate_fun)
        winobj.stop_btn.clicked.connect(stop_translate_fun)
        winobj.open_result_btn.clicked.connect(open_result_fun)
        winobj.provider_combo.currentIndexChanged.connect(provider_changed)
        winobj.test_btn.clicked.connect(test_llm_connection)
        
        # ç›‘å¬ API Key è¾“å…¥å˜åŒ–ï¼Œè‡ªåŠ¨ä¿å­˜åˆ° .env æ–‡ä»¶
        winobj.api_key_input.textChanged.connect(save_api_key_to_env)
        
        # ç›‘å¬æ¨¡å‹å’Œ Base URL å˜åŒ–ï¼Œä¿å­˜é…ç½®
        winobj.model_combo.currentTextChanged.connect(save_llm_config)
        winobj.base_url_input.textChanged.connect(save_llm_config)
        
        # ç›‘å¬åŒè¯­å­—å¹•é€‰é¡¹å˜åŒ–ï¼Œä¿å­˜é…ç½®
        winobj.bilingual_checkbox.stateChanged.connect(save_bilingual_config)
        
        # è§¦å‘ä¸€æ¬¡ä»¥åˆå§‹åŒ–æ¨¡å‹åˆ—è¡¨å’ŒåŠ è½½ä¿å­˜çš„é…ç½®
        provider_changed(winobj.provider_combo.currentIndex())
        
        # åŠ è½½ä¿å­˜çš„æ¨¡å‹å’Œ Base URL
        saved_model = config.params.get('llm_model', '')
        if saved_model:
            # å¦‚æœæ¨¡å‹ä¸åœ¨åˆ—è¡¨ä¸­ï¼Œæ·»åŠ è¿›å»
            if winobj.model_combo.findText(saved_model) == -1:
                winobj.model_combo.addItem(saved_model)
            winobj.model_combo.setCurrentText(saved_model)
        
        saved_base_url = config.params.get('llm_base_url', '')
        if saved_base_url:
            winobj.base_url_input.setText(saved_base_url)
        
        winobj.selected_file = None
        winobj.show()
        
    except Exception as e:
        print(f"Error opening LLM translate window: {e}")
        import traceback
        traceback.print_exc()

