"""
ä½¿ç”¨ Whisper AI é‡æ–°ç”Ÿæˆç²¾ç¡®çš„å­—å¹•
è‡ªåŠ¨è¯†åˆ«è¯­éŸ³å¹¶ç”Ÿæˆå‡†ç¡®çš„æ—¶é—´å¯¹é½å­—å¹•
"""

import sys
import os
from pathlib import Path


def regenerate_subtitles_with_whisper(video_file, language='en', model_size='base'):
    """
    ä½¿ç”¨ Whisper é‡æ–°ç”Ÿæˆå­—å¹•
    
    Args:
        video_file: è§†é¢‘æ–‡ä»¶è·¯å¾„
        language: è¯­è¨€ä»£ç  (en, zh, ja, etc.)
        model_size: æ¨¡å‹å¤§å° (tiny, base, small, medium, large)
    
    Returns:
        ç”Ÿæˆçš„SRTæ–‡ä»¶è·¯å¾„
    """
    try:
        import whisper
    except ImportError:
        print("âŒ æœªå®‰è£… Whisperï¼Œæ­£åœ¨å®‰è£…...")
        print("è¯·è¿è¡Œ: pip install openai-whisper")
        sys.exit(1)
    
    print(f"ğŸ“¥ åŠ è½½ Whisper æ¨¡å‹: {model_size}")
    model = whisper.load_model(model_size)
    
    print(f"ğŸ¤ å¼€å§‹è¯†åˆ«è¯­éŸ³: {video_file}")
    result = model.transcribe(
        video_file,
        language=language,
        word_timestamps=True,  # è·å–å•è¯çº§åˆ«çš„æ—¶é—´æˆ³
        verbose=True
    )
    
    # ç”Ÿæˆ SRT æ–‡ä»¶
    video_path = Path(video_file)
    output_file = video_path.parent / f"{video_path.stem}_whisper.srt"
    
    print(f"ğŸ’¾ ä¿å­˜å­—å¹•åˆ°: {output_file}")
    
    with open(output_file, 'w', encoding='utf-8') as f:
        for i, segment in enumerate(result['segments'], 1):
            start = format_timestamp(segment['start'])
            end = format_timestamp(segment['end'])
            text = segment['text'].strip()
            
            f.write(f"{i}\n")
            f.write(f"{start} --> {end}\n")
            f.write(f"{text}\n")
            f.write("\n")
    
    print(f"âœ… å®Œæˆï¼å…±ç”Ÿæˆ {len(result['segments'])} æ¡å­—å¹•")
    return str(output_file)


def format_timestamp(seconds):
    """å°†ç§’è½¬æ¢ä¸º SRT æ—¶é—´æ ¼å¼"""
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = int(seconds % 60)
    milliseconds = int((seconds % 1) * 1000)
    return f"{hours:02d}:{minutes:02d}:{secs:02d},{milliseconds:03d}"


def main():
    if len(sys.argv) < 2:
        print("=" * 70)
        print("ğŸ¬ Whisper AI å­—å¹•ç”Ÿæˆå™¨")
        print("=" * 70)
        print("\nç”¨æ³•:")
        print("  python regenerate_subtitles.py <è§†é¢‘æ–‡ä»¶> [è¯­è¨€] [æ¨¡å‹å¤§å°]")
        print("\nå‚æ•°:")
        print("  è§†é¢‘æ–‡ä»¶    - è§†é¢‘æ–‡ä»¶è·¯å¾„ (å¿…éœ€)")
        print("  è¯­è¨€       - è¯­è¨€ä»£ç ï¼Œé»˜è®¤: en")
        print("              en=è‹±è¯­, zh=ä¸­æ–‡, ja=æ—¥è¯­, es=è¥¿ç­ç‰™è¯­, etc.")
        print("  æ¨¡å‹å¤§å°    - æ¨¡å‹å¤§å°ï¼Œé»˜è®¤: base")
        print("              tiny   - æœ€å¿«ï¼Œå‡†ç¡®åº¦ä½")
        print("              base   - å¿«é€Ÿï¼Œå‡†ç¡®åº¦ä¸­ç­‰ (æ¨è)")
        print("              small  - è¾ƒæ…¢ï¼Œå‡†ç¡®åº¦è¾ƒé«˜")
        print("              medium - æ…¢ï¼Œå‡†ç¡®åº¦é«˜")
        print("              large  - æœ€æ…¢ï¼Œå‡†ç¡®åº¦æœ€é«˜")
        print("\nç¤ºä¾‹:")
        print("  python regenerate_subtitles.py video.mp4")
        print("  python regenerate_subtitles.py video.mp4 en base")
        print("  python regenerate_subtitles.py video.mp4 zh small")
        print("=" * 70)
        sys.exit(1)
    
    video_file = sys.argv[1]
    language = sys.argv[2] if len(sys.argv) > 2 else 'en'
    model_size = sys.argv[3] if len(sys.argv) > 3 else 'base'
    
    if not Path(video_file).exists():
        print(f"âŒ é”™è¯¯: æ–‡ä»¶ä¸å­˜åœ¨: {video_file}")
        sys.exit(1)
    
    print("\n" + "=" * 70)
    print("ğŸ¬ Whisper AI å­—å¹•ç”Ÿæˆå™¨")
    print("=" * 70)
    print(f"è§†é¢‘æ–‡ä»¶: {video_file}")
    print(f"è¯­è¨€: {language}")
    print(f"æ¨¡å‹: {model_size}")
    print("=" * 70 + "\n")
    
    output_file = regenerate_subtitles_with_whisper(video_file, language, model_size)
    
    print("\n" + "=" * 70)
    print("âœ… å­—å¹•ç”Ÿæˆå®Œæˆï¼")
    print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶: {output_file}")
    print("=" * 70)


if __name__ == "__main__":
    main()

