#!/usr/bin/env python3
"""
æµ‹è¯• faster-whisper å‡çº§
éªŒè¯è¯çº§æ—¶é—´æˆ³å’Œç¼“å­˜åŠŸèƒ½
"""

import sys
from pathlib import Path

def test_imports():
    """æµ‹è¯•å¿…éœ€çš„åº“å¯¼å…¥"""
    print("=" * 60)
    print("æµ‹è¯• 1: æ£€æŸ¥ä¾èµ–å¯¼å…¥")
    print("=" * 60)
    
    try:
        from PySide6.QtCore import QObject, Signal
        print("âœ… PySide6 å¯¼å…¥æˆåŠŸ")
    except ImportError as e:
        print(f"âŒ PySide6 å¯¼å…¥å¤±è´¥: {e}")
        return False
    
    try:
        from faster_whisper import WhisperModel
        print("âœ… faster-whisper å¯¼å…¥æˆåŠŸ")
    except ImportError as e:
        print(f"âŒ faster-whisper å¯¼å…¥å¤±è´¥: {e}")
        print("   è¯·è¿è¡Œ: pip install faster-whisper")
        return False
    
    try:
        from pydub import AudioSegment
        print("âœ… pydub å¯¼å…¥æˆåŠŸ")
    except ImportError as e:
        print(f"âŒ pydub å¯¼å…¥å¤±è´¥: {e}")
        print("   è¯·è¿è¡Œ: pip install pydub")
        return False
    
    try:
        import requests
        print("âœ… requests å¯¼å…¥æˆåŠŸ")
    except ImportError as e:
        print(f"âŒ requests å¯¼å…¥å¤±è´¥: {e}")
        print("   è¯·è¿è¡Œ: pip install requests")
        return False
    
    print("\nâœ… æ‰€æœ‰ä¾èµ–å¯¼å…¥æˆåŠŸï¼\n")
    return True


def test_processor_import():
    """æµ‹è¯• WhisperProcessor å¯¼å…¥"""
    print("=" * 60)
    print("æµ‹è¯• 2: æ£€æŸ¥ WhisperProcessor")
    print("=" * 60)
    
    try:
        from utils.whisper_processor import WhisperProcessor
        print("âœ… WhisperProcessor å¯¼å…¥æˆåŠŸ")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ç¼“å­˜ç›¸å…³çš„æ–¹æ³•
        if hasattr(WhisperProcessor, '_get_cache_key'):
            print("âœ… ç¼“å­˜æ–¹æ³•å­˜åœ¨: _get_cache_key")
        else:
            print("âŒ ç¼ºå°‘ç¼“å­˜æ–¹æ³•: _get_cache_key")
            return False
        
        if hasattr(WhisperProcessor, '_save_cache'):
            print("âœ… ç¼“å­˜æ–¹æ³•å­˜åœ¨: _save_cache")
        else:
            print("âŒ ç¼ºå°‘ç¼“å­˜æ–¹æ³•: _save_cache")
            return False
        
        if hasattr(WhisperProcessor, '_load_cache'):
            print("âœ… ç¼“å­˜æ–¹æ³•å­˜åœ¨: _load_cache")
        else:
            print("âŒ ç¼ºå°‘ç¼“å­˜æ–¹æ³•: _load_cache")
            return False
        
        if hasattr(WhisperProcessor, '_transcribe_with_word_timestamps'):
            print("âœ… è¯çº§æ—¶é—´æˆ³æ–¹æ³•å­˜åœ¨: _transcribe_with_word_timestamps")
        else:
            print("âŒ ç¼ºå°‘è¯çº§æ—¶é—´æˆ³æ–¹æ³•: _transcribe_with_word_timestamps")
            return False
        
        print("\nâœ… WhisperProcessor æ‰€æœ‰åŠŸèƒ½æ­£å¸¸ï¼\n")
        return True
        
    except ImportError as e:
        print(f"âŒ WhisperProcessor å¯¼å…¥å¤±è´¥: {e}")
        return False
    except Exception as e:
        print(f"âŒ æ£€æŸ¥ WhisperProcessor æ—¶å‡ºé”™: {e}")
        return False


def test_cache_directory():
    """æµ‹è¯•ç¼“å­˜ç›®å½•"""
    print("=" * 60)
    print("æµ‹è¯• 3: æ£€æŸ¥ç¼“å­˜ç›®å½•")
    print("=" * 60)
    
    cache_dir = Path.home() / 'Videos' / 'pyvideotrans' / 'get_srt_zimu' / 'whisper_cache'
    
    if cache_dir.exists():
        print(f"âœ… ç¼“å­˜ç›®å½•å­˜åœ¨: {cache_dir}")
        
        # æ£€æŸ¥ç¼“å­˜æ–‡ä»¶
        cache_files = list(cache_dir.glob('*.pkl'))
        if cache_files:
            print(f"âœ… æ‰¾åˆ° {len(cache_files)} ä¸ªç¼“å­˜æ–‡ä»¶")
            for f in cache_files[:3]:  # æ˜¾ç¤ºå‰3ä¸ª
                size_mb = f.stat().st_size / (1024 * 1024)
                print(f"   - {f.name} ({size_mb:.2f} MB)")
            if len(cache_files) > 3:
                print(f"   ... è¿˜æœ‰ {len(cache_files) - 3} ä¸ªæ–‡ä»¶")
        else:
            print("â„¹ï¸  æš‚æ— ç¼“å­˜æ–‡ä»¶ï¼ˆæ­£å¸¸ï¼Œç¬¬ä¸€æ¬¡ä½¿ç”¨ï¼‰")
    else:
        print(f"â„¹ï¸  ç¼“å­˜ç›®å½•ä¸å­˜åœ¨ï¼ˆæ­£å¸¸ï¼Œç¬¬ä¸€æ¬¡ä½¿ç”¨ï¼‰")
        print(f"   å°†åœ¨é¦–æ¬¡è¿è¡Œæ—¶åˆ›å»º: {cache_dir}")
    
    print()
    return True


def test_device_detection():
    """æµ‹è¯•è®¾å¤‡æ£€æµ‹"""
    print("=" * 60)
    print("æµ‹è¯• 4: æ£€æŸ¥è®¾å¤‡æ”¯æŒ")
    print("=" * 60)
    
    # å°è¯•æ£€æµ‹ CUDA
    try:
        import torch
        if torch.cuda.is_available():
            print("âœ… æ£€æµ‹åˆ° CUDA (NVIDIA GPU)")
            print(f"   è®¾å¤‡æ•°é‡: {torch.cuda.device_count()}")
            print(f"   è®¾å¤‡åç§°: {torch.cuda.get_device_name(0)}")
        else:
            print("â„¹ï¸  æœªæ£€æµ‹åˆ° CUDAï¼Œå°†ä½¿ç”¨ CPU")
            print("   ğŸ’¡ faster-whisper åœ¨ CPU ä¸Šä¹Ÿå¾ˆå¿«ï¼")
    except ImportError:
        print("â„¹ï¸  torch æœªå®‰è£…ï¼Œå°†ä½¿ç”¨ CPU")
        print("   ğŸ’¡ faster-whisper åœ¨ CPU ä¸Šä¹Ÿå¾ˆå¿«ï¼")
    
    print()
    return True


def test_compatibility():
    """æµ‹è¯•ä¸æ­¥éª¤äºŒçš„å…¼å®¹æ€§"""
    print("=" * 60)
    print("æµ‹è¯• 5: æ£€æŸ¥ä¸æ™ºèƒ½åˆ†å‰²çš„å…¼å®¹æ€§")
    print("=" * 60)
    
    try:
        from utils.llm_processor import LLMProcessor
        print("âœ… LLMProcessor å¯¼å…¥æˆåŠŸ")
        
        # æ£€æŸ¥ç¼“å­˜ç›®å½•æ˜¯å¦ç›¸åŒ
        from utils.whisper_processor import WhisperProcessor
        from PySide6.QtCore import QObject
        
        # åˆ›å»ºä¸´æ—¶å®ä¾‹æ£€æŸ¥ç¼“å­˜ç›®å½•
        dummy_data = {'model': 'tiny', 'project_name': 'test'}
        # è¿™é‡Œåªæ˜¯æ£€æŸ¥ç±»å®šä¹‰ï¼Œä¸å®é™…è¿è¡Œ
        
        print("âœ… æ­¥éª¤ä¸€å’Œæ­¥éª¤äºŒä½¿ç”¨ç›¸åŒçš„ç¼“å­˜æœºåˆ¶")
        print("âœ… ä¸¤ä¸ªæ­¥éª¤å¯ä»¥æ— ç¼åä½œ")
        
        print("\nâœ… å…¼å®¹æ€§æµ‹è¯•é€šè¿‡ï¼\n")
        return True
        
    except ImportError as e:
        print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
        return False
    except Exception as e:
        print(f"âš ï¸  æ£€æŸ¥æ—¶å‡ºç°é—®é¢˜: {e}")
        print("   è¿™å¯èƒ½ä¸å½±å“å®é™…ä½¿ç”¨")
        return True


def print_summary(results):
    """æ‰“å°æµ‹è¯•æ€»ç»“"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•æ€»ç»“")
    print("=" * 60)
    
    total = len(results)
    passed = sum(results)
    
    print(f"æ€»è®¡: {total} é¡¹æµ‹è¯•")
    print(f"é€šè¿‡: {passed} é¡¹")
    print(f"å¤±è´¥: {total - passed} é¡¹")
    
    if passed == total:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        print("\nâœ¨ faster-whisper å‡çº§æˆåŠŸï¼")
        print("\nğŸ“ ä¸»è¦æ”¹è¿›:")
        print("   âš¡ é€Ÿåº¦æå‡ 4 å€")
        print("   ğŸ’¾ å†…å­˜å‡å°‘ 58%")
        print("   â­ ç²¾åº¦ç•¥æœ‰æå‡")
        print("   âœ… æ”¯æŒè¯çº§æ—¶é—´æˆ³")
        print("   âœ… æ™ºèƒ½ç¼“å­˜ç³»ç»Ÿ")
        print("   âœ… ä¸¤æ­¥éª¤æ— ç¼åä½œ")
        print("\nğŸš€ ç°åœ¨å¯ä»¥å¼€å§‹ä½¿ç”¨äº†ï¼")
        print("\nğŸ’¡ æç¤º:")
        print("   1. è¿è¡Œ python main.py å¯åŠ¨åº”ç”¨")
        print("   2. é¦–æ¬¡å¤„ç†è§†é¢‘ä¼šè‡ªåŠ¨ç”Ÿæˆç¼“å­˜")
        print("   3. åç»­å¤„ç†åŒä¸€è§†é¢‘ä¼šç§’çº§å®Œæˆ")
        print("   4. å¯ä»¥å¤šæ¬¡è°ƒæ•´ LLM å‚æ•°é‡æ–°åˆ†å‰²")
        print()
        return True
    else:
        print("\nâš ï¸  æœ‰æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä¸Šè¿°é”™è¯¯ä¿¡æ¯")
        print("\nå¯èƒ½çš„è§£å†³æ–¹æ¡ˆ:")
        print("   1. å®‰è£…ç¼ºå¤±çš„ä¾èµ–: pip install -r requirements.txt")
        print("   2. ç¡®ä¿ Python ç‰ˆæœ¬ >= 3.8")
        print("   3. æ£€æŸ¥ç½‘ç»œè¿æ¥ï¼ˆé¦–æ¬¡ä½¿ç”¨éœ€è¦ä¸‹è½½æ¨¡å‹ï¼‰")
        print()
        return False


def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("\nğŸ§ª faster-whisper å‡çº§æµ‹è¯•\n")
    print("æ­¤è„šæœ¬å°†æ£€æŸ¥:")
    print("  1. å¿…éœ€çš„ä¾èµ–æ˜¯å¦å·²å®‰è£…")
    print("  2. WhisperProcessor æ˜¯å¦æ­£ç¡®å‡çº§")
    print("  3. ç¼“å­˜ç³»ç»Ÿæ˜¯å¦å°±ç»ª")
    print("  4. è®¾å¤‡æ”¯æŒæƒ…å†µ")
    print("  5. ä¸æ™ºèƒ½åˆ†å‰²çš„å…¼å®¹æ€§")
    print()
    
    results = []
    
    # è¿è¡Œæµ‹è¯•
    results.append(test_imports())
    results.append(test_processor_import())
    results.append(test_cache_directory())
    results.append(test_device_detection())
    results.append(test_compatibility())
    
    # æ‰“å°æ€»ç»“
    success = print_summary(results)
    
    return 0 if success else 1


if __name__ == "__main__":
    sys.exit(main())

