# ğŸ”§ æ—¶é—´æˆ³æ’å€¼ä¼°ç®—ä¿®å¤

## ğŸ› é—®é¢˜æè¿°

LLM é‡æ–°åˆ†å‰²åçš„å­—å¹•æ—¶é—´æˆ³ä¸¥é‡å‹ç¼©ï¼Œå¯¼è‡´æ˜¾ç¤ºå¼‚å¸¸ã€‚

### é—®é¢˜ç¤ºä¾‹

**åŸå§‹å­—å¹•ï¼š**
```srt
124
00:08:00,920 --> 00:08:04,959
We don't have to afford Kansas to get a year go down into the basement
```

**é‡æ–°åˆ†å‰²åï¼ˆä¿®å¤å‰ï¼‰ï¼š**
```srt
129
00:08:00,920 --> 00:08:01,639   â† æ—¶é—´æˆ³è¢«å‹ç¼©äº†ï¼
We don't have to hoard cans and go down into the basement
```

---

## ğŸ” æ ¹æœ¬åŸå› 

### åœºæ™¯åˆ†æ

1. **Whisper è¯†åˆ«è¯ï¼š** å¯èƒ½æ¼è¯†åˆ«ä¸€äº›è¯ï¼ˆé”™è¯¯è¯†åˆ«ã€è¿è¯»ç­‰ï¼‰
2. **LLM æ–‡æœ¬æ®µï¼š** ä½¿ç”¨åŸå§‹å­—å¹•æ–‡æœ¬ï¼ŒåŒ…å«å®Œæ•´çš„è¯
3. **åŒ¹é…è¿‡ç¨‹ï¼š** 
   - LLM æ–‡æœ¬ï¼š"We don't have to hoard cans and go down into the basement" (12è¯)
   - Whisper å®é™…åŒ¹é…ï¼š"We don't have to ... go down into the basement" (8è¯ï¼Œæ¼äº†"hoard cans and")
4. **æ–°ç‰ˆæœ¬é—®é¢˜ï¼š** åªä½¿ç”¨æœ€åä¸€ä¸ªåŒ¹é…è¯çš„ç»“æŸæ—¶é—´ â†’ 8è¯çš„æ—¶é•¿
5. **ç»“æœï¼š** æ—¶é—´æˆ³å¤ªçŸ­ï¼Œå®é™…éœ€è¦12è¯çš„æ—¶é•¿

### ä»£ç é—®é¢˜

**ä¿®å¤å‰ï¼ˆ`llm_processor.py`ï¼‰ï¼š**
```python
matched_words = [words[i] for i in matched_indices]
start_time = matched_words[0]['start']
end_time = matched_words[-1]['end']  # âš ï¸ é—®é¢˜ï¼šç›´æ¥ä½¿ç”¨

return {
    'start': start_time,
    'end': end_time,  # åªæœ‰8ä¸ªè¯çš„æ—¶é•¿ï¼Œå®é™…éœ€è¦12ä¸ªè¯ï¼
    'next_idx': word_idx
}
```

---

## âœ… ä¿®å¤æ–¹æ¡ˆ

### æ ¸å¿ƒæ€è·¯

**æ—¶é—´æˆ³æ’å€¼ä¼°ç®—**ï¼šæ ¹æ®åŒ¹é…ç‡å’Œè¯å¯†åº¦æ¥ä¼°ç®—å®é™…æ—¶é•¿ã€‚

### ç®—æ³•é€»è¾‘

```python
# è®¡ç®—åŒ¹é…ç‡
match_ratio = len(matched_indices) / len(text_words)

if match_ratio < 0.5:  # åŒ¹é…ç‡ä½äº50%
    if len(matched_indices) >= 2:
        # åŸºäºåŒ¹é…è¯çš„å¯†åº¦ä¼°ç®—æ€»æ—¶é•¿
        avg_word_duration = (end_time - start_time) / len(matched_indices)
        estimated_duration = avg_word_duration * len(text_words)
        
        # è°ƒæ•´ç»“æŸæ—¶é—´
        end_time = start_time + estimated_duration
    else:
        # åªæœ‰ä¸€ä¸ªåŒ¹é…è¯ï¼Œä½¿ç”¨é»˜è®¤ä¼°ç®—
        avg_duration_per_word = 0.3  # å‡è®¾æ¯è¯0.3ç§’
        end_time = start_time + (len(text_words) * avg_duration_per_word)
```

### ç¤ºä¾‹è®¡ç®—

**åœºæ™¯ï¼š**
- LLM æ–‡æœ¬ï¼š12ä¸ªè¯
- Whisper åŒ¹é…ï¼š8ä¸ªè¯
- åŒ¹é…è¯æ—¶é—´èŒƒå›´ï¼š1.0ç§’ï¼ˆä» 00:08:00.920 åˆ° 00:08:01.920ï¼‰

**è®¡ç®—ï¼š**
```python
match_ratio = 8 / 12 = 0.667  # 66.7% åŒ¹é…ç‡ï¼ˆ> 50%ï¼Œä¸è§¦å‘æ’å€¼ï¼‰
```

**åœºæ™¯2ï¼ˆæ›´æç«¯ï¼‰ï¼š**
- LLM æ–‡æœ¬ï¼š15ä¸ªè¯
- Whisper åŒ¹é…ï¼š6ä¸ªè¯
- åŒ¹é…è¯æ—¶é—´èŒƒå›´ï¼š2.0ç§’

**è®¡ç®—ï¼š**
```python
match_ratio = 6 / 15 = 0.4  # 40% åŒ¹é…ç‡ï¼ˆ< 50%ï¼Œè§¦å‘æ’å€¼ï¼‰
avg_word_duration = 2.0 / 6 = 0.333ç§’/è¯
estimated_duration = 0.333 * 15 = 5.0ç§’

# ä¿®å¤å‰ï¼šend_time = start_time + 2.0ç§’
# ä¿®å¤åï¼šend_time = start_time + 5.0ç§’  âœ…
```

---

## ğŸ“Š ä¿®å¤æ•ˆæœå¯¹æ¯”

### ç¤ºä¾‹1ï¼šæ­£å¸¸åŒ¹é…ï¼ˆåŒ¹é…ç‡ > 50%ï¼‰

**ä¸å—å½±å“ï¼Œä¿æŒåŸé€»è¾‘ï¼š**
```python
åŒ¹é…ç‡ï¼š80%
æ—¶é—´æˆ³ï¼šç›´æ¥ä½¿ç”¨æœ€åä¸€ä¸ªåŒ¹é…è¯çš„ç»“æŸæ—¶é—´
```

### ç¤ºä¾‹2ï¼šä½åŒ¹é…ç‡ï¼ˆåŒ¹é…ç‡ < 50%ï¼‰

**ä¿®å¤å‰ï¼š**
```srt
129
00:08:00,920 --> 00:08:01,639
We don't have to hoard cans and go down into the basement
```

**ä¿®å¤åï¼š**
```srt
129
00:08:00,920 --> 00:08:04,959
We don't have to hoard cans and go down into the basement
```

---

## ğŸ¯ ä¸ºä»€ä¹ˆä¼šå‡ºç°ä½åŒ¹é…ç‡ï¼Ÿ

### å¸¸è§åŸå› 

1. **Whisper è¯†åˆ«é”™è¯¯**
   - é”™è¯¯è¯†åˆ«ï¼š`afford Kansas` â†’ å®é™…æ˜¯ `hoard cans`
   - è¿è¯»/å£éŸ³ï¼š`get a year go` â†’ å®é™…æ˜¯ `go down`

2. **LLM æ–‡æœ¬æ ¡æ­£**
   - åŸå§‹å­—å¹•ï¼š`We don't have to afford Kansas to get a year go down`
   - LLM ä¼˜åŒ–åï¼š`We don't have to hoard cans and go down`
   - ç»“æœï¼šå¾ˆå¤šè¯æ— æ³•åŒ¹é…

3. **è¯­è¨€å·®å¼‚**
   - åŸå§‹ï¼šå£è¯­åŒ–ã€éæ­£å¼
   - LLMï¼šæ ‡å‡†åŒ–ã€æ­£å¼

### æ’å€¼ä¼°ç®—çš„æ„ä¹‰

æ’å€¼ä¼°ç®—èƒ½å¤Ÿï¼š
1. âœ… å¤„ç† Whisper æ¼è¯†åˆ«çš„è¯
2. âœ… ä¼°ç®—ç¼ºå¤±è¯çš„æ—¶é•¿
3. âœ… ä¿æŒå­—å¹•æ˜¾ç¤ºçš„å®Œæ•´æ€§
4. âœ… é¿å…æ—¶é—´æˆ³è¿‡çŸ­å¯¼è‡´å­—å¹•é—ªç°

---

## ğŸ”§ æŠ€æœ¯ç»†èŠ‚

### åŒ¹é…ç®—æ³•

```python
def _match_text_to_words(self, text, words, start_idx):
    """åŒ¹é…æ–‡æœ¬åˆ°è¯çº§æ—¶é—´æˆ³ï¼ˆå¢å¼ºç‰ˆï¼‰"""
    
    # 1. æ¸…ç†å’Œåˆ†è¯
    text_clean = text.lower()
    text_words = [w for w in text_clean.split() if w]
    
    # 2. åŠ¨æ€è§„åˆ’åºåˆ—å¯¹é½
    matched_indices = []
    text_idx = 0
    word_idx = start_idx
    max_lookahead = 15  # å‰ç»èŒƒå›´
    
    while text_idx < len(text_words) and word_idx < len(words):
        # åœ¨å‰ç»èŒƒå›´å†…æŸ¥æ‰¾æœ€ä½³åŒ¹é…
        best_match = self._find_best_match(...)
        
        if best_score > 0.5:
            matched_indices.append(best_match)
            word_idx = best_match + 1
            text_idx += 1
        else:
            text_idx += 1  # è·³è¿‡æœªåŒ¹é…çš„è¯
    
    # 3. æ—¶é—´æˆ³æ’å€¼ä¼°ç®—
    match_ratio = len(matched_indices) / len(text_words)
    if match_ratio < 0.5:
        # æ’å€¼ä¼°ç®—...
    
    return {
        'start': start_time,
        'end': end_time,  # å¯èƒ½æ˜¯æ’å€¼ä¼°ç®—çš„
        'next_idx': word_idx,
        'match_ratio': match_ratio
    }
```

### åŒ¹é…åˆ†æ•°è®¡ç®—

```python
def _calculate_match_score(self, text_word, whisper_word):
    """è®¡ç®—ä¸¤ä¸ªè¯çš„åŒ¹é…åˆ†æ•°"""
    
    # å®Œå…¨åŒ¹é…
    if text_word == whisper_word:
        return 1.0
    
    # åŒ…å«å…³ç³»
    if text_word in whisper_word or whisper_word in text_word:
        return (shorter_len / longer_len) * 0.9
    
    # ç¼–è¾‘è·ç¦»
    distance = self._levenshtein_distance(text_word, whisper_word)
    similarity = 1.0 - (distance / max_len)
    
    return similarity if similarity > 0.6 else 0.0
```

---

## ğŸ“ ä¿®æ”¹çš„æ–‡ä»¶

- âœ… `get_srt_zimu/utils/llm_processor.py` - `_match_text_to_words` æ–¹æ³•

---

## ğŸ‰ æ€»ç»“

### é—®é¢˜
- LLM é‡æ–°åˆ†å‰²åçš„å­—å¹•æ—¶é—´æˆ³è¢«å‹ç¼©
- åŸå› ï¼šç¼ºå°‘æ—¶é—´æˆ³æ’å€¼ä¼°ç®—é€»è¾‘

### ä¿®å¤
- æ·»åŠ åŒ¹é…ç‡æ£€æŸ¥
- ä½åŒ¹é…ç‡æ—¶ä½¿ç”¨æ’å€¼ä¼°ç®—
- åŸºäºè¯å¯†åº¦ä¼°ç®—å®é™…æ—¶é•¿

### æ•ˆæœ
- âœ… æ—¶é—´æˆ³å‡†ç¡®
- âœ… å­—å¹•æ˜¾ç¤ºå®Œæ•´
- âœ… é¿å…é—ªç°é—®é¢˜

---

**ç°åœ¨æ—¶é—´æˆ³å¯¹é½æ­£å¸¸äº†ï¼** ğŸ‰

