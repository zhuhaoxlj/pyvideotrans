# ğŸ› å­—å¹•ç¼ºå¤±é—®é¢˜åˆ†æä¸ä¿®å¤

## ğŸ“Š é—®é¢˜ç°è±¡

### æ•°æ®å¯¹æ¯”
- **LLM è¾“å‡ºï¼š** 133 æ¡æ–‡æœ¬æ®µ
- **ç”Ÿæˆçš„å­—å¹•ï¼š** 52 æ¡å­—å¹•
- **ç¼ºå¤±ï¼š** 81 æ¡å­—å¹•ï¼ˆ61%ä¸¢å¤±ï¼ï¼‰

### å…·ä½“è¡¨ç°
```
åŸå§‹å­—å¹•ï¼š129 æ¡
LLM è¾“å‡ºï¼š133 æ¡æ–‡æœ¬æ®µ
â†“
æœ€ç»ˆç”Ÿæˆï¼š52 æ¡å­—å¹• âŒ

ç¼ºå¤±å†…å®¹ï¼šä»ç¬¬ 53 æ¡å¼€å§‹çš„æ‰€æœ‰å†…å®¹
```

---

## ğŸ” æ ¹æœ¬åŸå› åˆ†æ

### é—®é¢˜1ï¼šword_idx ç”¨å°½

**æ ¸å¿ƒé—®é¢˜ï¼š** å½“ `word_idx` æ¥è¿‘ `len(words)` æ—¶ï¼Œåç»­ segments æ— æ³•å†åŒ¹é…ä»»ä½•è¯ï¼

```python
while text_idx < len(text_words) and word_idx < len(words):
    # å°è¯•åŒ¹é…...
    
# âš ï¸ å¦‚æœ word_idx >= len(words)ï¼Œå¾ªç¯ç«‹å³é€€å‡º
# matched_indices ä¸ºç©ºï¼Œè¿”å› None
```

**æ•°æ®åˆ†æï¼š**
- Whisper è¯†åˆ«è¯æ•°ï¼š1,230 ä¸ª
- LLM è¾“å‡ºæ€»è¯æ•°ï¼šçº¦ 1,330 ä¸ªï¼ˆ133æ®µ Ã— 10è¯/æ®µï¼‰
- **LLM è¯æ•° > Whisper è¯æ•°ï¼**

**ç»“æœï¼š**
1. åŒ¹é…åˆ°ç¬¬ 52 ä¸ª segment æ—¶ï¼Œword_idx å·²ç»æ¥è¿‘ 1,230
2. ç¬¬ 53 ä¸ª segment å°è¯•åŒ¹é…æ—¶ï¼Œ`word_idx >= len(words)`
3. å¾ªç¯ç«‹å³é€€å‡ºï¼Œ`matched_indices = []`
4. è¿”å› `None`ï¼Œsegment è¢«è·³è¿‡
5. åç»­æ‰€æœ‰ segments éƒ½é‡åˆ°åŒæ ·é—®é¢˜
6. æœ€ç»ˆåªç”Ÿæˆäº† 52 æ¡å­—å¹•

### é—®é¢˜2ï¼šåŒ¹é…ç­–ç•¥è¿‡äºä¿å®ˆ

**å½“å‰ç­–ç•¥ï¼š**
```python
if best_score > 0.5:  # é˜ˆå€¼ 50%
    matched_indices.append(best_match)
    word_idx = best_match + 1
    text_idx += 1
else:
    text_idx += 1  # åªè·³è¿‡æ–‡æœ¬è¯ï¼Œword_idx ä¸åŠ¨
```

**é—®é¢˜ï¼š**
- å¦‚æœä¸€æ®µ segment ä¸­æœ‰å¤šä¸ªè¯åŒ¹é…ä¸ä¸Šï¼ˆWhisper æ¼è¯†åˆ«ï¼‰
- è¿™äº›è¯è¢«è·³è¿‡ï¼Œä½† word_idx ä¸æ¨è¿›
- å¯¼è‡´ word_idx æ¨è¿›ç¼“æ…¢
- æœ€ç»ˆè¿‡æ—©ç”¨å°½

### é—®é¢˜3ï¼šæ²¡æœ‰"é‡æ–°å¯¹é½"æœºåˆ¶

å½“åŒ¹é…å¤±è´¥æ—¶ï¼Œåº”è¯¥æœ‰ç­–ç•¥åœ°æ¨è¿› word_idx æ¥å°è¯•é‡æ–°å¯¹é½ï¼Œä½†å½“å‰å®ç°æ²¡æœ‰è¿™ä¸ªæœºåˆ¶ã€‚

---

## âœ… è§£å†³æ–¹æ¡ˆ

### æ–¹æ¡ˆ1ï¼šæ”¾å®½åŒ¹é…é˜ˆå€¼ + æ™ºèƒ½æ¨è¿›

```python
def _match_text_to_words(self, text, words, start_idx):
    """åŒ¹é…æ–‡æœ¬åˆ°è¯çº§æ—¶é—´æˆ³ï¼ˆå¢å¼ºç‰ˆï¼‰"""
    # ... åˆ†è¯ç­‰å‡†å¤‡å·¥ä½œ ...
    
    matched_indices = []
    text_idx = 0
    word_idx = start_idx
    max_lookahead = 15
    consecutive_misses = 0  # è¿ç»­æœªåŒ¹é…è®¡æ•°
    
    while text_idx < len(text_words) and word_idx < len(words):
        text_word = text_words[text_idx]
        best_match = None
        best_score = 0
        
        # åœ¨å‰ç»èŒƒå›´å†…æŸ¥æ‰¾æœ€ä½³åŒ¹é…
        for offset in range(min(max_lookahead, len(words) - word_idx)):
            # ... è®¡ç®—åŒ¹é…åˆ†æ•° ...
            if score > best_score:
                best_score = score
                best_match = word_idx + offset
        
        # âœ… å…³é”®ä¿®æ”¹ï¼šé™ä½é˜ˆå€¼ï¼Œæ›´å®¹æ˜“æ¥å—åŒ¹é…
        if best_score > 0.3:  # ä» 0.5 é™ä½åˆ° 0.3
            matched_indices.append(best_match)
            word_idx = best_match + 1
            text_idx += 1
            consecutive_misses = 0
        else:
            # æœªæ‰¾åˆ°åŒ¹é…
            text_idx += 1
            consecutive_misses += 1
            
            # âœ… æ™ºèƒ½æ¨è¿›ï¼šè¿ç»­å¤šæ¬¡æœªåŒ¹é…æ—¶ï¼Œé€‚åº¦æ¨è¿› word_idx
            if consecutive_misses >= 3:
                # æ¨è¿›è¾ƒå°æ­¥é•¿ï¼Œé¿å…è·³è¿‡å¤ªå¤š
                word_idx = min(word_idx + 2, len(words) - 1)
                consecutive_misses = 0
    
    # âœ… å³ä½¿åªåŒ¹é…äº†å°‘é‡è¯ï¼Œä¹Ÿè¿”å›ç»“æœï¼ˆä¸è¦å¤ªä¸¥æ ¼ï¼‰
    if len(matched_indices) >= 1:  # è‡³å°‘åŒ¹é…1ä¸ªè¯å°±å¯ä»¥
        # ... ç”Ÿæˆæ—¶é—´æˆ³ ...
        return result
    
    return None
```

### æ–¹æ¡ˆ2ï¼šå¼ºåˆ¶å¯¹é½ç­–ç•¥ï¼ˆåœ¨ _parse_llm_response å±‚é¢ï¼‰

```python
def _parse_llm_response(self, response, words):
    """è§£æ LLM è¿”å›çš„ç»“æœ"""
    segments = json.loads(...)
    
    subtitles = []
    word_idx = 0
    consecutive_failures = 0
    
    for i, segment in enumerate(segments):
        match_result = self._match_text_to_words(segment_text, words, word_idx)
        
        if match_result:
            subtitles.append(...)
            word_idx = match_result['next_idx']
            consecutive_failures = 0
        else:
            consecutive_failures += 1
            
            # âœ… å¼ºåˆ¶é‡æ–°å¯¹é½
            if consecutive_failures >= 3:
                # è®¡ç®—åº”è¯¥æ¨è¿›å¤šå°‘
                # åŸºäºå·²å¤„ç†çš„ segments æ¯”ä¾‹ä¼°ç®—
                progress_ratio = i / len(segments)
                target_word_idx = int(len(words) * progress_ratio)
                
                # æ¨è¿›åˆ°ä¼°ç®—ä½ç½®
                word_idx = max(word_idx, target_word_idx)
                consecutive_failures = 0
                
                # é‡æ–°å°è¯•åŒ¹é…å½“å‰ segment
                match_result = self._match_text_to_words(segment_text, words, word_idx)
                if match_result:
                    subtitles.append(...)
                    word_idx = match_result['next_idx']
    
    return subtitles
```

### æ–¹æ¡ˆ3ï¼šå…è®¸"è·³è·ƒå¼"åŒ¹é…

```python
def _match_text_to_words(self, text, words, start_idx):
    """åŒ¹é…æ–‡æœ¬åˆ°è¯çº§æ—¶é—´æˆ³ï¼ˆè·³è·ƒå¼ï¼‰"""
    # ... å‡†å¤‡å·¥ä½œ ...
    
    matched_indices = []
    text_idx = 0
    word_idx = start_idx
    max_lookahead = 20  # âœ… å¢åŠ å‰ç»èŒƒå›´
    
    while text_idx < len(text_words):
        # âœ… ç§»é™¤ word_idx < len(words) çš„é™åˆ¶
        # å¦‚æœ word_idx å¤ªå¤§ï¼Œæ‰©å¤§æœç´¢èŒƒå›´
        
        if word_idx >= len(words):
            # å·²ç»åˆ°æœ«å°¾ï¼Œæ— æ³•å†åŒ¹é…
            break
        
        search_end = min(word_idx + max_lookahead, len(words))
        if search_end <= word_idx:
            break
        
        # åœ¨æ‰©å¤§çš„èŒƒå›´å†…æœç´¢
        best_match = None
        best_score = 0
        
        for search_idx in range(word_idx, search_end):
            score = self._calculate_match_score(...)
            if score > best_score:
                best_score = score
                best_match = search_idx
        
        if best_score > 0.3:  # é™ä½é˜ˆå€¼
            matched_indices.append(best_match)
            word_idx = best_match + 1
            text_idx += 1
        else:
            # å³ä½¿æ²¡åŒ¹é…ï¼Œä¹Ÿæ¨è¿›ä¸€ç‚¹
            text_idx += 1
            word_idx += 1  # âœ… å°æ­¥æ¨è¿›
    
    return result if matched_indices else None
```

---

## ğŸš€ æ¨èæ–¹æ¡ˆï¼ˆç»¼åˆï¼‰

ç»“åˆä»¥ä¸Šæ–¹æ¡ˆçš„ä¼˜ç‚¹ï¼š

```python
def _parse_llm_response(self, response, words):
    """è§£æ LLM è¿”å›çš„ç»“æœï¼ˆå¢å¼ºç‰ˆï¼‰"""
    segments = json.loads(response)
    subtitles = []
    word_idx = 0
    failed_segments = []
    
    # ç¬¬ä¸€éï¼šæ­£å¸¸åŒ¹é…
    for i, segment in enumerate(segments):
        match_result = self._match_text_to_words_v2(
            segment['text'], words, word_idx, 
            allow_partial=True  # âœ… å…è®¸éƒ¨åˆ†åŒ¹é…
        )
        
        if match_result:
            subtitles.append(...)
            word_idx = match_result['next_idx']
        else:
            failed_segments.append((i, segment))
            # âœ… åŸºäºè¿›åº¦æ¨è¿›
            word_idx = int(len(words) * (i / len(segments)))
    
    # ç¬¬äºŒéï¼šé‡æ–°åŒ¹é…å¤±è´¥çš„ segmentsï¼ˆä½¿ç”¨æ›´å®½æ¾çš„ç­–ç•¥ï¼‰
    for i, segment in failed_segments:
        # å°è¯•åœ¨æ›´å¤§èŒƒå›´å†…æœç´¢
        match_result = self._match_text_anywhere(segment['text'], words)
        if match_result:
            subtitles.append(...)
    
    # æŒ‰æ—¶é—´æˆ³æ’åº
    subtitles.sort(key=lambda x: x['start'])
    return subtitles
```

---

## ğŸ“ ç«‹å³ä¿®å¤ï¼ˆä¸´æ—¶æ–¹æ¡ˆï¼‰

æˆ‘å·²ç»æ·»åŠ äº†ä¸´æ—¶è°ƒè¯•å’Œä¿®å¤ï¼š

```python
# å¦‚æœè¿ç»­3ä¸ª segments æ— æ³•åŒ¹é…ï¼Œå¼ºåˆ¶æ¨è¿› word_idx
if skipped_count >= 3 and word_idx < len(words) - 10:
    word_idx += 5
    skipped_count = 0
```

**ç°åœ¨é‡æ–°æµ‹è¯•ä¼šçœ‹åˆ°è¯¦ç»†çš„è°ƒè¯•ä¿¡æ¯ï¼š**
- å“ªäº› segments æ— æ³•åŒ¹é…
- å½“å‰ word_idx çš„ä½ç½®
- å¼ºåˆ¶æ¨è¿›çš„æƒ…å†µ

---

## ğŸ¯ å®Œæ•´ä¿®å¤è®¡åˆ’

1. **ç«‹å³ï¼š** ä½¿ç”¨ä¸´æ—¶ä¿®å¤ï¼ˆå·²å®Œæˆï¼‰ âœ…
2. **çŸ­æœŸï¼š** é™ä½åŒ¹é…é˜ˆå€¼åˆ° 0.3
3. **ä¸­æœŸï¼š** å®ç°æ™ºèƒ½æ¨è¿›ç­–ç•¥
4. **é•¿æœŸï¼š** å®ç°ä¸¤éåŒ¹é…ç®—æ³•

---

**ç°åœ¨é‡æ–°è¿è¡Œæµ‹è¯•ï¼ŒæŸ¥çœ‹è¯¦ç»†æ—¥å¿—ï¼** ğŸ”

