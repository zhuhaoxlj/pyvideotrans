"""
LLM æ™ºèƒ½å­—å¹•åˆ†å‰²å¤„ç†å™¨
åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„è¯­ä¹‰ç†è§£è¿›è¡Œæ™ºèƒ½æ–­å¥
æ”¯æŒï¼šä»è§†é¢‘ç”Ÿæˆå­—å¹•ã€é‡æ–°åˆ†å‰²ç°æœ‰å­—å¹•ã€ç¼“å­˜æœºåˆ¶ç­‰

å®Œæ•´è¿ç§»è‡ª videotrans.winform.fn_llm_split
"""

import json
import re
import hashlib
import pickle
import time
import difflib
from pathlib import Path
from PySide6.QtCore import QThread, Signal


class LLMProcessor(QThread):
    """LLM å­—å¹•åˆ†å‰²å¤„ç†çº¿ç¨‹"""
    progress = Signal(str)  # è¿›åº¦ä¿¡æ¯
    stream = Signal(str)    # æµå¼è¾“å‡º
    finished_signal = Signal(str)  # å®Œæˆä¿¡å·ï¼Œä¼ é€’è¾“å‡ºæ–‡ä»¶è·¯å¾„
    error = Signal(str)     # é”™è¯¯ä¿¡å·
    
    def __init__(self, video_file=None, srt_file=None, llm_provider='siliconflow', 
                 llm_api_key='', llm_model='Qwen/Qwen2.5-7B-Instruct', llm_base_url='',
                 language='en', model_size='large-v3-turbo', max_duration=5.0, 
                 max_words=15, device='cpu', output_dir=None, models_dir=None, enable_cache=True):
        """
        åˆå§‹åŒ– LLM å¤„ç†å™¨
        
        Args:
            video_file: è§†é¢‘æ–‡ä»¶è·¯å¾„ï¼ˆç”¨äºç”Ÿæˆæ–°å­—å¹•ï¼‰
            srt_file: SRT æ–‡ä»¶è·¯å¾„ï¼ˆç”¨äºé‡æ–°åˆ†å‰²ç°æœ‰å­—å¹•ï¼‰
            llm_provider: LLM æä¾›å•†
            llm_api_key: LLM API Key
            llm_model: LLM æ¨¡å‹
            llm_base_url: LLM Base URLï¼ˆå¯é€‰ï¼‰
            language: Whisper è¯†åˆ«è¯­è¨€
            model_size: Whisper æ¨¡å‹å¤§å°
            max_duration: æœ€å¤§æŒç»­æ—¶é—´
            max_words: æœ€å¤§è¯æ•°
            device: è®¡ç®—è®¾å¤‡ï¼ˆcpu/cuda/mpsï¼‰
            output_dir: è¾“å‡ºç›®å½•
            models_dir: Whisperæ¨¡å‹ç›®å½•
            enable_cache: æ˜¯å¦å¯ç”¨è¯çº§æ—¶é—´æˆ³ç¼“å­˜
        """
        super().__init__()
        self.video_file = video_file
        self.srt_file = srt_file
        self.llm_provider = llm_provider.lower()
        self.llm_api_key = llm_api_key
        self.llm_model = llm_model
        self.llm_base_url = llm_base_url
        self.language = language
        self.model_size = model_size
        self.max_duration = max_duration
        self.max_words = max_words
        self.device = device
        self.enable_cache = enable_cache
        
        # è®¾ç½®è¾“å‡ºç›®å½•å’Œæ–‡ä»¶
        if output_dir:
            self.output_dir = Path(output_dir)
        else:
            self.output_dir = Path.home() / 'Videos' / 'pyvideotrans' / 'get_srt_zimu' / 'output'
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # ç¼“å­˜ç›®å½•
        self.cache_dir = Path.home() / 'Videos' / 'pyvideotrans' / 'get_srt_zimu' / 'whisper_cache'
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        
        # Whisperæ¨¡å‹ç›®å½•
        if models_dir:
            self.models_dir = Path(models_dir)
        else:
            # å°è¯•ä½¿ç”¨get_srt_zimuçš„modelsç›®å½•ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä½¿ç”¨ä¸»é¡¹ç›®çš„
            local_models = Path(__file__).parent.parent / 'models'
            main_models = Path(__file__).parent.parent.parent / 'models'
            self.models_dir = local_models if local_models.exists() else main_models
        
        # ç¡®å®šè¾“å‡ºæ–‡ä»¶å
        if video_file:
            base_name = Path(video_file).stem
            suffix = '_llm_resplit.srt' if srt_file else '_llm_smart.srt'
        elif srt_file:
            base_name = Path(srt_file).stem
            suffix = '_llm_split.srt'
        else:
            raise ValueError("å¿…é¡»æä¾› video_file æˆ– srt_file")
        
        self.output_file = str(self.output_dir / f"{base_name}{suffix}")
    
    def run(self):
        """ä¸»å¤„ç†æµç¨‹"""
        try:
            if self.srt_file and not self.video_file:
                # æ¨¡å¼1ï¼šä»…é‡æ–°åˆ†å‰²ç°æœ‰å­—å¹•ï¼ˆç®€å•æ¨¡å¼ï¼‰
                self.progress.emit('ğŸ¤– æ¨¡å¼: é‡æ–°åˆ†å‰²ç°æœ‰å­—å¹•ï¼ˆä»…LLMï¼‰')
                self.process_srt_only()
            elif self.video_file and self.srt_file:
                # æ¨¡å¼2ï¼šä½¿ç”¨è§†é¢‘+ç°æœ‰å­—å¹•é‡æ–°åˆ†å‰²
                self.progress.emit('ğŸ¤– æ¨¡å¼: ä½¿ç”¨è§†é¢‘+ç°æœ‰å­—å¹•ï¼ˆWhisperè¯çº§+LLMï¼‰')
                self.process_with_video_and_srt()
            elif self.video_file:
                # æ¨¡å¼3ï¼šä»è§†é¢‘ç”Ÿæˆæ–°å­—å¹•
                self.progress.emit('ğŸ¤– æ¨¡å¼: ä»è§†é¢‘ç”Ÿæˆæ–°å­—å¹•ï¼ˆWhisper+LLMï¼‰')
                self.process_new_transcription()
            else:
                self.error.emit("å¿…é¡»æä¾›è§†é¢‘æ–‡ä»¶æˆ–å­—å¹•æ–‡ä»¶")
                return
                
        except Exception as e:
            import traceback
            self.error.emit(f"å¤„ç†å¤±è´¥: {str(e)}\n{traceback.format_exc()}")
    
    def process_srt_only(self):
        """å¤„ç†æ¨¡å¼1ï¼šä»…é‡æ–°åˆ†å‰²ç°æœ‰å­—å¹•ï¼ˆç®€å•LLMåˆ†å‰²ï¼‰"""
        # 1. è¯»å– SRT æ–‡ä»¶
        self.progress.emit("ğŸ“– è¯»å–å­—å¹•æ–‡ä»¶...")
        subtitles = self.parse_srt(self.srt_file)
        if not subtitles:
            self.error.emit("æ— æ³•è§£æå­—å¹•æ–‡ä»¶")
            return
        
        self.progress.emit(f"âœ… è¯»å–åˆ° {len(subtitles)} æ¡å­—å¹•")
        
        # 2. æå–æ–‡æœ¬
        full_text = ' '.join([sub['text'] for sub in subtitles])
        self.progress.emit(f"ğŸ“ æ–‡æœ¬é•¿åº¦: {len(full_text)} å­—ç¬¦")
        
        # 3. è°ƒç”¨ LLM è¿›è¡Œæ™ºèƒ½åˆ†å‰²
        self.progress.emit("ğŸ¤– æ­£åœ¨è°ƒç”¨ LLM è¿›è¡Œæ™ºèƒ½åˆ†å‰²...")
        self.progress.emit(f"   æä¾›å•†: {self.llm_provider}")
        self.progress.emit(f"   æ¨¡å‹: {self.llm_model}")
        
        new_segments = self.llm_split_simple(full_text)
        
        if not new_segments:
            self.error.emit("LLM åˆ†å‰²å¤±è´¥")
            return
        
        self.progress.emit(f"âœ… LLM è¿”å› {len(new_segments)} ä¸ªåˆ†æ®µ")
        
        # 4. æ˜ å°„åˆ°æ—¶é—´æˆ³
        self.progress.emit("â° æ˜ å°„æ—¶é—´æˆ³...")
        new_subtitles = self.map_timestamps(new_segments, subtitles)
        
        if not new_subtitles:
            self.error.emit("æ—¶é—´æˆ³æ˜ å°„å¤±è´¥")
            return
        
        # 5. ä¿å­˜ç»“æœ
        self.progress.emit("ğŸ’¾ ä¿å­˜ç»“æœ...")
        self.save_srt(new_subtitles)
        
        self.progress.emit(f"âœ… å®Œæˆï¼ç”Ÿæˆ {len(new_subtitles)} æ¡å­—å¹•")
        self.progress.emit(f"ğŸ“ ä¿å­˜åˆ°: {self.output_file}")
        
        self.finished_signal.emit(self.output_file)
    
    def process_new_transcription(self):
        """å¤„ç†æ¨¡å¼3ï¼šä»è§†é¢‘ç”Ÿæˆæ–°å­—å¹• + LLMä¼˜åŒ–"""
        # æ£€æŸ¥ç¼“å­˜ï¼ˆåªä½¿ç”¨è§†é¢‘æ–‡ä»¶ï¼Œå› ä¸ºè¯çº§æ—¶é—´æˆ³åªä¾èµ–è§†é¢‘å†…å®¹ï¼‰
        self.progress.emit('ğŸ” æ£€æŸ¥ç¼“å­˜...')
        self.progress.emit(f'   è§†é¢‘æ–‡ä»¶: {self.video_file}')
        cache_status = 'âœ… å·²å¯ç”¨' if self.enable_cache else 'âŒ å·²ç¦ç”¨'
        self.progress.emit(f'   ç¼“å­˜å¼€å…³: {cache_status}')
        
        cached_data = None
        if self.enable_cache:
            cache_key = self.get_cache_key(self.video_file)  # åªç”¨è§†é¢‘æ–‡ä»¶ç”Ÿæˆç¼“å­˜key
            self.progress.emit(f'   ç¼“å­˜é”®: {cache_key[:16]}... (SHA256)')
            cached_data = self.load_cache(cache_key)
        else:
            self.progress.emit('   âš ï¸  ç¼“å­˜å·²ç¦ç”¨ï¼Œå°†é‡æ–°è¯†åˆ«')
        
        if cached_data:
            self.progress.emit('   âœ… æ‰¾åˆ°ç¼“å­˜ï¼')
            all_words = cached_data['all_words']
            detected_language = cached_data['language']
            self.progress.emit(f'   ğŸ“Š ä»ç¼“å­˜åŠ è½½: {len(all_words)} ä¸ªè¯')
            self.progress.emit(f'   ğŸŒ æ£€æµ‹è¯­è¨€: {detected_language}')
        else:
            self.progress.emit('   âŒ æœªæ‰¾åˆ°ç¼“å­˜ï¼Œå¼€å§‹ Whisper å¤„ç†...')
            all_words, detected_language = self.transcribe_with_whisper()
            if not all_words:
                return
            # ä¿å­˜ç¼“å­˜ï¼ˆä»…åœ¨å¯ç”¨ç¼“å­˜æ—¶ï¼‰
            if self.enable_cache:
                cache_key = self.get_cache_key(self.video_file)
                self.save_cache(cache_key, all_words, detected_language)
            else:
                self.progress.emit('ğŸ’¡ æç¤º: ç¼“å­˜å·²ç¦ç”¨ï¼Œæœªä¿å­˜è¯çº§æ—¶é—´æˆ³')
        
        # ä½¿ç”¨ LLM è¿›è¡Œæ™ºèƒ½æ–­å¥
        self.progress.emit('ğŸ¤– ä½¿ç”¨ LLM è¿›è¡Œæ™ºèƒ½æ–­å¥ä¼˜åŒ–...')
        subtitles = self.llm_smart_split(all_words, detected_language)
        
        if not subtitles:
            self.error.emit('LLM æ–­å¥å¤±è´¥')
            return
        
        self.progress.emit(f'âœ… ç”Ÿæˆ {len(subtitles)} æ¡å­—å¹•')
        
        # ä¿å­˜
        self.save_srt(subtitles)
        
        self.progress.emit('ğŸ’¾ ä¿å­˜å®Œæˆ')
        self.finished_signal.emit(self.output_file)
    
    def process_with_video_and_srt(self):
        """å¤„ç†æ¨¡å¼2ï¼šä½¿ç”¨è§†é¢‘+ç°æœ‰å­—å¹•é‡æ–°åˆ†å‰²"""
        self.progress.emit(f'ğŸ“– è¯»å–ç°æœ‰å­—å¹•: {Path(self.srt_file).name}')
        
        # è¯»å–ç°æœ‰å­—å¹•
        original_subtitles = self.parse_srt(self.srt_file)
        if not original_subtitles:
            self.error.emit('æ— æ³•è§£æå­—å¹•æ–‡ä»¶')
            return
        
        self.progress.emit(f'âœ… è¯»å–åˆ° {len(original_subtitles)} æ¡åŸå§‹å­—å¹•')
        
        # æå–å®Œæ•´æ–‡æœ¬
        original_text = ' '.join([sub['text'] for sub in original_subtitles])
        self.progress.emit(f'ğŸ“ åŸå§‹æ–‡æœ¬é•¿åº¦: {len(original_text)} å­—ç¬¦')
        
        # æ£€æŸ¥ç¼“å­˜ï¼ˆåªä½¿ç”¨è§†é¢‘æ–‡ä»¶ï¼Œå› ä¸ºè¯çº§æ—¶é—´æˆ³åªä¾èµ–è§†é¢‘å†…å®¹ï¼‰
        self.progress.emit('ğŸ” æ£€æŸ¥ç¼“å­˜...')
        self.progress.emit(f'   è§†é¢‘æ–‡ä»¶: {self.video_file}')
        cache_status = 'âœ… å·²å¯ç”¨' if self.enable_cache else 'âŒ å·²ç¦ç”¨'
        self.progress.emit(f'   ç¼“å­˜å¼€å…³: {cache_status}')
        
        cached_data = None
        if self.enable_cache:
            cache_key = self.get_cache_key(self.video_file)  # ä¸ä¼ srt_fileï¼Œåªç”¨è§†é¢‘
            self.progress.emit(f'   ç¼“å­˜é”®: {cache_key[:16]}... (SHA256)')
            cached_data = self.load_cache(cache_key)
        else:
            self.progress.emit('   âš ï¸  ç¼“å­˜å·²ç¦ç”¨ï¼Œå°†é‡æ–°è¯†åˆ«')
        
        if cached_data:
            self.progress.emit('   âœ… æ‰¾åˆ°ç¼“å­˜ï¼')
            all_words = cached_data['all_words']
            detected_language = cached_data['language']
            self.progress.emit(f'   ğŸ“Š ä»ç¼“å­˜åŠ è½½: {len(all_words)} ä¸ªè¯')
            self.progress.emit(f'   ğŸŒ æ£€æµ‹è¯­è¨€: {detected_language}')
        else:
            self.progress.emit('   âŒ æœªæ‰¾åˆ°ç¼“å­˜ï¼Œå¼€å§‹ Whisper å¤„ç†...')
            all_words, detected_language = self.transcribe_with_whisper()
            if not all_words:
                return
            # ä¿å­˜ç¼“å­˜ï¼ˆä»…åœ¨å¯ç”¨ç¼“å­˜æ—¶ï¼‰
            if self.enable_cache:
                cache_key = self.get_cache_key(self.video_file)
                self.save_cache(cache_key, all_words, detected_language)
            else:
                self.progress.emit('ğŸ’¡ æç¤º: ç¼“å­˜å·²ç¦ç”¨ï¼Œæœªä¿å­˜è¯çº§æ—¶é—´æˆ³')
        
        # ä½¿ç”¨ LLM è¿›è¡Œæ™ºèƒ½æ–­å¥ï¼ˆä½¿ç”¨åŸå§‹æ–‡æœ¬ï¼‰
        self.progress.emit('ğŸ¤– ä½¿ç”¨ LLM è¿›è¡Œæ™ºèƒ½æ–­å¥ä¼˜åŒ–...')
        subtitles = self.llm_smart_split(all_words, detected_language, original_text=original_text)
        
        if not subtitles:
            self.error.emit('LLM æ–­å¥å¤±è´¥')
            return
        
        self.progress.emit(f'ğŸ“Š åŸå§‹å­—å¹•: {len(original_subtitles)} æ¡ â†’ æ–°å­—å¹•: {len(subtitles)} æ¡')
        
        # ä¿å­˜
        self.save_srt(subtitles)
        
        self.progress.emit('ğŸ’¾ ä¿å­˜å®Œæˆ')
        self.finished_signal.emit(self.output_file)
    
    # ========== ç¼“å­˜ç›¸å…³æ–¹æ³• ==========
    
    def get_file_hash(self, filepath):
        """è®¡ç®—æ–‡ä»¶çš„å“ˆå¸Œå€¼"""
        hash_obj = hashlib.sha256()
        try:
            with open(filepath, 'rb') as f:
                for chunk in iter(lambda: f.read(8192), b''):
                    hash_obj.update(chunk)
            return hash_obj.hexdigest()
        except Exception as e:
            self.progress.emit(f'âš ï¸ è®¡ç®—å“ˆå¸Œå€¼å¤±è´¥: {str(e)}')
            return None
    
    def get_cache_key(self, video_file, srt_file=None):
        """ç”Ÿæˆç¼“å­˜é”®"""
        video_hash = self.get_file_hash(video_file)
        if not video_hash:
            return None
        
        if srt_file:
            srt_hash = self.get_file_hash(srt_file)
            if not srt_hash:
                return None
            return f"{video_hash}_{srt_hash}"
        
        return video_hash
    
    def save_cache(self, cache_key, all_words, language):
        """ä¿å­˜ç¼“å­˜"""
        if not cache_key:
            return
        
        cache_file = self.cache_dir / f"{cache_key}.pkl"
        try:
            cache_data = {
                'all_words': all_words,
                'language': language,
                'timestamp': time.time()
            }
            with open(cache_file, 'wb') as f:
                pickle.dump(cache_data, f)
            self.progress.emit(f'ğŸ’¾ ç¼“å­˜å·²ä¿å­˜: {cache_file.name}')
        except Exception as e:
            self.progress.emit(f'âš ï¸ ä¿å­˜ç¼“å­˜å¤±è´¥: {str(e)}')
    
    def load_cache(self, cache_key):
        """åŠ è½½ç¼“å­˜"""
        if not cache_key:
            return None
        
        cache_file = self.cache_dir / f"{cache_key}.pkl"
        if not cache_file.exists():
            return None
        
        try:
            with open(cache_file, 'rb') as f:
                cache_data = pickle.load(f)
            return cache_data
        except Exception as e:
            self.progress.emit(f'âš ï¸ è¯»å–ç¼“å­˜å¤±è´¥: {str(e)}')
            return None
    
    # ========== Whisper è½¬å½•æ–¹æ³• ==========
    
    def transcribe_with_whisper(self):
        """ä½¿ç”¨ Whisper è¿›è¡Œè¯­éŸ³è¯†åˆ«"""
        self.progress.emit('ğŸ”§ åŠ è½½ Faster-Whisper æ¨¡å‹...')
        
        try:
            from faster_whisper import WhisperModel
        except ImportError:
            self.error.emit('æœªå®‰è£… faster-whisper\nè¯·è¿è¡Œ: pip install faster-whisper')
            return None, None
        
        self.progress.emit(f'ğŸ“¥ æ¨¡å‹: {self.model_size}')
        
        # è®¾å¤‡ä¿¡æ¯
        device_name = {
            'cpu': 'CPU',
            'cuda': 'CUDA (NVIDIA GPU)',
            'mps': 'MPS (Apple Silicon GPU)'
        }.get(self.device, self.device.upper())
        self.progress.emit(f'âš™ï¸  è®¾å¤‡: {device_name}')
        
        # æ ¹æ®è®¾å¤‡é€‰æ‹©è®¡ç®—ç±»å‹
        if self.device == 'cuda':
            compute_type = "float16"
        elif self.device == 'mps':
            compute_type = "float16"
        else:
            compute_type = "int8"
        
        # åŠ è½½æ¨¡å‹
        try:
            model = WhisperModel(
                self.model_size,
                device=self.device,
                compute_type=compute_type,
                download_root=str(self.models_dir)
            )
        except ValueError as e:
            if 'unsupported device' in str(e).lower() and self.device == 'mps':
                self.progress.emit('âš ï¸  faster-whisper æš‚ä¸æ”¯æŒ MPS')
                self.progress.emit('ğŸ“¥ å›é€€åˆ° CPU æ¨¡å¼...')
                self.device = 'cpu'
                compute_type = 'int8'
                model = WhisperModel(
                    self.model_size,
                    device='cpu',
                    compute_type='int8',
                    download_root=str(self.models_dir)
                )
            else:
                raise
        
        self.progress.emit(f'ğŸ¤ å¼€å§‹è¯†åˆ«è¯­éŸ³...')
        self.progress.emit('â³ æ­¤è¿‡ç¨‹å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼Œè¯·è€å¿ƒç­‰å¾…...')
        
        # è½¬å½•éŸ³é¢‘
        start_time = time.time()
        segments, info = model.transcribe(
            self.video_file,
            language=self.language if self.language != 'auto' else None,
            word_timestamps=True,
            beam_size=5,
            vad_filter=True,
            vad_parameters=dict(
                threshold=0.5,
                min_speech_duration_ms=250,
                max_speech_duration_s=float('inf'),
                min_silence_duration_ms=2000,
                speech_pad_ms=400
            )
        )
        transcribe_time = time.time() - start_time
        
        self.progress.emit(f'âœ… è¯†åˆ«å®Œæˆï¼æ£€æµ‹è¯­è¨€: {info.language} (è€—æ—¶: {transcribe_time:.1f}ç§’)')
        self.progress.emit('ğŸ“Š æ”¶é›†è¯çº§æ—¶é—´æˆ³...')
        
        # æ”¶é›†æ‰€æœ‰è¯
        all_words = []
        segment_count = 0
        for segment in segments:
            segment_count += 1
            if segment_count % 10 == 0:
                self.progress.emit(f'   å¤„ç†ç‰‡æ®µ: {segment_count}...')
            
            if hasattr(segment, 'words') and segment.words:
                for word in segment.words:
                    all_words.append({
                        'word': word.word,
                        'start': word.start,
                        'end': word.end
                    })
        
        if not all_words:
            self.error.emit('æœªæ£€æµ‹åˆ°ä»»ä½•è¯­éŸ³å†…å®¹')
            return None, None
        
        self.progress.emit(f'âœ… æ”¶é›†å®Œæˆï¼å…± {len(all_words)} ä¸ªè¯')
        
        return all_words, info.language
    
    # ========== LLM åˆ†å‰²æ–¹æ³• ==========
    
    def llm_split_simple(self, text):
        """ç®€å•çš„ LLM åˆ†å‰²ï¼ˆç”¨äºä»…SRTæ¨¡å¼ï¼‰"""
        prompt = f"""You are an expert subtitle editor. Split the following text into natural, readable subtitle segments.

TEXT TO SPLIT:
{text}

REQUIREMENTS:
1. Each segment should be 3-6 seconds when spoken (approximately 10-15 words)
2. Split at natural phrase boundaries
3. Maintain semantic completeness
4. Consider reading speed and viewer comprehension

OUTPUT FORMAT:
Return ONLY a JSON array. Each element should be a string (the subtitle text).

Example:
["First subtitle segment here", "Second subtitle segment here", "Third subtitle segment"]

DO NOT include explanations, only return the JSON array."""
        
        try:
            self.progress.emit("   ğŸ“¡ æ­£åœ¨è°ƒç”¨ LLM API...")
            
            if self.llm_provider == 'siliconflow':
                response = self._call_siliconflow_stream(prompt)
            elif self.llm_provider == 'openai':
                response = self._call_openai_stream(prompt)
            elif self.llm_provider == 'claude':
                response = self._call_claude_stream(prompt)
            elif self.llm_provider == 'deepseek':
                response = self._call_deepseek_stream(prompt)
            else:
                response = self._call_siliconflow_stream(prompt)
            
            self.progress.emit("\n   âœ… LLM å“åº”å®Œæˆ")
            
            # è§£æå“åº”
            segments = self._parse_simple_response(response)
            return segments
            
        except Exception as e:
            self.progress.emit(f"\n   âŒ LLM è°ƒç”¨å¤±è´¥: {str(e)}") 
            raise
    
    def llm_smart_split(self, words, detected_language, original_text=None):
        """ä½¿ç”¨ LLM è¿›è¡Œæ™ºèƒ½æ–­å¥ï¼ˆåŸºäºè¯çº§æ—¶é—´æˆ³ï¼‰"""
        if not words:
            return []
        
        # å¦‚æœæœ‰åŸå§‹æ–‡æœ¬ï¼Œä½¿ç”¨åŸå§‹æ–‡æœ¬ï¼›å¦åˆ™ä½¿ç”¨è¯†åˆ«çš„æ–‡æœ¬
        reference_text = original_text if original_text else ''.join([w['word'] for w in words])
        
        # æ„å»º prompt
        prompt = self._build_llm_prompt(reference_text, len(words), detected_language)
        
        self.progress.emit(f'   LLMæä¾›å•†: {self.llm_provider}')
        self.progress.emit(f'   LLMæ¨¡å‹: {self.llm_model}')
        self.progress.emit(f'   å¤„ç†æ–‡æœ¬: {len(words)} è¯')
        self.progress.emit('   â³ æ­£åœ¨è°ƒç”¨ LLM APIï¼Œè¯·ç¨å€™...')
        
        # è°ƒç”¨ LLMï¼ˆæ”¯æŒæµå¼ä¼ è¾“ï¼‰
        start_time = time.time()
        try:
            self.progress.emit('   ğŸ“¡ LLM å“åº”æµ:')
            response = self._call_llm_stream(prompt)
            llm_time = time.time() - start_time
            self.progress.emit(f'\n   âœ… LLMå“åº”å®Œæˆ (è€—æ—¶: {llm_time:.1f}ç§’)')
        except Exception as e:
            self.progress.emit(f'   âš ï¸  LLMè°ƒç”¨å¤±è´¥: {str(e)}')
            self.progress.emit('   å›é€€åˆ°è§„åˆ™å¼•æ“æ–­å¥')
            return self.fallback_split(words)
        
        # è§£æ LLM è¿”å›çš„æ–­å¥ç»“æœ
        self.progress.emit('   ğŸ“‹ è§£æ LLM è¿”å›ç»“æœ...')
        subtitles = self._parse_llm_response(response, words)
        
        if not subtitles:
            self.progress.emit('   âš ï¸  LLMè¿”å›æ ¼å¼é”™è¯¯ï¼Œå›é€€åˆ°è§„åˆ™å¼•æ“')
            return self.fallback_split(words)
        
        self.progress.emit(f'   âœ… è§£æå®Œæˆï¼Œç”Ÿæˆ {len(subtitles)} æ¡å­—å¹•')
        
        # éªŒè¯å’Œè°ƒæ•´æ—¶é—´æˆ³
        self.progress.emit('   ğŸ”§ éªŒè¯å’Œè°ƒæ•´æ—¶é—´æˆ³...')
        subtitles = self._validate_and_adjust_timestamps(subtitles)
        
        self.progress.emit('   âœ… æ—¶é—´æˆ³è°ƒæ•´å®Œæˆ')
        
        return subtitles
    
    def _build_llm_prompt(self, text, word_count, language):
        """æ„å»º LLM prompt"""
        lang_name = {
            'en': 'English',
            'zh': 'Chinese',
            'ja': 'Japanese',
            'ko': 'Korean',
            'es': 'Spanish',
            'fr': 'French',
            'de': 'German',
            'ru': 'Russian'
        }.get(language, 'English')
        
        prompt = f"""You are an expert subtitle editor. Your task is to split the following {lang_name} text into natural, readable subtitle segments.

TEXT TO SPLIT:
{text}

REQUIREMENTS:
1. Each subtitle should be 3-6 seconds when spoken (approximately {int(self.max_words * 0.7)}-{self.max_words} words)
2. Split at natural phrase boundaries (not in the middle of phrases)
3. Maintain semantic completeness (don't split incomplete thoughts)
4. Consider reading speed and viewer comprehension
5. Prioritize natural pauses in speech
6. Keep related concepts together (e.g., "a beautiful day" should not be split)

The text has {word_count} words total. Please split it into approximately {max(2, word_count // self.max_words)} segments.

OUTPUT FORMAT:
Return ONLY a JSON array of subtitle segments. Each segment should have:
- "text": the subtitle text
- "word_count": approximate number of words

Example output:
[
  {{"text": "Bringing people together these days is a feat.", "word_count": 8}},
  {{"text": "Thousands of people coming joyfully together", "word_count": 6}},
  {{"text": "to create a mile-long beautiful spectacle", "word_count": 7}}
]

DO NOT include explanations, only return the JSON array."""

        return prompt
    
    def _call_llm_stream(self, prompt):
        """è°ƒç”¨ LLM APIï¼ˆæµå¼ä¼ è¾“ï¼‰"""
        if self.llm_provider == 'siliconflow':
            return self._call_siliconflow_stream(prompt)
        elif self.llm_provider == 'openai':
            return self._call_openai_stream(prompt)
        elif self.llm_provider == 'claude':
            return self._call_claude_stream(prompt)
        elif self.llm_provider == 'deepseek':
            return self._call_deepseek_stream(prompt)
        else:
            return self._call_siliconflow_stream(prompt)
    
    def _call_siliconflow_stream(self, prompt):
        """è°ƒç”¨ SiliconFlow APIï¼ˆæµå¼ï¼‰"""
        import requests
        
        url = 'https://api.siliconflow.cn/v1/chat/completions'
        headers = {
            'Authorization': f'Bearer {self.llm_api_key}',
            'Content-Type': 'application/json'
        }
        data = {
            'model': self.llm_model if self.llm_model else 'Qwen/Qwen2.5-7B-Instruct',
            'messages': [
                {'role': 'system', 'content': 'You are an expert subtitle editor.'},
                {'role': 'user', 'content': prompt}
            ],
            'temperature': 0.3,
            'stream': True
        }
        
        response = requests.post(url, headers=headers, json=data, stream=True, timeout=120)
        response.raise_for_status()
        
        full_content = []
        for line in response.iter_lines():
            if not line:
                continue
            
            line = line.decode('utf-8')
            if line.startswith('data: '):
                data_str = line[6:]
                if data_str == '[DONE]':
                    break
                
                try:
                    chunk = json.loads(data_str)
                    if 'choices' in chunk and len(chunk['choices']) > 0:
                        delta = chunk['choices'][0].get('delta', {})
                        content = delta.get('content', '')
                        if content:
                            full_content.append(content)
                            self.stream.emit(content)
                except json.JSONDecodeError:
                    continue
        
        return ''.join(full_content)
    
    def _call_openai_stream(self, prompt):
        """è°ƒç”¨ OpenAI APIï¼ˆæµå¼ï¼‰"""
        import requests
        
        url = self.llm_base_url if self.llm_base_url else 'https://api.openai.com/v1/chat/completions'
        headers = {
            'Authorization': f'Bearer {self.llm_api_key}',
            'Content-Type': 'application/json'
        }
        data = {
            'model': self.llm_model,
            'messages': [
                {'role': 'system', 'content': 'You are an expert subtitle editor.'},
                {'role': 'user', 'content': prompt}
            ],
            'temperature': 0.3,
            'stream': True
        }
        
        response = requests.post(url, headers=headers, json=data, stream=True, timeout=120)
        response.raise_for_status()
        
        full_content = []
        for line in response.iter_lines():
            if not line:
                continue
            
            line = line.decode('utf-8')
            if line.startswith('data: '):
                data_str = line[6:]
                if data_str == '[DONE]':
                    break
                
                try:
                    chunk = json.loads(data_str)
                    if 'choices' in chunk and len(chunk['choices']) > 0:
                        delta = chunk['choices'][0].get('delta', {})
                        content = delta.get('content', '')
                        if content:
                            full_content.append(content)
                            self.stream.emit(content)
                except json.JSONDecodeError:
                    continue
        
        return ''.join(full_content)
    
    def _call_claude_stream(self, prompt):
        """è°ƒç”¨ Claude APIï¼ˆæµå¼ï¼‰"""
        import requests
        
        url = 'https://api.anthropic.com/v1/messages'
        headers = {
            'x-api-key': self.llm_api_key,
            'anthropic-version': '2023-06-01',
            'Content-Type': 'application/json'
        }
        data = {
            'model': self.llm_model,
            'max_tokens': 4096,
            'messages': [{'role': 'user', 'content': prompt}],
            'temperature': 0.3,
            'stream': True
        }
        
        response = requests.post(url, headers=headers, json=data, stream=True, timeout=120)
        response.raise_for_status()
        
        full_content = []
        for line in response.iter_lines():
            if not line:
                continue
            
            line = line.decode('utf-8')
            if line.startswith('data: '):
                data_str = line[6:]
                
                try:
                    chunk = json.loads(data_str)
                    if chunk.get('type') == 'content_block_delta':
                        delta = chunk.get('delta', {})
                        content = delta.get('text', '')
                        if content:
                            full_content.append(content)
                            self.stream.emit(content)
                except json.JSONDecodeError:
                    continue
        
        return ''.join(full_content)
    
    def _call_deepseek_stream(self, prompt):
        """è°ƒç”¨ DeepSeek APIï¼ˆæµå¼ï¼‰"""
        import requests
        
        url = 'https://api.deepseek.com/v1/chat/completions'
        headers = {
            'Authorization': f'Bearer {self.llm_api_key}',
            'Content-Type': 'application/json'
        }
        data = {
            'model': self.llm_model,
            'messages': [
                {'role': 'system', 'content': 'You are an expert subtitle editor.'},
                {'role': 'user', 'content': prompt}
            ],
            'temperature': 0.3,
            'stream': True
        }
        
        response = requests.post(url, headers=headers, json=data, stream=True, timeout=120)
        response.raise_for_status()
        
        full_content = []
        for line in response.iter_lines():
            if not line:
                continue
            
            line = line.decode('utf-8')
            if line.startswith('data: '):
                data_str = line[6:]
                if data_str == '[DONE]':
                    break
                
                try:
                    chunk = json.loads(data_str)
                    if 'choices' in chunk and len(chunk['choices']) > 0:
                        delta = chunk['choices'][0].get('delta', {})
                        content = delta.get('content', '')
                        if content:
                            full_content.append(content)
                            self.stream.emit(content)
                except json.JSONDecodeError:
                    continue
        
        return ''.join(full_content)
    
    def _parse_simple_response(self, response):
        """è§£æç®€å•çš„ LLM è¿”å›ï¼ˆå­—ç¬¦ä¸²æ•°ç»„ï¼‰"""
        # æå– JSON æ•°ç»„
        json_match = re.search(r'\[.*\]', response, re.DOTALL)
        if not json_match:
            return []
        
        try:
            segments = json.loads(json_match.group(0))
            if isinstance(segments, list):
                return [s.strip() for s in segments if isinstance(s, str) and s.strip()]
        except json.JSONDecodeError:
            pass
        
        return []
    
    def _parse_llm_response(self, response, words):
        """è§£æ LLM è¿”å›çš„ç»“æœï¼ˆå¯¹è±¡æ•°ç»„ï¼‰"""
        # å°è¯•æå– JSON
        json_match = re.search(r'\[.*\]', response, re.DOTALL)
        if not json_match:
            return []
        
        try:
            segments = json.loads(json_match.group(0))
        except json.JSONDecodeError:
            return []
        
        if not isinstance(segments, list):
            return []
        
        # å°† LLM è¿”å›çš„æ–‡æœ¬æ®µåŒ¹é…åˆ°è¯çº§æ—¶é—´æˆ³
        subtitles = []
        word_idx = 0
        skipped_count = 0
        
        for i, segment in enumerate(segments):
            if not isinstance(segment, dict) or 'text' not in segment:
                continue
            
            segment_text = segment['text'].strip()
            if not segment_text:
                continue
            
            # ä½¿ç”¨å¢å¼ºçš„åŒ¹é…ç­–ç•¥
            # å¦‚æœæ¥è¿‘å°¾éƒ¨ï¼Œæ”¾å®½åŒ¹é…æ¡ä»¶
            remaining_segments = len(segments) - i
            remaining_words = len(words) - word_idx
            is_near_end = remaining_words < remaining_segments * 5
            
            match_result = self._match_text_to_words(segment_text, words, word_idx, relax=is_near_end)
            
            if match_result:
                subtitle = {
                    'start': match_result['start'],
                    'end': match_result['end'],
                    'text': segment_text
                }
                subtitles.append(subtitle)
                word_idx = match_result['next_idx']
                
                # é‡ç½®è·³è¿‡è®¡æ•°
                skipped_count = 0
            else:
                skipped_count += 1
                self.progress.emit(f'   âš ï¸  Segment {i+1} æ— æ³•åŒ¹é…ï¼ˆå·²è·³è¿‡ {skipped_count} ä¸ªï¼‰')
                self.progress.emit(f'      å½“å‰ word_idx: {word_idx}/{len(words)}')
                self.progress.emit(f'      æ–‡æœ¬: "{segment_text[:50]}..."')
                
                # æ˜¾ç¤ºå½“å‰ä½ç½®çš„è¯ï¼Œå¸®åŠ©è¯Šæ–­
                if word_idx < len(words):
                    nearby_words = []
                    for j in range(word_idx, min(word_idx + 5, len(words))):
                        nearby_words.append(words[j]['word'])
                    self.progress.emit(f'      é™„è¿‘çš„è¯: {" ".join(nearby_words)}')
                
                # å¦‚æœè¿ç»­è·³è¿‡å¤ªå¤šï¼Œå¼ºåˆ¶æ¨è¿› word_idx
                if skipped_count >= 3 and word_idx < len(words) - 10:
                    # åŸºäºè¿›åº¦æ¯”ä¾‹æ¨è¿›
                    progress_ratio = (i + 1) / len(segments)
                    target_idx = int(len(words) * progress_ratio)
                    jump = max(10, target_idx - word_idx)
                    word_idx = min(word_idx + jump, len(words) - 10)
                    self.progress.emit(f'      â†’ åŸºäºè¿›åº¦æ¨è¿› word_idx åˆ° {word_idx} (è·³è·ƒ{jump}ä¸ªè¯)')
                    skipped_count = 0
        
        self.progress.emit(f'   ğŸ“Š æˆåŠŸåŒ¹é…: {len(subtitles)}/{len(segments)} ä¸ª segments')
        return subtitles
    
    def _match_text_to_words(self, text, words, start_idx, relax=False):
        """åŒ¹é…æ–‡æœ¬åˆ°è¯çº§æ—¶é—´æˆ³ï¼ˆå¢å¼ºç‰ˆï¼‰
        
        Args:
            text: è¦åŒ¹é…çš„æ–‡æœ¬
            words: è¯çº§æ—¶é—´æˆ³åˆ—è¡¨
            start_idx: å¼€å§‹ç´¢å¼•
            relax: æ˜¯å¦æ”¾å®½åŒ¹é…æ¡ä»¶ï¼ˆç”¨äºå°¾éƒ¨segmentsï¼‰
        """
        # æ¸…ç†å’Œåˆ†è¯
        text_clean = text.lower()
        for punct in [',', '.', '!', '?', ';', ':', '"', "'", '(', ')', '[', ']']:
            text_clean = text_clean.replace(punct, ' ')
        text_words = [w for w in text_clean.split() if w]
        
        if not text_words:
            return None
        
        # ä½¿ç”¨åŠ¨æ€è§„åˆ’è¿›è¡Œåºåˆ—å¯¹é½
        matched_indices = []
        text_idx = 0
        word_idx = start_idx
        max_lookahead = 20  # âœ… å¢åŠ å‰ç»èŒƒå›´
        consecutive_misses = 0  # è¿ç»­æœªåŒ¹é…è®¡æ•°
        
        while text_idx < len(text_words) and word_idx < len(words):
            text_word = text_words[text_idx]
            best_match = None
            best_score = 0
            
            # åœ¨å½“å‰ä½ç½®é™„è¿‘æŸ¥æ‰¾æœ€ä½³åŒ¹é…
            for offset in range(min(max_lookahead, len(words) - word_idx)):
                if word_idx + offset >= len(words):
                    break
                
                word_data = words[word_idx + offset]
                word_text = word_data['word'].lower().strip()
                
                # æ¸…ç†å•è¯
                for punct in [',', '.', '!', '?', ';', ':', '"', "'", '(', ')', '[', ']']:
                    word_text = word_text.replace(punct, '')
                word_text = word_text.strip()
                
                if not word_text:
                    continue
                
                # è®¡ç®—åŒ¹é…åˆ†æ•°
                score = self._calculate_match_score(text_word, word_text)
                score = score - (offset * 0.05)  # âœ… é™ä½ä½ç½®æƒ©ç½šï¼ˆä»0.1åˆ°0.05ï¼‰
                
                if score > best_score:
                    best_score = score
                    best_match = word_idx + offset
            
            # âœ… é™ä½åŒ¹é…é˜ˆå€¼ï¼ˆä» 0.5 åˆ° 0.3ï¼‰ï¼Œæ›´å®¹æ˜“æ¥å—åŒ¹é…
            # å¦‚æœæ˜¯æ”¾å®½æ¨¡å¼ï¼Œè¿›ä¸€æ­¥é™ä½é˜ˆå€¼
            threshold = 0.2 if relax else 0.3
            if best_score > threshold:
                matched_indices.append(best_match)
                word_idx = best_match + 1
                text_idx += 1
                consecutive_misses = 0
            else:
                # æœªæ‰¾åˆ°åŒ¹é…ï¼Œå¯èƒ½æ˜¯ Whisper ç¼ºå¤±çš„è¯
                text_idx += 1
                consecutive_misses += 1
                
                # âœ… æ™ºèƒ½æ¨è¿›ï¼šè¿ç»­å¤šæ¬¡æœªåŒ¹é…æ—¶ï¼Œé€‚åº¦æ¨è¿› word_idx
                if consecutive_misses >= 2:
                    word_idx = min(word_idx + 1, len(words) - 1)
                    consecutive_misses = 0
        
        # âœ… æ”¾å®½è¦æ±‚ï¼šåªè¦åŒ¹é…äº†è‡³å°‘1ä¸ªè¯å°±è¿”å›ç»“æœ
        if len(matched_indices) < 1:
            return None
        
        # è·å–åŒ¹é…åˆ°çš„å•è¯çš„æ—¶é—´æˆ³
        matched_words = [words[i] for i in matched_indices]
        start_time = matched_words[0]['start']
        end_time = matched_words[-1]['end']
        
        # ğŸ”§ æ—¶é—´æˆ³æ’å€¼ä¼°ç®—ï¼ˆå¤„ç† Whisper æ¼è¯†åˆ«çš„è¯ï¼‰
        match_ratio = len(matched_indices) / len(text_words)
        if match_ratio < 0.5:
            # åŒ¹é…ç‡ä½äº50%ï¼Œå¯èƒ½æœ‰å¾ˆå¤šç¼ºå¤±è¯
            # ä½¿ç”¨æ›´ä¿å®ˆçš„æ—¶é—´èŒƒå›´ä¼°ç®—
            if len(matched_indices) >= 2:
                # åŸºäºåŒ¹é…è¯çš„å¯†åº¦ä¼°ç®—æ€»æ—¶é•¿
                avg_word_duration = (end_time - start_time) / len(matched_indices)
                estimated_duration = avg_word_duration * len(text_words)
                
                # è°ƒæ•´ç»“æŸæ—¶é—´
                end_time = start_time + estimated_duration
            else:
                # åªæœ‰ä¸€ä¸ªåŒ¹é…è¯ï¼Œä½¿ç”¨é»˜è®¤ä¼°ç®—
                avg_duration_per_word = 0.3  # å‡è®¾æ¯è¯0.3ç§’
                end_time = start_time + (len(text_words) * avg_duration_per_word)
        
        return {
            'start': start_time,
            'end': end_time,
            'next_idx': word_idx,
            'match_ratio': match_ratio  # ç”¨äºè°ƒè¯•
        }
    
    def _calculate_match_score(self, text_word, whisper_word):
        """è®¡ç®—ä¸¤ä¸ªè¯çš„åŒ¹é…åˆ†æ•°ï¼ˆæ”¹è¿›ç‰ˆï¼šæ›´æ™ºèƒ½çš„ç›¸ä¼¼åº¦åˆ¤æ–­ï¼‰"""
        if not text_word or not whisper_word:
            return 0.0
        
        # å®Œå…¨åŒ¹é…
        if text_word == whisper_word:
            return 1.0
        
        # ä¸€ä¸ªåŒ…å«å¦ä¸€ä¸ª
        if text_word in whisper_word or whisper_word in text_word:
            shorter = min(len(text_word), len(whisper_word))
            longer = max(len(text_word), len(whisper_word))
            return shorter / longer * 0.9
        
        # ä½¿ç”¨ç¼–è¾‘è·ç¦»
        distance = self._levenshtein_distance(text_word, whisper_word)
        max_len = max(len(text_word), len(whisper_word))
        
        if max_len == 0:
            return 0.0
        
        # è®¡ç®—åŸºäºç¼–è¾‘è·ç¦»çš„ç›¸ä¼¼åº¦
        edit_similarity = 1.0 - (distance / max_len)
        
        # ä½¿ç”¨ SequenceMatcher è®¡ç®—åºåˆ—ç›¸ä¼¼åº¦
        seq_similarity = difflib.SequenceMatcher(None, text_word, whisper_word).ratio()
        
        # å–ä¸¤è€…çš„æœ€å¤§å€¼ï¼ˆæ›´å®½æ¾çš„åŒ¹é…ç­–ç•¥ï¼‰
        final_similarity = max(edit_similarity, seq_similarity)
        
        # ğŸ”§ å…³é”®æ”¹è¿›ï¼šæ ¹æ®è¯é•¿è°ƒæ•´å®¹å¿åº¦
        if max_len <= 3:
            # çŸ­è¯ï¼šè¦æ±‚è‡³å°‘ 50% ç›¸ä¼¼åº¦
            threshold = 0.5
        elif max_len <= 6:
            # ä¸­ç­‰é•¿åº¦è¯ï¼šè¦æ±‚è‡³å°‘ 40% ç›¸ä¼¼åº¦
            threshold = 0.4
        else:
            # é•¿è¯ï¼šè¦æ±‚è‡³å°‘ 30% ç›¸ä¼¼åº¦ï¼Œå¹¶ç»™äºˆç¼–è¾‘è·ç¦»ä¼˜æƒ 
            threshold = 0.3
            # å¯¹äºé•¿è¯ï¼Œå¦‚æœç¼–è¾‘è·ç¦» <= 3ï¼Œç»™äºˆé¢å¤–å¥–åŠ±
            if distance <= 3:
                final_similarity = max(final_similarity, 0.7)
        
        return final_similarity if final_similarity >= threshold else 0.0
    
    def _levenshtein_distance(self, s1, s2):
        """è®¡ç®—ç¼–è¾‘è·ç¦»"""
        if len(s1) < len(s2):
            return self._levenshtein_distance(s2, s1)
        
        if len(s2) == 0:
            return len(s1)
        
        previous_row = range(len(s2) + 1)
        for i, c1 in enumerate(s1):
            current_row = [i + 1]
            for j, c2 in enumerate(s2):
                insertions = previous_row[j + 1] + 1
                deletions = current_row[j] + 1
                substitutions = previous_row[j] + (c1 != c2)
                current_row.append(min(insertions, deletions, substitutions))
            previous_row = current_row
        
        return previous_row[-1]
    
    def _validate_and_adjust_timestamps(self, subtitles):
        """éªŒè¯å’Œè°ƒæ•´æ—¶é—´æˆ³"""
        if not subtitles:
            return []
        
        validated = []
        
        for i, sub in enumerate(subtitles):
            # ç¡®ä¿æ—¶é—´æˆ³åˆæ³•
            if sub['start'] >= sub['end']:
                sub['end'] = sub['start'] + 1.0
            
            # ç¡®ä¿ä¸ä¸å‰ä¸€æ¡é‡å 
            if i > 0 and sub['start'] < validated[-1]['end']:
                sub['start'] = validated[-1]['end'] + 0.01
                if sub['start'] >= sub['end']:
                    sub['end'] = sub['start'] + 1.0
            
            # æ£€æŸ¥æŒç»­æ—¶é—´æ˜¯å¦åˆç†
            duration = sub['end'] - sub['start']
            if duration > self.max_duration * 2:
                sub['end'] = sub['start'] + self.max_duration * 1.5
            elif duration < 0.5:
                sub['end'] = sub['start'] + 0.5
            
            validated.append(sub)
        
        return validated
    
    def fallback_split(self, words):
        """è§„åˆ™å¼•æ“å›é€€ï¼ˆå½“LLMå¤±è´¥æ—¶ï¼‰"""
        self.progress.emit('   ğŸ”„ ä½¿ç”¨è§„åˆ™å¼•æ“æ–­å¥...')
        
        if not words or len(words) == 0:
            self.progress.emit('   âš ï¸  è¯åˆ—è¡¨ä¸ºç©ºï¼Œæ— æ³•æ–­å¥')
            return []
        
        try:
            subtitles = []
            current_words = []
            current_start = words[0]['start']
            
            sentence_ends = {'.', '!', '?', 'ã€‚', 'ï¼', 'ï¼Ÿ'}
            
            for i, word in enumerate(words):
                current_words.append(word)
                duration = word['end'] - current_start
                word_text = word['word'].strip()
                
                should_split = False
                
                # å¥å­ç»“æŸ
                if word_text and word_text[-1] in sentence_ends:
                    should_split = True
                # è¶…é™åˆ¶
                elif duration >= self.max_duration or len(current_words) >= self.max_words:
                    should_split = True
                
                if should_split and current_words:
                    subtitle = {
                        'start': current_start,
                        'end': current_words[-1]['end'],
                        'text': ''.join([w['word'] for w in current_words]).strip(),
                    }
                    subtitles.append(subtitle)
                    current_words = []
                    if i + 1 < len(words):
                        current_start = words[i + 1]['start']
            
            # å¤„ç†å‰©ä½™çš„è¯
            if current_words:
                subtitle = {
                    'start': current_start,
                    'end': current_words[-1]['end'],
                    'text': ''.join([w['word'] for w in current_words]).strip(),
                }
                subtitles.append(subtitle)
            
            self.progress.emit(f'   âœ… è§„åˆ™å¼•æ“ç”Ÿæˆ {len(subtitles)} æ¡å­—å¹•')
            return subtitles
            
        except Exception as e:
            self.progress.emit(f'   âŒ è§„åˆ™å¼•æ“å¤±è´¥: {str(e)}')
            import traceback
            self.progress.emit(f'   è¯¦ç»†é”™è¯¯: {traceback.format_exc()}')
            return []
    
    # ========== SRT æ–‡ä»¶å¤„ç†æ–¹æ³• ==========
    
    def parse_srt(self, srt_file):
        """è§£æ SRT æ–‡ä»¶"""
        try:
            with open(srt_file, 'r', encoding='utf-8') as f:
                content = f.read()
        except:
            try:
                with open(srt_file, 'r', encoding='utf-8-sig') as f:
                    content = f.read()
            except:
                return []
        
        pattern = r'(\d+)\s*\n(\d{2}:\d{2}:\d{2},\d{3})\s*-->\s*(\d{2}:\d{2}:\d{2},\d{3})\s*\n((?:.*\n)*?)(?:\n|$)'
        matches = re.findall(pattern, content)
        
        subtitles = []
        for match in matches:
            start_time = self.parse_timestamp(match[1])
            end_time = self.parse_timestamp(match[2])
            text = match[3].strip()
            
            if text:
                subtitles.append({
                    'start': start_time,
                    'end': end_time,
                    'text': text
                })
        
        return subtitles
    
    def parse_timestamp(self, timestamp_str):
        """å°† SRT æ—¶é—´æˆ³è½¬æ¢ä¸ºç§’"""
        match = re.match(r'(\d{2}):(\d{2}):(\d{2}),(\d{3})', timestamp_str)
        if match:
            h, m, s, ms = map(int, match.groups())
            return h * 3600 + m * 60 + s + ms / 1000.0
        return 0.0
    
    def map_timestamps(self, new_segments, original_subtitles):
        """å°†æ–°åˆ†æ®µæ˜ å°„åˆ°åŸå§‹å­—å¹•çš„æ—¶é—´æˆ³ï¼ˆç®€å•æ˜ å°„ï¼‰"""
        new_subtitles = []
        
        # æ„å»ºåŸå§‹æ–‡æœ¬
        original_text = ' '.join([sub['text'] for sub in original_subtitles])
        
        # ä¸ºæ¯ä¸ªæ–°åˆ†æ®µæ‰¾åˆ°åœ¨åŸå§‹æ–‡æœ¬ä¸­çš„ä½ç½®
        current_pos = 0
        
        for segment_text in new_segments:
            segment_lower = segment_text.lower().strip()
            original_lower = original_text[current_pos:].lower()
            
            # æŸ¥æ‰¾æœ€æ¥è¿‘çš„åŒ¹é…
            pos = original_lower.find(segment_lower[:min(20, len(segment_lower))])
            if pos == -1:
                continue
            
            actual_pos = current_pos + pos
            
            # æ‰¾åˆ°å¯¹åº”çš„æ—¶é—´æˆ³èŒƒå›´
            char_count = 0
            start_time = None
            end_time = None
            
            for sub in original_subtitles:
                sub_text = sub['text']
                if start_time is None and char_count + len(sub_text) >= actual_pos:
                    start_time = sub['start']
                
                char_count += len(sub_text) + 1
                
                if char_count >= actual_pos + len(segment_text):
                    end_time = sub['end']
                    break
            
            if start_time and end_time:
                new_subtitles.append({
                    'start': start_time,
                    'end': end_time,
                    'text': segment_text
                })
                current_pos = actual_pos + len(segment_text)
        
        return new_subtitles
    
    def save_srt(self, subtitles):
        """ä¿å­˜ä¸º SRT æ ¼å¼"""
        with open(self.output_file, 'w', encoding='utf-8') as f:
            for i, sub in enumerate(subtitles, 1):
                f.write(f"{i}\n")
                f.write(f"{self.format_timestamp(sub['start'])} --> {self.format_timestamp(sub['end'])}\n")
                f.write(f"{sub['text']}\n")
                f.write("\n")
    
    def format_timestamp(self, seconds):
        """è½¬æ¢ä¸º SRT æ—¶é—´æ ¼å¼"""
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = int(seconds % 60)
        milliseconds = int((seconds % 1) * 1000)
        return f"{hours:02d}:{minutes:02d}:{secs:02d},{milliseconds:03d}"

