"""
LLM æ™ºèƒ½å­—å¹•åˆ†å‰²å¤„ç†å™¨
åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„è¯­ä¹‰ç†è§£è¿›è¡Œæ™ºèƒ½æ–­å¥
æ”¯æŒï¼šä»è§†é¢‘ç”Ÿæˆå­—å¹•ã€é‡æ–°åˆ†å‰²ç°æœ‰å­—å¹•ã€ç¼“å­˜æœºåˆ¶ç­‰

å®Œæ•´è¿ç§»è‡ª videotrans.winform.fn_llm_split
"""

import json
import re
import hashlib
import pickle
import time
import difflib
from pathlib import Path
from PySide6.QtCore import QThread, Signal


class LLMProcessor(QThread):
    """LLM å­—å¹•åˆ†å‰²å¤„ç†çº¿ç¨‹"""
    progress = Signal(str)  # è¿›åº¦ä¿¡æ¯
    stream = Signal(str)    # æµå¼è¾“å‡º
    finished_signal = Signal(str)  # å®Œæˆä¿¡å·ï¼Œä¼ é€’è¾“å‡ºæ–‡ä»¶è·¯å¾„
    error = Signal(str)     # é”™è¯¯ä¿¡å·
    
    def __init__(self, video_file=None, srt_file=None, llm_provider='siliconflow',
                 llm_api_key='', llm_model='deepseek-ai/DeepSeek-V3.1-Terminus', llm_base_url='',
                 language='en', model_size='large-v3-turbo', max_duration=5.0,
                 max_words=12, device='cpu', output_dir=None, models_dir=None, enable_cache=True,
                 enable_chunking=True, chunk_size=500, enable_strict_validation=True):
        """
        åˆå§‹åŒ– LLM å¤„ç†å™¨
        
        Args:
            video_file: è§†é¢‘æ–‡ä»¶è·¯å¾„ï¼ˆç”¨äºç”Ÿæˆæ–°å­—å¹•ï¼‰
            srt_file: SRT æ–‡ä»¶è·¯å¾„ï¼ˆç”¨äºé‡æ–°åˆ†å‰²ç°æœ‰å­—å¹•ï¼‰
            llm_provider: LLM æä¾›å•†
            llm_api_key: LLM API Key
            llm_model: LLM æ¨¡å‹
            llm_base_url: LLM Base URLï¼ˆå¯é€‰ï¼‰
            language: Whisper è¯†åˆ«è¯­è¨€
            model_size: Whisper æ¨¡å‹å¤§å°
            max_duration: æœ€å¤§æŒç»­æ—¶é—´
            max_words: æœ€å¤§è¯æ•°
            device: è®¡ç®—è®¾å¤‡ï¼ˆcpu/cuda/mpsï¼‰
            output_dir: è¾“å‡ºç›®å½•
            models_dir: Whisperæ¨¡å‹ç›®å½•
            enable_cache: æ˜¯å¦å¯ç”¨è¯çº§æ—¶é—´æˆ³ç¼“å­˜
            enable_chunking: æ˜¯å¦å¯ç”¨åˆ†æ®µå¤„ç†ï¼ˆæ¨èæ€§èƒ½ä¸€èˆ¬çš„æ¨¡å‹å¯ç”¨ï¼‰
            chunk_size: æ¯æ®µçš„è¯æ•°ï¼ˆé»˜è®¤500è¯ï¼‰
            enable_strict_validation: æ˜¯å¦å¯ç”¨ä¸¥æ ¼æ–‡æœ¬éªŒè¯ï¼ˆæ£€æµ‹LLMæ˜¯å¦ä¿®æ”¹äº†å•è¯ï¼‰
        """
        super().__init__()
        self.video_file = video_file
        self.srt_file = srt_file
        self.llm_provider = llm_provider.lower()
        self.llm_api_key = llm_api_key
        self.llm_model = llm_model
        self.llm_base_url = llm_base_url
        self.language = language
        self.model_size = model_size
        self.max_duration = max_duration
        self.max_words = max_words
        self.device = device
        self.enable_cache = enable_cache
        self.enable_chunking = enable_chunking
        self.chunk_size = chunk_size
        self.enable_strict_validation = enable_strict_validation
        
        # è®¾ç½®è¾“å‡ºç›®å½•å’Œæ–‡ä»¶
        if output_dir:
            self.output_dir = Path(output_dir)
        else:
            self.output_dir = Path.home() / 'Videos' / 'pyvideotrans' / 'get_srt_zimu' / 'output'
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # ç¼“å­˜ç›®å½•
        self.cache_dir = Path.home() / 'Videos' / 'pyvideotrans' / 'get_srt_zimu' / 'whisper_cache'
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        
        # Whisperæ¨¡å‹ç›®å½•
        if models_dir:
            self.models_dir = Path(models_dir)
        else:
            # å°è¯•ä½¿ç”¨get_srt_zimuçš„modelsç›®å½•ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä½¿ç”¨ä¸»é¡¹ç›®çš„
            local_models = Path(__file__).parent.parent / 'models'
            main_models = Path(__file__).parent.parent.parent / 'models'
            self.models_dir = local_models if local_models.exists() else main_models
        
        # ç¡®å®šè¾“å‡ºæ–‡ä»¶å
        if video_file:
            base_name = Path(video_file).stem
            suffix = '_llm_resplit.srt' if srt_file else '_llm_smart.srt'
        elif srt_file:
            base_name = Path(srt_file).stem
            suffix = '_llm_split.srt'
        else:
            raise ValueError("å¿…é¡»æä¾› video_file æˆ– srt_file")
        
        self.output_file = str(self.output_dir / f"{base_name}{suffix}")
    
    def run(self):
        """ä¸»å¤„ç†æµç¨‹"""
        try:
            if self.srt_file and not self.video_file:
                # æ¨¡å¼1ï¼šä»…é‡æ–°åˆ†å‰²ç°æœ‰å­—å¹•ï¼ˆç®€å•æ¨¡å¼ï¼‰
                self.progress.emit('ğŸ¤– æ¨¡å¼: é‡æ–°åˆ†å‰²ç°æœ‰å­—å¹•ï¼ˆä»…LLMï¼‰')
                self.process_srt_only()
            elif self.video_file and self.srt_file:
                # æ¨¡å¼2ï¼šä½¿ç”¨è§†é¢‘+ç°æœ‰å­—å¹•é‡æ–°åˆ†å‰²
                self.progress.emit('ğŸ¤– æ¨¡å¼: ä½¿ç”¨è§†é¢‘+ç°æœ‰å­—å¹•ï¼ˆWhisperè¯çº§+LLMï¼‰')
                self.process_with_video_and_srt()
            elif self.video_file:
                # æ¨¡å¼3ï¼šä»è§†é¢‘ç”Ÿæˆæ–°å­—å¹•
                self.progress.emit('ğŸ¤– æ¨¡å¼: ä»è§†é¢‘ç”Ÿæˆæ–°å­—å¹•ï¼ˆWhisper+LLMï¼‰')
                self.process_new_transcription()
            else:
                self.error.emit("å¿…é¡»æä¾›è§†é¢‘æ–‡ä»¶æˆ–å­—å¹•æ–‡ä»¶")
                return
                
        except Exception as e:
            import traceback
            self.error.emit(f"å¤„ç†å¤±è´¥: {str(e)}\n{traceback.format_exc()}")
    
    def process_srt_only(self):
        """å¤„ç†æ¨¡å¼1ï¼šä»…é‡æ–°åˆ†å‰²ç°æœ‰å­—å¹•ï¼ˆç®€å•LLMåˆ†å‰²ï¼‰"""
        # 1. è¯»å– SRT æ–‡ä»¶
        self.progress.emit("ğŸ“– è¯»å–å­—å¹•æ–‡ä»¶...")
        subtitles = self.parse_srt(self.srt_file)
        if not subtitles:
            self.error.emit("æ— æ³•è§£æå­—å¹•æ–‡ä»¶")
            return
        
        self.progress.emit(f"âœ… è¯»å–åˆ° {len(subtitles)} æ¡å­—å¹•")
        
        # 2. æå–æ–‡æœ¬
        full_text = ' '.join([sub['text'] for sub in subtitles])
        self.progress.emit(f"ğŸ“ æ–‡æœ¬é•¿åº¦: {len(full_text)} å­—ç¬¦")
        
        # 3. è°ƒç”¨ LLM è¿›è¡Œæ™ºèƒ½åˆ†å‰²
        self.progress.emit("ğŸ¤– æ­£åœ¨è°ƒç”¨ LLM è¿›è¡Œæ™ºèƒ½åˆ†å‰²...")
        self.progress.emit(f"   æä¾›å•†: {self.llm_provider}")
        self.progress.emit(f"   æ¨¡å‹: {self.llm_model}")
        
        new_segments = self.llm_split_simple(full_text)
        
        if not new_segments:
            self.error.emit("LLM åˆ†å‰²å¤±è´¥")
            return
        
        self.progress.emit(f"âœ… LLM è¿”å› {len(new_segments)} ä¸ªåˆ†æ®µ")
        
        # 4. æ˜ å°„åˆ°æ—¶é—´æˆ³
        self.progress.emit("â° æ˜ å°„æ—¶é—´æˆ³...")
        new_subtitles = self.map_timestamps(new_segments, subtitles)
        
        if not new_subtitles:
            self.error.emit("æ—¶é—´æˆ³æ˜ å°„å¤±è´¥")
            return
        
        # 5. ä¿å­˜ç»“æœ
        self.progress.emit("ğŸ’¾ ä¿å­˜ç»“æœ...")
        self.save_srt(new_subtitles)
        
        self.progress.emit(f"âœ… å®Œæˆï¼ç”Ÿæˆ {len(new_subtitles)} æ¡å­—å¹•")
        self.progress.emit(f"ğŸ“ ä¿å­˜åˆ°: {self.output_file}")
        
        self.finished_signal.emit(self.output_file)
    
    def process_new_transcription(self):
        """å¤„ç†æ¨¡å¼3ï¼šä»è§†é¢‘ç”Ÿæˆæ–°å­—å¹• + LLMä¼˜åŒ–"""
        # æ£€æŸ¥ç¼“å­˜ï¼ˆåªä½¿ç”¨è§†é¢‘æ–‡ä»¶ï¼Œå› ä¸ºè¯çº§æ—¶é—´æˆ³åªä¾èµ–è§†é¢‘å†…å®¹ï¼‰
        self.progress.emit('ğŸ” æ£€æŸ¥ç¼“å­˜...')
        self.progress.emit(f'   è§†é¢‘æ–‡ä»¶: {self.video_file}')
        cache_status = 'âœ… å·²å¯ç”¨' if self.enable_cache else 'âŒ å·²ç¦ç”¨'
        self.progress.emit(f'   ç¼“å­˜å¼€å…³: {cache_status}')
        
        cached_data = None
        if self.enable_cache:
            cache_key = self.get_cache_key(self.video_file)  # åªç”¨è§†é¢‘æ–‡ä»¶ç”Ÿæˆç¼“å­˜key
            self.progress.emit(f'   ç¼“å­˜é”®: {cache_key[:16]}... (SHA256)')
            cached_data = self.load_cache(cache_key)
        else:
            self.progress.emit('   âš ï¸  ç¼“å­˜å·²ç¦ç”¨ï¼Œå°†é‡æ–°è¯†åˆ«')
        
        if cached_data:
            self.progress.emit('   âœ… æ‰¾åˆ°ç¼“å­˜ï¼')
            all_words = cached_data['all_words']
            detected_language = cached_data['language']
            self.progress.emit(f'   ğŸ“Š ä»ç¼“å­˜åŠ è½½: {len(all_words)} ä¸ªè¯')
            self.progress.emit(f'   ğŸŒ æ£€æµ‹è¯­è¨€: {detected_language}')
        else:
            self.progress.emit('   âŒ æœªæ‰¾åˆ°ç¼“å­˜ï¼Œå¼€å§‹ Whisper å¤„ç†...')
            all_words, detected_language = self.transcribe_with_whisper()
            if not all_words:
                return
            # ä¿å­˜ç¼“å­˜ï¼ˆä»…åœ¨å¯ç”¨ç¼“å­˜æ—¶ï¼‰
            if self.enable_cache:
                cache_key = self.get_cache_key(self.video_file)
                self.save_cache(cache_key, all_words, detected_language)
            else:
                self.progress.emit('ğŸ’¡ æç¤º: ç¼“å­˜å·²ç¦ç”¨ï¼Œæœªä¿å­˜è¯çº§æ—¶é—´æˆ³')
        
        # ä½¿ç”¨ LLM è¿›è¡Œæ™ºèƒ½æ–­å¥
        self.progress.emit('ğŸ¤– ä½¿ç”¨ LLM è¿›è¡Œæ™ºèƒ½æ–­å¥ä¼˜åŒ–...')
        subtitles = self.llm_smart_split(all_words, detected_language)
        
        if not subtitles:
            self.error.emit('LLM æ–­å¥å¤±è´¥')
            return
        
        self.progress.emit(f'âœ… ç”Ÿæˆ {len(subtitles)} æ¡å­—å¹•')
        
        # ä¿å­˜
        self.save_srt(subtitles)
        
        self.progress.emit('ğŸ’¾ ä¿å­˜å®Œæˆ')
        self.finished_signal.emit(self.output_file)
    
    def process_with_video_and_srt(self):
        """å¤„ç†æ¨¡å¼2ï¼šä½¿ç”¨è§†é¢‘+ç°æœ‰å­—å¹•é‡æ–°åˆ†å‰²"""
        self.progress.emit(f'ğŸ“– è¯»å–ç°æœ‰å­—å¹•: {Path(self.srt_file).name}')
        
        # è¯»å–ç°æœ‰å­—å¹•
        original_subtitles = self.parse_srt(self.srt_file)
        if not original_subtitles:
            self.error.emit('æ— æ³•è§£æå­—å¹•æ–‡ä»¶')
            return
        
        self.progress.emit(f'âœ… è¯»å–åˆ° {len(original_subtitles)} æ¡åŸå§‹å­—å¹•')
        
        # æå–å®Œæ•´æ–‡æœ¬
        original_text = ' '.join([sub['text'] for sub in original_subtitles])
        self.progress.emit(f'ğŸ“ åŸå§‹æ–‡æœ¬é•¿åº¦: {len(original_text)} å­—ç¬¦')
        
        # æ£€æŸ¥ç¼“å­˜ï¼ˆåªä½¿ç”¨è§†é¢‘æ–‡ä»¶ï¼Œå› ä¸ºè¯çº§æ—¶é—´æˆ³åªä¾èµ–è§†é¢‘å†…å®¹ï¼‰
        self.progress.emit('ğŸ” æ£€æŸ¥ç¼“å­˜...')
        self.progress.emit(f'   è§†é¢‘æ–‡ä»¶: {self.video_file}')
        cache_status = 'âœ… å·²å¯ç”¨' if self.enable_cache else 'âŒ å·²ç¦ç”¨'
        self.progress.emit(f'   ç¼“å­˜å¼€å…³: {cache_status}')
        
        cached_data = None
        if self.enable_cache:
            cache_key = self.get_cache_key(self.video_file)  # ä¸ä¼ srt_fileï¼Œåªç”¨è§†é¢‘
            self.progress.emit(f'   ç¼“å­˜é”®: {cache_key[:16]}... (SHA256)')
            cached_data = self.load_cache(cache_key)
        else:
            self.progress.emit('   âš ï¸  ç¼“å­˜å·²ç¦ç”¨ï¼Œå°†é‡æ–°è¯†åˆ«')
        
        if cached_data:
            self.progress.emit('   âœ… æ‰¾åˆ°ç¼“å­˜ï¼')
            all_words = cached_data['all_words']
            detected_language = cached_data['language']
            self.progress.emit(f'   ğŸ“Š ä»ç¼“å­˜åŠ è½½: {len(all_words)} ä¸ªè¯')
            self.progress.emit(f'   ğŸŒ æ£€æµ‹è¯­è¨€: {detected_language}')
        else:
            self.progress.emit('   âŒ æœªæ‰¾åˆ°ç¼“å­˜ï¼Œå¼€å§‹ Whisper å¤„ç†...')
            all_words, detected_language = self.transcribe_with_whisper()
            if not all_words:
                return
            # ä¿å­˜ç¼“å­˜ï¼ˆä»…åœ¨å¯ç”¨ç¼“å­˜æ—¶ï¼‰
            if self.enable_cache:
                cache_key = self.get_cache_key(self.video_file)
                self.save_cache(cache_key, all_words, detected_language)
            else:
                self.progress.emit('ğŸ’¡ æç¤º: ç¼“å­˜å·²ç¦ç”¨ï¼Œæœªä¿å­˜è¯çº§æ—¶é—´æˆ³')
        
        # ä½¿ç”¨ LLM è¿›è¡Œæ™ºèƒ½æ–­å¥ï¼ˆä½¿ç”¨åŸå§‹æ–‡æœ¬ï¼‰
        self.progress.emit('ğŸ¤– ä½¿ç”¨ LLM è¿›è¡Œæ™ºèƒ½æ–­å¥ä¼˜åŒ–...')
        subtitles = self.llm_smart_split(all_words, detected_language, original_text=original_text)
        
        if not subtitles:
            self.error.emit('LLM æ–­å¥å¤±è´¥')
            return
        
        self.progress.emit(f'ğŸ“Š åŸå§‹å­—å¹•: {len(original_subtitles)} æ¡ â†’ æ–°å­—å¹•: {len(subtitles)} æ¡')
        
        # ä¿å­˜
        self.save_srt(subtitles)
        
        self.progress.emit('ğŸ’¾ ä¿å­˜å®Œæˆ')
        self.finished_signal.emit(self.output_file)
    
    # ========== ç¼“å­˜ç›¸å…³æ–¹æ³• ==========
    
    def get_file_hash(self, filepath):
        """è®¡ç®—æ–‡ä»¶çš„å“ˆå¸Œå€¼"""
        hash_obj = hashlib.sha256()
        try:
            with open(filepath, 'rb') as f:
                for chunk in iter(lambda: f.read(8192), b''):
                    hash_obj.update(chunk)
            return hash_obj.hexdigest()
        except Exception as e:
            self.progress.emit(f'âš ï¸ è®¡ç®—å“ˆå¸Œå€¼å¤±è´¥: {str(e)}')
            return None
    
    def get_cache_key(self, video_file, srt_file=None):
        """ç”Ÿæˆç¼“å­˜é”®"""
        video_hash = self.get_file_hash(video_file)
        if not video_hash:
            return None
        
        if srt_file:
            srt_hash = self.get_file_hash(srt_file)
            if not srt_hash:
                return None
            return f"{video_hash}_{srt_hash}"
        
        return video_hash
    
    def save_cache(self, cache_key, all_words, language):
        """ä¿å­˜ç¼“å­˜"""
        if not cache_key:
            return
        
        cache_file = self.cache_dir / f"{cache_key}.pkl"
        try:
            cache_data = {
                'all_words': all_words,
                'language': language,
                'timestamp': time.time()
            }
            with open(cache_file, 'wb') as f:
                pickle.dump(cache_data, f)
            self.progress.emit(f'ğŸ’¾ ç¼“å­˜å·²ä¿å­˜: {cache_file.name}')
        except Exception as e:
            self.progress.emit(f'âš ï¸ ä¿å­˜ç¼“å­˜å¤±è´¥: {str(e)}')
    
    def load_cache(self, cache_key):
        """åŠ è½½ç¼“å­˜"""
        if not cache_key:
            return None
        
        cache_file = self.cache_dir / f"{cache_key}.pkl"
        if not cache_file.exists():
            return None
        
        try:
            with open(cache_file, 'rb') as f:
                cache_data = pickle.load(f)
            return cache_data
        except Exception as e:
            self.progress.emit(f'âš ï¸ è¯»å–ç¼“å­˜å¤±è´¥: {str(e)}')
            return None
    
    # ========== Whisper è½¬å½•æ–¹æ³• ==========
    
    def transcribe_with_whisper(self):
        """ä½¿ç”¨ Whisper è¿›è¡Œè¯­éŸ³è¯†åˆ«"""
        self.progress.emit('ğŸ”§ åŠ è½½ Faster-Whisper æ¨¡å‹...')
        
        try:
            from faster_whisper import WhisperModel
        except ImportError:
            self.error.emit('æœªå®‰è£… faster-whisper\nè¯·è¿è¡Œ: pip install faster-whisper')
            return None, None
        
        self.progress.emit(f'ğŸ“¥ æ¨¡å‹: {self.model_size}')
        
        # è®¾å¤‡ä¿¡æ¯
        device_name = {
            'cpu': 'CPU',
            'cuda': 'CUDA (NVIDIA GPU)',
            'mps': 'MPS (Apple Silicon GPU)'
        }.get(self.device, self.device.upper())
        self.progress.emit(f'âš™ï¸  è®¾å¤‡: {device_name}')
        
        # æ ¹æ®è®¾å¤‡é€‰æ‹©è®¡ç®—ç±»å‹
        if self.device == 'cuda':
            compute_type = "float16"
        elif self.device == 'mps':
            compute_type = "float16"
        else:
            compute_type = "int8"
        
        # åŠ è½½æ¨¡å‹
        try:
            model = WhisperModel(
                self.model_size,
                device=self.device,
                compute_type=compute_type,
                download_root=str(self.models_dir)
            )
        except ValueError as e:
            if 'unsupported device' in str(e).lower() and self.device == 'mps':
                self.progress.emit('âš ï¸  faster-whisper æš‚ä¸æ”¯æŒ MPS')
                self.progress.emit('ğŸ“¥ å›é€€åˆ° CPU æ¨¡å¼...')
                self.device = 'cpu'
                compute_type = 'int8'
                model = WhisperModel(
                    self.model_size,
                    device='cpu',
                    compute_type='int8',
                    download_root=str(self.models_dir)
                )
            else:
                raise
        
        self.progress.emit(f'ğŸ¤ å¼€å§‹è¯†åˆ«è¯­éŸ³...')
        self.progress.emit('â³ æ­¤è¿‡ç¨‹å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼Œè¯·è€å¿ƒç­‰å¾…...')
        
        # è½¬å½•éŸ³é¢‘
        start_time = time.time()
        segments, info = model.transcribe(
            self.video_file,
            language=self.language if self.language != 'auto' else None,
            word_timestamps=True,
            beam_size=5,
            vad_filter=True,
            vad_parameters=dict(
                threshold=0.5,
                min_speech_duration_ms=250,
                max_speech_duration_s=float('inf'),
                min_silence_duration_ms=2000,
                speech_pad_ms=400
            )
        )
        transcribe_time = time.time() - start_time
        
        self.progress.emit(f'âœ… è¯†åˆ«å®Œæˆï¼æ£€æµ‹è¯­è¨€: {info.language} (è€—æ—¶: {transcribe_time:.1f}ç§’)')
        self.progress.emit('ğŸ“Š æ”¶é›†è¯çº§æ—¶é—´æˆ³...')
        
        # æ”¶é›†æ‰€æœ‰è¯
        all_words = []
        segment_count = 0
        for segment in segments:
            segment_count += 1
            if segment_count % 10 == 0:
                self.progress.emit(f'   å¤„ç†ç‰‡æ®µ: {segment_count}...')
            
            if hasattr(segment, 'words') and segment.words:
                for word in segment.words:
                    all_words.append({
                        'word': word.word,
                        'start': word.start,
                        'end': word.end
                    })
        
        if not all_words:
            self.error.emit('æœªæ£€æµ‹åˆ°ä»»ä½•è¯­éŸ³å†…å®¹')
            return None, None
        
        self.progress.emit(f'âœ… æ”¶é›†å®Œæˆï¼å…± {len(all_words)} ä¸ªè¯')
        
        return all_words, info.language
    
    # ========== LLM åˆ†å‰²æ–¹æ³• ==========
    
    def llm_split_simple(self, text):
        """ç®€å•çš„ LLM åˆ†å‰²ï¼ˆç”¨äºä»…SRTæ¨¡å¼ï¼‰- æ”¯æŒåˆ†æ®µå¤„ç†å’Œä¸¥æ ¼éªŒè¯"""
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ†æ®µå¤„ç†
        word_count = len(text.split())
        
        if self.enable_chunking and word_count > self.chunk_size:
            self.progress.emit(f"ğŸ“Š æ–‡æœ¬è¾ƒé•¿ ({word_count} è¯)ï¼Œå¯ç”¨åˆ†æ®µå¤„ç†æ¨¡å¼")
            self.progress.emit(f"   åˆ†æ®µå¤§å°: {self.chunk_size} è¯/æ®µ")
            return self._llm_split_chunked(text)
        else:
            self.progress.emit(f"ğŸ“Š æ–‡æœ¬é•¿åº¦é€‚ä¸­ ({word_count} è¯)ï¼Œä½¿ç”¨å•æ¬¡å¤„ç†")
            return self._llm_split_single(text)
    
    def _llm_split_single(self, text):
        """å•æ¬¡å¤„ç†æ•´ä¸ªæ–‡æœ¬"""
        prompt = f"""You are a professional subtitle editor following industry standards (BBC, Netflix, TED).

TEXT TO SPLIT:
{text}

PRINCIPLES (in order of importance):

1. **SEMANTIC COMPLETENESS**: Each subtitle should express a complete thought
   - Don't break in the middle of phrases or clauses
   - Keep grammatical structures intact
   - A subtitle should be understandable on its own

2. **NATURAL BREAKING POINTS**: Split at logical pauses
   - Priority 1: Sentence endings (periods, question marks)
   - Priority 2: Major punctuation (commas, semicolons, dashes)
   - Priority 3: Conjunctions (and, but, because, when, if)

3. **READING COMFORT**:
   - For English: typically 6-12 words (flexible!)
   - Shorter (3-5 words) OK if complete
   - Longer (up to 15 words) OK if indivisible
   - Reading time: 1-2 seconds per subtitle

4. **NATURAL VARIETY**: Don't make every subtitle the same length

âš ï¸ CRITICAL: DO NOT modify, correct, or rewrite any words. Keep the text EXACTLY as written.

EXAMPLES:

âŒ BAD (breaks meaning):
1. "One of my earliest memories is"
2. "of trying to wake up"
3. "one of my relatives"

âœ… GOOD (preserves meaning):
1. "One of my earliest memories"
2. "is of trying to wake up one of my relatives"

OR:
1. "One of my earliest memories is of trying to wake up one of my relatives"

OUTPUT FORMAT:
Return ONLY a JSON array. Each element should be a string (the subtitle text).

Example:
["First complete thought here", "Second complete thought", "Third one"]

DO NOT include explanations, only return the JSON array.

REMEMBER: 
1. Copy text EXACTLY - do not fix grammar or spelling
2. Semantic completeness is MORE important than exact word counts."""
        
        try:
            self.progress.emit("   ğŸ“¡ æ­£åœ¨è°ƒç”¨ LLM API...")
            
            if self.llm_provider == 'siliconflow':
                response = self._call_siliconflow_stream(prompt)
            elif self.llm_provider == 'openai':
                response = self._call_openai_stream(prompt)
            elif self.llm_provider == 'claude':
                response = self._call_claude_stream(prompt)
            elif self.llm_provider == 'deepseek':
                response = self._call_deepseek_stream(prompt)
            else:
                response = self._call_siliconflow_stream(prompt)
            
            self.progress.emit("\n   âœ… LLM å“åº”å®Œæˆ")
            
            # è§£æå“åº”
            segments = self._parse_simple_response(response)
            
            # ä¸¥æ ¼éªŒè¯
            if self.enable_strict_validation and segments:
                segments = self._validate_text_integrity(text, segments)
            
            return segments
            
        except Exception as e:
            self.progress.emit(f"\n   âŒ LLM è°ƒç”¨å¤±è´¥: {str(e)}") 
            raise
    
    def _llm_split_chunked(self, text):
        """åˆ†æ®µå¤„ç†é•¿æ–‡æœ¬"""
        # æŒ‰å¥å­åˆ†å‰²
        sentences = self._split_into_sentences(text)
        
        if not sentences:
            self.progress.emit("   âš ï¸  æ— æ³•åˆ†å‰²å¥å­ï¼Œå›é€€åˆ°å•æ¬¡å¤„ç†")
            return self._llm_split_single(text)
        
        self.progress.emit(f"   âœ‚ï¸  åˆ†å‰²ä¸º {len(sentences)} ä¸ªå¥å­")
        
        # å°†å¥å­ç»„åˆæˆchunks
        chunks = []
        current_chunk = []
        current_word_count = 0
        
        for sentence in sentences:
            sentence_words = len(sentence.split())
            
            if current_word_count + sentence_words > self.chunk_size and current_chunk:
                # å½“å‰chunkå·²æ»¡ï¼Œä¿å­˜å¹¶å¼€å§‹æ–°chunk
                chunks.append(' '.join(current_chunk))
                current_chunk = [sentence]
                current_word_count = sentence_words
            else:
                current_chunk.append(sentence)
                current_word_count += sentence_words
        
        # æ·»åŠ æœ€åä¸€ä¸ªchunk
        if current_chunk:
            chunks.append(' '.join(current_chunk))
        
        self.progress.emit(f"   ğŸ“¦ ç»„åˆä¸º {len(chunks)} ä¸ªå¤„ç†å—")
        
        # å¤„ç†æ¯ä¸ªchunk
        all_segments = []
        for i, chunk in enumerate(chunks, 1):
            self.progress.emit(f"\n   ğŸ”„ å¤„ç†ç¬¬ {i}/{len(chunks)} å— ({len(chunk.split())} è¯)...")
            
            try:
                chunk_segments = self._llm_split_single(chunk)
                if chunk_segments:
                    all_segments.extend(chunk_segments)
                    self.progress.emit(f"   âœ… ç¬¬ {i} å—å®Œæˆï¼Œç”Ÿæˆ {len(chunk_segments)} ä¸ªç‰‡æ®µ")
                else:
                    self.progress.emit(f"   âš ï¸  ç¬¬ {i} å—å¤„ç†å¤±è´¥ï¼Œè·³è¿‡")
            except Exception as e:
                self.progress.emit(f"   âŒ ç¬¬ {i} å—é”™è¯¯: {str(e)}")
                continue
        
        self.progress.emit(f"\n   âœ… åˆ†æ®µå¤„ç†å®Œæˆï¼å…± {len(all_segments)} ä¸ªç‰‡æ®µ")
        return all_segments
    
    def _split_into_sentences(self, text):
        """å°†æ–‡æœ¬åˆ†å‰²æˆå¥å­"""
        import re
        
        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æŒ‰æ ‡ç‚¹åˆ†å‰²
        # ä¿ç•™æ ‡ç‚¹ç¬¦å·
        pattern = r'([.!?]+[\s]|[ã€‚ï¼ï¼Ÿ]+)'
        parts = re.split(pattern, text)
        
        sentences = []
        current = ''
        
        for part in parts:
            current += part
            if re.match(pattern, part):
                # é‡åˆ°å¥å­ç»“æŸç¬¦
                sentences.append(current.strip())
                current = ''
        
        # æ·»åŠ å‰©ä½™éƒ¨åˆ†
        if current.strip():
            sentences.append(current.strip())
        
        return [s for s in sentences if s]
    
    def _validate_text_integrity(self, original_text, segments):
        """éªŒè¯LLMæ˜¯å¦ä¿®æ”¹äº†åŸæ–‡"""
        self.progress.emit("   ğŸ” éªŒè¯æ–‡æœ¬å®Œæ•´æ€§...")
        
        # é‡å»ºæ–‡æœ¬
        reconstructed = ' '.join(segments)
        
        # æ ‡å‡†åŒ–æ¯”è¾ƒï¼ˆå¿½ç•¥å¤šä½™ç©ºæ ¼å’Œæ ‡ç‚¹ï¼‰
        def normalize(text):
            text = text.lower()
            text = re.sub(r'\s+', ' ', text)
            text = text.strip()
            return text
        
        original_norm = normalize(original_text)
        reconstructed_norm = normalize(reconstructed)
        
        # è®¡ç®—ç›¸ä¼¼åº¦
        similarity = difflib.SequenceMatcher(None, original_norm, reconstructed_norm).ratio()
        
        self.progress.emit(f"   ğŸ“Š æ–‡æœ¬ç›¸ä¼¼åº¦: {similarity*100:.1f}%")
        
        if similarity < 0.95:
            self.progress.emit("   âš ï¸  è­¦å‘Š: LLM ä¿®æ”¹äº†éƒ¨åˆ†å•è¯ï¼")
            self.progress.emit(f"   åŸæ–‡é•¿åº¦: {len(original_text)} å­—ç¬¦")
            self.progress.emit(f"   è¿”å›é•¿åº¦: {len(reconstructed)} å­—ç¬¦")
            
            # æ˜¾ç¤ºå·®å¼‚
            diff = difflib.unified_diff(
                original_norm.split()[:20], 
                reconstructed_norm.split()[:20],
                lineterm='',
                n=0
            )
            diff_lines = list(diff)[2:]  # è·³è¿‡å¤´éƒ¨
            if diff_lines:
                self.progress.emit("   å·®å¼‚ç¤ºä¾‹ï¼ˆå‰20è¯ï¼‰:")
                for line in diff_lines[:5]:
                    self.progress.emit(f"      {line}")
            
            # è¯¢é—®æ˜¯å¦ç»§ç»­
            self.progress.emit("   ğŸ’¡ æç¤º: å»ºè®®ä½¿ç”¨æ›´å¥½çš„æ¨¡å‹æˆ–è°ƒæ•´å‚æ•°")
        else:
            self.progress.emit("   âœ… æ–‡æœ¬å®Œæ•´æ€§éªŒè¯é€šè¿‡")
        
        return segments
    
    def llm_smart_split(self, words, detected_language, original_text=None):
        """ä½¿ç”¨ LLM è¿›è¡Œæ™ºèƒ½æ–­å¥ï¼ˆåŸºäºè¯çº§æ—¶é—´æˆ³ï¼‰- æ”¯æŒåˆ†æ®µå¤„ç†"""
        if not words:
            return []
        
        # å¦‚æœæœ‰åŸå§‹æ–‡æœ¬ï¼Œä½¿ç”¨åŸå§‹æ–‡æœ¬ï¼›å¦åˆ™ä½¿ç”¨è¯†åˆ«çš„æ–‡æœ¬
        reference_text = original_text if original_text else ''.join([w['word'] for w in words])
        
        self.progress.emit(f'   LLMæä¾›å•†: {self.llm_provider}')
        self.progress.emit(f'   LLMæ¨¡å‹: {self.llm_model}')
        self.progress.emit(f'   å¤„ç†æ–‡æœ¬: {len(words)} è¯')
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ†æ®µå¤„ç†
        if self.enable_chunking and len(words) > self.chunk_size:
            self.progress.emit(f"ğŸ“Š è¯æ•°è¾ƒå¤š ({len(words)} è¯)ï¼Œå¯ç”¨åˆ†æ®µå¤„ç†")
            self.progress.emit(f"   åˆ†æ®µå¤§å°: {self.chunk_size} è¯/æ®µ")
            return self._llm_smart_split_chunked(words, detected_language, reference_text)
        else:
            self.progress.emit(f"ğŸ“Š è¯æ•°é€‚ä¸­ ({len(words)} è¯)ï¼Œä½¿ç”¨å•æ¬¡å¤„ç†")
            return self._llm_smart_split_single(words, detected_language, reference_text)
    
    def _llm_smart_split_single(self, words, detected_language, reference_text):
        """å•æ¬¡å¤„ç†æ‰€æœ‰è¯"""
        # æ„å»º prompt
        prompt = self._build_llm_prompt(reference_text, len(words), detected_language)
        
        self.progress.emit('   â³ æ­£åœ¨è°ƒç”¨ LLM APIï¼Œè¯·ç¨å€™...')
        
        # è°ƒç”¨ LLMï¼ˆæ”¯æŒæµå¼ä¼ è¾“ï¼‰
        start_time = time.time()
        try:
            self.progress.emit('   ğŸ“¡ LLM å“åº”æµ:')
            response = self._call_llm_stream(prompt, reference_text)
            llm_time = time.time() - start_time
            self.progress.emit(f'\n   âœ… LLMå“åº”å®Œæˆ (è€—æ—¶: {llm_time:.1f}ç§’)')
        except Exception as e:
            self.progress.emit(f'   âš ï¸  LLMè°ƒç”¨å¤±è´¥: {str(e)}')
            self.progress.emit('   å›é€€åˆ°è§„åˆ™å¼•æ“æ–­å¥')
            return self.fallback_split(words)
        
        # è§£æ LLM è¿”å›çš„æ–­å¥ç»“æœ
        self.progress.emit('   ğŸ“‹ è§£æ LLM è¿”å›ç»“æœ...')
        subtitles = self._parse_llm_response(response, words)
        
        if not subtitles:
            self.progress.emit('   âš ï¸  LLMè¿”å›æ ¼å¼é”™è¯¯ï¼Œå›é€€åˆ°è§„åˆ™å¼•æ“')
            return self.fallback_split(words)
        
        self.progress.emit(f'   âœ… è§£æå®Œæˆï¼Œç”Ÿæˆ {len(subtitles)} æ¡å­—å¹•')
        
        # ä¸¥æ ¼éªŒè¯ï¼ˆæ£€æŸ¥æ˜¯å¦ä¿®æ”¹äº†å•è¯ï¼‰
        if self.enable_strict_validation:
            subtitles = self._validate_subtitle_text_integrity(reference_text, subtitles)
        
        # éªŒè¯å’Œè°ƒæ•´æ—¶é—´æˆ³
        self.progress.emit('   ğŸ”§ éªŒè¯å’Œè°ƒæ•´æ—¶é—´æˆ³...')
        subtitles = self._validate_and_adjust_timestamps(subtitles)
        
        self.progress.emit('   âœ… æ—¶é—´æˆ³è°ƒæ•´å®Œæˆ')
        
        return subtitles
    
    def _llm_smart_split_chunked(self, words, detected_language, reference_text):
        """åˆ†æ®µå¤„ç†è¯çº§æ—¶é—´æˆ³"""
        # å°†wordsåˆ†æˆå¤šä¸ªchunks
        chunks = []
        current_chunk = []
        
        for i, word in enumerate(words):
            current_chunk.append(word)
            
            if len(current_chunk) >= self.chunk_size:
                chunks.append(current_chunk)
                current_chunk = []
        
        # æ·»åŠ å‰©ä½™çš„è¯
        if current_chunk:
            chunks.append(current_chunk)
        
        self.progress.emit(f"   ğŸ“¦ åˆ†ä¸º {len(chunks)} ä¸ªå¤„ç†å—")
        
        # å¤„ç†æ¯ä¸ªchunk
        all_subtitles = []
        
        for i, chunk_words in enumerate(chunks, 1):
            self.progress.emit(f"\n   ğŸ”„ å¤„ç†ç¬¬ {i}/{len(chunks)} å— ({len(chunk_words)} è¯)...")
            
            # æ„å»ºè¿™ä¸ªchunkçš„æ–‡æœ¬
            chunk_text = ''.join([w['word'] for w in chunk_words])
            
            try:
                chunk_subtitles = self._llm_smart_split_single(chunk_words, detected_language, chunk_text)
                if chunk_subtitles:
                    all_subtitles.extend(chunk_subtitles)
                    self.progress.emit(f"   âœ… ç¬¬ {i} å—å®Œæˆï¼Œç”Ÿæˆ {len(chunk_subtitles)} æ¡å­—å¹•")
                else:
                    self.progress.emit(f"   âš ï¸  ç¬¬ {i} å—å¤„ç†å¤±è´¥ï¼Œä½¿ç”¨è§„åˆ™å¼•æ“")
                    fallback_subs = self.fallback_split(chunk_words)
                    if fallback_subs:
                        all_subtitles.extend(fallback_subs)
            except Exception as e:
                self.progress.emit(f"   âŒ ç¬¬ {i} å—é”™è¯¯: {str(e)}")
                # ä½¿ç”¨è§„åˆ™å¼•æ“ä½œä¸ºåå¤‡
                fallback_subs = self.fallback_split(chunk_words)
                if fallback_subs:
                    all_subtitles.extend(fallback_subs)
        
        self.progress.emit(f"\n   âœ… åˆ†æ®µå¤„ç†å®Œæˆï¼å…± {len(all_subtitles)} æ¡å­—å¹•")
        
        # æœ€ç»ˆéªŒè¯å’Œè°ƒæ•´
        self.progress.emit('   ğŸ”§ æœ€ç»ˆæ—¶é—´æˆ³è°ƒæ•´...')
        all_subtitles = self._validate_and_adjust_timestamps(all_subtitles)
        
        return all_subtitles
    
    def _validate_subtitle_text_integrity(self, original_text, subtitles):
        """éªŒè¯å­—å¹•æ–‡æœ¬æ˜¯å¦è¢«LLMä¿®æ”¹"""
        self.progress.emit("   ğŸ” éªŒè¯å­—å¹•æ–‡æœ¬å®Œæ•´æ€§...")
        
        # é‡å»ºæ–‡æœ¬
        reconstructed = ' '.join([sub['text'] for sub in subtitles])
        
        # æ ‡å‡†åŒ–æ¯”è¾ƒ
        def normalize(text):
            text = text.lower()
            text = re.sub(r'\s+', ' ', text)
            text = text.strip()
            return text
        
        original_norm = normalize(original_text)
        reconstructed_norm = normalize(reconstructed)
        
        # è®¡ç®—ç›¸ä¼¼åº¦
        similarity = difflib.SequenceMatcher(None, original_norm, reconstructed_norm).ratio()
        
        self.progress.emit(f"   ğŸ“Š æ–‡æœ¬ç›¸ä¼¼åº¦: {similarity*100:.1f}%")
        
        if similarity < 0.90:
            self.progress.emit("   âš ï¸  è­¦å‘Š: LLM ä¿®æ”¹äº†éƒ¨åˆ†å•è¯ï¼")
            self.progress.emit(f"   åŸæ–‡é•¿åº¦: {len(original_text)} å­—ç¬¦")
            self.progress.emit(f"   è¿”å›é•¿åº¦: {len(reconstructed)} å­—ç¬¦")
            
            # æ˜¾ç¤ºå·®å¼‚ç¤ºä¾‹
            diff = difflib.unified_diff(
                original_norm.split()[:30], 
                reconstructed_norm.split()[:30],
                lineterm='',
                n=0
            )
            diff_lines = list(diff)[2:]
            if diff_lines:
                self.progress.emit("   å·®å¼‚ç¤ºä¾‹ï¼ˆå‰30è¯ï¼‰:")
                for line in diff_lines[:8]:
                    self.progress.emit(f"      {line}")
            
            self.progress.emit("   ğŸ’¡ æç¤º: è€ƒè™‘æ¢ç”¨æ›´å¥½çš„æ¨¡å‹æˆ–å¯ç”¨åˆ†æ®µå¤„ç†")
        else:
            self.progress.emit("   âœ… æ–‡æœ¬å®Œæ•´æ€§éªŒè¯é€šè¿‡")
        
        return subtitles
    
    def _build_llm_prompt(self, text, word_count, language):
        """æ„å»º LLM prompt - æˆç†Ÿç‰ˆï¼Œå¹³è¡¡è¯­ä¹‰å®Œæ•´æ€§å’Œå¯è¯»æ€§"""
        lang_name = {
            'en': 'English',
            'zh': 'Chinese',
            'ja': 'Japanese',
            'ko': 'Korean',
            'es': 'Spanish',
            'fr': 'French',
            'de': 'German',
            'ru': 'Russian'
        }.get(language, 'English')

        prompt = f"""You are a subtitle splitter. Your ONLY task is to split long text into shorter subtitle segments.

âš ï¸ CRITICAL RULES (MUST FOLLOW):
1. DO NOT modify, correct, or rewrite any words in the original text
2. DO NOT fix grammar, spelling, or punctuation errors
3. DO NOT rearrange or paraphrase the content
4. ONLY split the text - keep every word exactly as it appears

TEXT TO SPLIT:
{text}

SPLITTING GUIDELINES:

Target Length: ~10 words per subtitle (flexible: 7-13 words is fine)

Split Priority:
1. At sentence endings (. ? ! )
2. At major punctuation (, ; : â€” )
3. At conjunctions (and, but, so, because, when, if)
4. Keep complete phrases together (don't split subject-verb-object)

EXAMPLES:

âŒ BAD - Breaks meaning:
"One of my earliest memories is"
"of trying to wake up"

âœ… GOOD - Complete thoughts:
"One of my earliest memories"
"is of trying to wake up one of my relatives"

âŒ BAD - Too mechanical:
"And I've been thinking about"
"it a lot lately, partly"
"because it's now exactly 100"

âœ… GOOD - Natural splits:
"And I've been thinking about it a lot lately,"
"partly because it's now exactly 100 years"
"since drugs were first banned"

OUTPUT FORMAT (JSON only, no explanations):
[
  {{"text": "exact text from original", "word_count": 5}},
  {{"text": "next segment", "word_count": 10}}
]

REMINDER: Copy the text EXACTLY as written. Do not change anything - just split it into readable segments."""

        return prompt
    
    def _call_llm_stream(self, prompt, words_text):
        """è°ƒç”¨ LLM APIï¼ˆæµå¼ä¼ è¾“ï¼‰- ä¸¥æ ¼æŒ‰ç…§ä¸»é¡¹ç›®å®ç°"""
        import requests
        import json
        
        if self.llm_provider == 'openai':
            return self._stream_openai(prompt)
        elif self.llm_provider == 'anthropic':
            return self._stream_anthropic(prompt)
        elif self.llm_provider == 'deepseek':
            return self._stream_deepseek(prompt)
        elif self.llm_provider == 'siliconflow':
            return self._stream_siliconflow(prompt)
        elif self.llm_provider == 'local':
            return self._stream_local_llm(prompt)
        else:
            raise ValueError(f'ä¸æ”¯æŒçš„ LLM æä¾›å•†: {self.llm_provider}')
    
    def _stream_siliconflow(self, prompt):
        """è°ƒç”¨ SiliconFlow API (æµå¼ä¼ è¾“) - ä¸¥æ ¼æŒ‰ç…§ä¸»é¡¹ç›®å®ç°"""
        import requests
        
        url = 'https://api.siliconflow.cn/v1/chat/completions'
        headers = {
            'Authorization': f'Bearer {self.llm_api_key}',
            'Content-Type': 'application/json'
        }
        data = {
            'model': self.llm_model if self.llm_model else 'Qwen/Qwen2.5-7B-Instruct',
            'messages': [
                {'role': 'system', 'content': 'You are an expert subtitle editor.'},
                {'role': 'user', 'content': prompt}
            ],
            'temperature': 0.3,
            'stream': True
        }
        
        response = requests.post(url, headers=headers, json=data, stream=True, timeout=120)
        response.raise_for_status()
        
        full_content = []
        for line in response.iter_lines():
            if not line:
                continue
            
            line = line.decode('utf-8')
            if line.startswith('data: '):
                data_str = line[6:]
                if data_str == '[DONE]':
                    break
                
                try:
                    chunk = json.loads(data_str)
                    if 'choices' in chunk and len(chunk['choices']) > 0:
                        delta = chunk['choices'][0].get('delta', {})
                        content = delta.get('content', '')
                        if content:
                            full_content.append(content)
                            self.stream.emit(content)
                except json.JSONDecodeError:
                    continue
        
        return ''.join(full_content)
    
    def _stream_openai(self, prompt):
        """è°ƒç”¨ OpenAI API (æµå¼ä¼ è¾“) - ä¸¥æ ¼æŒ‰ç…§ä¸»é¡¹ç›®å®ç°"""
        import requests
        
        url = self.llm_base_url if self.llm_base_url else 'https://api.openai.com/v1/chat/completions'
        headers = {
            'Authorization': f'Bearer {self.llm_api_key}',
            'Content-Type': 'application/json'
        }
        data = {
            'model': self.llm_model,
            'messages': [
                {'role': 'system', 'content': 'You are an expert subtitle editor.'},
                {'role': 'user', 'content': prompt}
            ],
            'temperature': 0.3,
            'stream': True
        }
        
        response = requests.post(url, headers=headers, json=data, stream=True, timeout=120)
        response.raise_for_status()
        
        full_content = []
        for line in response.iter_lines():
            if not line:
                continue
            
            line = line.decode('utf-8')
            if line.startswith('data: '):
                data_str = line[6:]
                if data_str == '[DONE]':
                    break
                
                try:
                    chunk = json.loads(data_str)
                    if 'choices' in chunk and len(chunk['choices']) > 0:
                        delta = chunk['choices'][0].get('delta', {})
                        content = delta.get('content', '')
                        if content:
                            full_content.append(content)
                            self.stream.emit(content)
                except json.JSONDecodeError:
                    continue
        
        return ''.join(full_content)
    
    def _stream_anthropic(self, prompt):
        """è°ƒç”¨ Anthropic Claude API (æµå¼ä¼ è¾“) - ä¸¥æ ¼æŒ‰ç…§ä¸»é¡¹ç›®å®ç°"""
        import requests
        
        url = 'https://api.anthropic.com/v1/messages'
        headers = {
            'x-api-key': self.llm_api_key,
            'anthropic-version': '2023-06-01',
            'Content-Type': 'application/json'
        }
        data = {
            'model': self.llm_model,
            'max_tokens': 4096,
            'messages': [{'role': 'user', 'content': prompt}],
            'temperature': 0.3,
            'stream': True
        }
        
        response = requests.post(url, headers=headers, json=data, stream=True, timeout=120)
        response.raise_for_status()
        
        full_content = []
        for line in response.iter_lines():
            if not line:
                continue
            
            line = line.decode('utf-8')
            if line.startswith('data: '):
                data_str = line[6:]
                
                try:
                    chunk = json.loads(data_str)
                    if chunk.get('type') == 'content_block_delta':
                        delta = chunk.get('delta', {})
                        content = delta.get('text', '')
                        if content:
                            full_content.append(content)
                            self.stream.emit(content)
                except json.JSONDecodeError:
                    continue
        
        return ''.join(full_content)
    
    def _stream_deepseek(self, prompt):
        """è°ƒç”¨ DeepSeek API (æµå¼ä¼ è¾“) - ä¸¥æ ¼æŒ‰ç…§ä¸»é¡¹ç›®å®ç°"""
        import requests
        
        url = 'https://api.deepseek.com/v1/chat/completions'
        headers = {
            'Authorization': f'Bearer {self.llm_api_key}',
            'Content-Type': 'application/json'
        }
        data = {
            'model': self.llm_model,
            'messages': [
                {'role': 'system', 'content': 'You are an expert subtitle editor.'},
                {'role': 'user', 'content': prompt}
            ],
            'temperature': 0.3,
            'stream': True
        }
        
        response = requests.post(url, headers=headers, json=data, stream=True, timeout=120)
        response.raise_for_status()
        
        full_content = []
        for line in response.iter_lines():
            if not line:
                continue
            
            line = line.decode('utf-8')
            if line.startswith('data: '):
                data_str = line[6:]
                if data_str == '[DONE]':
                    break
                
                try:
                    chunk = json.loads(data_str)
                    if 'choices' in chunk and len(chunk['choices']) > 0:
                        delta = chunk['choices'][0].get('delta', {})
                        content = delta.get('content', '')
                        if content:
                            full_content.append(content)
                            self.stream.emit(content)
                except json.JSONDecodeError:
                    continue
        
        return ''.join(full_content)
    
    def _stream_local_llm(self, prompt):
        """è°ƒç”¨æœ¬åœ° LLM (Ollama ç­‰ï¼Œæµå¼ä¼ è¾“) - ä¸¥æ ¼æŒ‰ç…§ä¸»é¡¹ç›®å®ç°"""
        import requests
        import json
        
        url = self.llm_base_url if self.llm_base_url else 'http://localhost:11434/api/generate'
        
        data = {
            'model': self.llm_model,
            'prompt': prompt,
            'stream': True
        }
        
        response = requests.post(url, json=data, stream=True, timeout=120)
        response.raise_for_status()
        
        full_content = []
        
        for line in response.iter_lines():
            if not line:
                continue
            
            try:
                chunk = json.loads(line)
                if 'response' in chunk:
                    content = chunk['response']
                    if content:
                        full_content.append(content)
                        self.stream.emit(content)
                
                if chunk.get('done', False):
                    break
            except json.JSONDecodeError:
                continue
        
        return ''.join(full_content)
    
    def _parse_simple_response(self, response):
        """è§£æç®€å•çš„ LLM è¿”å›ï¼ˆå­—ç¬¦ä¸²æ•°ç»„ï¼‰"""
        # æå– JSON æ•°ç»„
        json_match = re.search(r'\[.*\]', response, re.DOTALL)
        if not json_match:
            return []
        
        try:
            segments = json.loads(json_match.group(0))
            if isinstance(segments, list):
                return [s.strip() for s in segments if isinstance(s, str) and s.strip()]
        except json.JSONDecodeError:
            pass
        
        return []
    
    def _parse_llm_response(self, response, words):
        """è§£æ LLM è¿”å›çš„ç»“æœï¼ˆå¯¹è±¡æ•°ç»„ï¼‰"""
        # å°è¯•æå– JSON
        json_match = re.search(r'\[.*\]', response, re.DOTALL)
        if not json_match:
            return []
        
        try:
            segments = json.loads(json_match.group(0))
        except json.JSONDecodeError:
            return []
        
        if not isinstance(segments, list):
            return []
        
        # å°† LLM è¿”å›çš„æ–‡æœ¬æ®µåŒ¹é…åˆ°è¯çº§æ—¶é—´æˆ³
        subtitles = []
        word_idx = 0
        skipped_count = 0
        
        for i, segment in enumerate(segments):
            if not isinstance(segment, dict) or 'text' not in segment:
                continue
            
            segment_text = segment['text'].strip()
            if not segment_text:
                continue
            
            # ä½¿ç”¨å¢å¼ºçš„åŒ¹é…ç­–ç•¥
            # å¦‚æœæ¥è¿‘å°¾éƒ¨ï¼Œæ”¾å®½åŒ¹é…æ¡ä»¶
            remaining_segments = len(segments) - i
            remaining_words = len(words) - word_idx
            is_near_end = remaining_words < remaining_segments * 5
            
            match_result = self._match_text_to_words(segment_text, words, word_idx, relax=is_near_end)
            
            if match_result:
                subtitle = {
                    'start': match_result['start'],
                    'end': match_result['end'],
                    'text': segment_text
                }
                subtitles.append(subtitle)
                word_idx = match_result['next_idx']
                
                # é‡ç½®è·³è¿‡è®¡æ•°
                skipped_count = 0
            else:
                skipped_count += 1
                self.progress.emit(f'   âš ï¸  Segment {i+1} æ— æ³•åŒ¹é…ï¼ˆå·²è·³è¿‡ {skipped_count} ä¸ªï¼‰')
                self.progress.emit(f'      å½“å‰ word_idx: {word_idx}/{len(words)}')
                self.progress.emit(f'      æ–‡æœ¬: "{segment_text[:50]}..."')
                
                # æ˜¾ç¤ºå½“å‰ä½ç½®çš„è¯ï¼Œå¸®åŠ©è¯Šæ–­
                if word_idx < len(words):
                    nearby_words = []
                    for j in range(word_idx, min(word_idx + 5, len(words))):
                        nearby_words.append(words[j]['word'])
                    self.progress.emit(f'      é™„è¿‘çš„è¯: {" ".join(nearby_words)}')
                
                # å¦‚æœè¿ç»­è·³è¿‡å¤ªå¤šï¼Œå¼ºåˆ¶æ¨è¿› word_idx
                if skipped_count >= 3 and word_idx < len(words) - 10:
                    # åŸºäºè¿›åº¦æ¯”ä¾‹æ¨è¿›
                    progress_ratio = (i + 1) / len(segments)
                    target_idx = int(len(words) * progress_ratio)
                    jump = max(10, target_idx - word_idx)
                    word_idx = min(word_idx + jump, len(words) - 10)
                    self.progress.emit(f'      â†’ åŸºäºè¿›åº¦æ¨è¿› word_idx åˆ° {word_idx} (è·³è·ƒ{jump}ä¸ªè¯)')
                    skipped_count = 0
        
        self.progress.emit(f'   ğŸ“Š æˆåŠŸåŒ¹é…: {len(subtitles)}/{len(segments)} ä¸ª segments')
        return subtitles
    
    def _match_text_to_words(self, text, words, start_idx, relax=False):
        """
        å¢å¼ºçš„æ–‡æœ¬åˆ°å•è¯æ—¶é—´æˆ³åŒ¹é…ç®—æ³• - ä¿®å¤ç‰ˆ

        æ”¯æŒï¼š
        1. ç¼ºå¤±è¯çš„å¤„ç†ï¼ˆWhisper æœªè¯†åˆ«çš„è¯ï¼‰
        2. æ—¶é—´æˆ³æ’å€¼ä¼°ç®—
        3. æ›´æ™ºèƒ½çš„åºåˆ—å¯¹é½
        4. â­ æ—¶é—´æˆ³è¿ç»­æ€§æ£€æŸ¥ï¼ˆä¿®å¤æ—¶é—´è·³è·ƒé—®é¢˜ï¼‰

        Args:
            text: è¦åŒ¹é…çš„æ–‡æœ¬
            words: è¯çº§æ—¶é—´æˆ³åˆ—è¡¨
            start_idx: å¼€å§‹ç´¢å¼•
            relax: æ˜¯å¦æ”¾å®½åŒ¹é…æ¡ä»¶ï¼ˆç”¨äºå°¾éƒ¨segmentsï¼‰
        """
        import re

        # æ¸…ç†å’Œåˆ†è¯
        text_clean = text.lower()
        for punct in [',', '.', '!', '?', ';', ':', '"', "'", '(', ')', '[', ']']:
            text_clean = text_clean.replace(punct, ' ')
        text_words = [w for w in text_clean.split() if w]

        if not text_words:
            return None

        # ä½¿ç”¨åŠ¨æ€è§„åˆ’è¿›è¡Œåºåˆ—å¯¹é½
        matched_indices = []
        text_idx = 0
        word_idx = start_idx
        max_lookahead = 10  # å‡å°å‰ç»èŒƒå›´ï¼Œé¿å…è·¨å¥åŒ¹é…

        while text_idx < len(text_words) and word_idx < len(words):
            text_word = text_words[text_idx]
            best_match = None
            best_score = 0
            best_offset = 0

            # åœ¨å½“å‰ä½ç½®é™„è¿‘æŸ¥æ‰¾æœ€ä½³åŒ¹é…
            for offset in range(min(max_lookahead, len(words) - word_idx)):
                if word_idx + offset >= len(words):
                    break

                word_data = words[word_idx + offset]
                word_text = word_data['word'].lower().strip()

                # æ¸…ç†å•è¯
                for punct in [',', '.', '!', '?', ';', ':', '"', "'", '(', ')', '[', ']']:
                    word_text = word_text.replace(punct, '')
                word_text = word_text.strip()

                if not word_text:
                    continue

                # è®¡ç®—åŒ¹é…åˆ†æ•°
                score = self._calculate_match_score(text_word, word_text)

                # è€ƒè™‘ä½ç½®å› ç´ ï¼ˆè¶Šè¿‘è¶Šå¥½ï¼‰
                score = score - (offset * 0.15)  # å¢åŠ ä½ç½®æƒ©ç½š

                # â­ æ–°å¢ï¼šæ—¶é—´æˆ³è¿ç»­æ€§æ£€æŸ¥
                if matched_indices and offset > 0:
                    prev_match_idx = matched_indices[-1]
                    prev_end_time = words[prev_match_idx]['end']
                    current_start_time = word_data['start']
                    time_gap = current_start_time - prev_end_time

                    # å¦‚æœæ—¶é—´é—´éš”è¿‡å¤§ï¼ˆ>1.5ç§’ï¼‰ï¼Œé™ä½åˆ†æ•°
                    if time_gap > 1.5:
                        score -= 0.4

                if score > best_score:
                    best_score = score
                    best_match = word_idx + offset
                    best_offset = offset

            # å¦‚æœæ‰¾åˆ°åŒ¹é…ï¼ˆé˜ˆå€¼ï¼š0.6ï¼Œæé«˜é˜ˆå€¼ï¼‰
            if best_score > 0.6:
                matched_indices.append(best_match)
                word_idx = best_match + 1
                text_idx += 1
            else:
                # æœªæ‰¾åˆ°åŒ¹é…ï¼Œå¯èƒ½æ˜¯ Whisper ç¼ºå¤±çš„è¯
                # è·³è¿‡è¿™ä¸ªæ–‡æœ¬è¯ï¼Œä½†ä¸ç§»åŠ¨ word_idx
                text_idx += 1

        if not matched_indices:
            return None

        # è·å–åŒ¹é…åˆ°çš„å•è¯çš„æ—¶é—´æˆ³
        matched_words = [words[i] for i in matched_indices]

        # â­ æ ¸å¿ƒæ”¹è¿›ï¼šè®¡ç®—èµ·æ­¢æ—¶é—´ï¼ˆå¸¦æ—¶é—´è·³è·ƒæ£€æµ‹ï¼‰
        start_time = matched_words[0]['start']
        end_time = self._calculate_robust_end_time(matched_words, text_words)

        # å¦‚æœåŒ¹é…ç‡å¤ªä½ï¼Œå°è¯•æ’å€¼ä¼°ç®—
        match_ratio = len(matched_indices) / len(text_words)
        if match_ratio < 0.6:
            if len(matched_indices) >= 2:
                # åŸºäºåŒ¹é…è¯çš„å¯†åº¦ä¼°ç®—æ€»æ—¶é•¿
                avg_word_duration = (matched_words[-1]['end'] - matched_words[0]['start']) / len(matched_indices)
                estimated_duration = avg_word_duration * len(text_words)

                # ä½¿ç”¨ä¼°ç®—å€¼å’Œæ£€æµ‹å€¼ä¸­çš„è¾ƒå°è€…
                end_time = min(end_time, start_time + estimated_duration)
            else:
                # åªæœ‰ä¸€ä¸ªåŒ¹é…è¯ï¼Œä½¿ç”¨é»˜è®¤ä¼°ç®—
                avg_duration_per_word = 0.3  # å‡è®¾æ¯è¯0.3ç§’
                end_time = start_time + (len(text_words) * avg_duration_per_word)

        # â­ è¾¹ç•Œæ£€æŸ¥ï¼šç¡®ä¿ç»“æŸæ—¶é—´ä¸ä¼šè¿‡åº¦å»¶ä¼¸
        max_reasonable_duration = len(text_words) * 0.8  # å‡è®¾æœ€å¿« 1.25 è¯/ç§’
        if (end_time - start_time) > max_reasonable_duration:
            end_time = start_time + max_reasonable_duration

        return {
            'start': start_time,
            'end': end_time,
            'next_idx': word_idx,
            'match_ratio': match_ratio  # ç”¨äºè°ƒè¯•
        }

    def _calculate_robust_end_time(self, matched_words, text_words):
        """
        è®¡ç®—ç¨³å¥çš„ç»“æŸæ—¶é—´ï¼ˆä¿®å¤æ—¶é—´è·³è·ƒé—®é¢˜ï¼‰

        ç­–ç•¥ï¼š
        1. æ£€æŸ¥åŒ¹é…è¯ä¹‹é—´çš„æ—¶é—´é—´éš”
        2. å¦‚æœå‘ç°å¤§è·³è·ƒï¼ˆ>1.5ç§’ï¼‰ï¼Œæˆªæ–­åœ¨è·³è·ƒä¹‹å‰
        3. å¦åˆ™ä½¿ç”¨æœ€åä¸€ä¸ªåŒ¹é…è¯çš„ç»“æŸæ—¶é—´
        """
        if len(matched_words) == 1:
            return matched_words[0]['end']

        # æ£€æŸ¥æ—¶é—´è¿ç»­æ€§
        for i in range(len(matched_words) - 1):
            current_end = matched_words[i]['end']
            next_start = matched_words[i + 1]['start']
            time_gap = next_start - current_end

            # å¦‚æœå‘ç°å¤§è·³è·ƒï¼ˆ>1.5ç§’ï¼‰ï¼Œæˆªæ–­
            if time_gap > 1.5:
                # æˆªæ–­åœ¨è·³è·ƒä¹‹å‰ï¼Œå¹¶æ·»åŠ å°ç¼“å†²
                return current_end + 0.2

        # æ²¡æœ‰å¤§è·³è·ƒï¼Œä½†ä»éœ€éªŒè¯æ€»æ—¶é•¿æ˜¯å¦åˆç†
        last_end = matched_words[-1]['end']
        first_start = matched_words[0]['start']
        total_duration = last_end - first_start

        # å¦‚æœæ€»æ—¶é•¿è¿‡é•¿ï¼ˆ> æ–‡æœ¬è¯æ•° * 1.0 ç§’ï¼‰ï¼Œå¯èƒ½æœ‰é—®é¢˜
        max_expected_duration = len(text_words) * 1.0
        if total_duration > max_expected_duration and len(matched_words) > 1:
            # ä½¿ç”¨å€’æ•°ç¬¬äºŒä¸ªè¯çš„ç»“æŸæ—¶é—´
            return matched_words[-2]['end'] + 0.3

        return last_end
    
    def _calculate_match_score(self, text_word, whisper_word):
        """
        è®¡ç®—ä¸¤ä¸ªè¯çš„åŒ¹é…åˆ†æ•°ï¼ˆä¸¥æ ¼æŒ‰ç…§ä¸»é¡¹ç›®å®ç°ï¼‰
        
        è¿”å›å€¼ï¼š0.0 - 1.0
        """
        if not text_word or not whisper_word:
            return 0.0
        
        # å®Œå…¨åŒ¹é…
        if text_word == whisper_word:
            return 1.0
        
        # ä¸€ä¸ªåŒ…å«å¦ä¸€ä¸ª
        if text_word in whisper_word or whisper_word in text_word:
            shorter = min(len(text_word), len(whisper_word))
            longer = max(len(text_word), len(whisper_word))
            return shorter / longer * 0.9
        
        # ä½¿ç”¨ç¼–è¾‘è·ç¦»
        distance = self._levenshtein_distance(text_word, whisper_word)
        max_len = max(len(text_word), len(whisper_word))
        
        if max_len == 0:
            return 0.0
        
        similarity = 1.0 - (distance / max_len)
        
        # åªæœ‰ç›¸ä¼¼åº¦è¶³å¤Ÿé«˜æ‰è®¤ä¸ºæ˜¯åŒ¹é…
        return similarity if similarity > 0.6 else 0.0
    
    def _levenshtein_distance(self, s1, s2):
        """è®¡ç®—ç¼–è¾‘è·ç¦»"""
        if len(s1) < len(s2):
            return self._levenshtein_distance(s2, s1)
        
        if len(s2) == 0:
            return len(s1)
        
        previous_row = range(len(s2) + 1)
        for i, c1 in enumerate(s1):
            current_row = [i + 1]
            for j, c2 in enumerate(s2):
                insertions = previous_row[j + 1] + 1
                deletions = current_row[j] + 1
                substitutions = previous_row[j] + (c1 != c2)
                current_row.append(min(insertions, deletions, substitutions))
            previous_row = current_row
        
        return previous_row[-1]
    
    def _validate_and_adjust_timestamps(self, subtitles):
        """éªŒè¯å’Œè°ƒæ•´æ—¶é—´æˆ³ - å¢å¼ºç‰ˆ"""
        if not subtitles:
            return []

        validated = []

        for i, sub in enumerate(subtitles):
            # ç¡®ä¿æ—¶é—´æˆ³åˆæ³•
            if sub['start'] >= sub['end']:
                sub['end'] = sub['start'] + 1.0

            # ç¡®ä¿ä¸ä¸å‰ä¸€æ¡é‡å 
            if i > 0 and sub['start'] < validated[-1]['end']:
                # æ·»åŠ å°é—´éš”ï¼ˆ100msï¼‰
                sub['start'] = validated[-1]['end'] + 0.1
                if sub['start'] >= sub['end']:
                    sub['end'] = sub['start'] + 1.0

            # â­ æ–°å¢ï¼šåŸºäºè¯æ•°çš„æ™ºèƒ½æŒç»­æ—¶é—´æ£€æŸ¥
            duration = sub['end'] - sub['start']
            word_count = len(sub['text'].split())

            # æ­£å¸¸è¯´è¯é€Ÿåº¦ï¼š2-4 è¯/ç§’ï¼ˆè‹±æ–‡ï¼‰
            min_expected_duration = word_count * 0.25  # æœ€å¿« 4 è¯/ç§’
            max_expected_duration = word_count * 1.0   # æœ€æ…¢ 1 è¯/ç§’

            if duration > max_expected_duration and word_count > 0:
                self.progress.emit(
                    f'   âš ï¸  å­—å¹• {i+1} æ—¶é•¿è¿‡é•¿ ({duration:.2f}sï¼Œ{word_count}è¯)ï¼Œ'
                    f'è°ƒæ•´ä¸º {max_expected_duration:.2f}s'
                )
                sub['end'] = sub['start'] + max_expected_duration
            elif duration < min_expected_duration and word_count > 0:
                # åªæœ‰åœ¨æŒç»­æ—¶é—´çœŸçš„å¤ªçŸ­æ—¶æ‰è°ƒæ•´
                if duration < 0.5:
                    self.progress.emit(
                        f'   âš ï¸  å­—å¹• {i+1} æ—¶é•¿è¿‡çŸ­ ({duration:.2f}sï¼Œ{word_count}è¯)ï¼Œ'
                        f'è°ƒæ•´ä¸º {max(min_expected_duration, 0.5):.2f}s'
                    )
                    sub['end'] = sub['start'] + max(min_expected_duration, 0.5)

            validated.append(sub)

        return validated
    
    def fallback_split(self, words):
        """å›é€€åˆ°è§„åˆ™å¼•æ“æ–­å¥ï¼ˆå½“LLMå¤±è´¥æ—¶ï¼‰- ä¸¥æ ¼æŒ‰ç…§ä¸»é¡¹ç›®å®ç°"""
        self.progress.emit('   ğŸ”„ ä½¿ç”¨è§„åˆ™å¼•æ“æ–­å¥...')
        
        # æ£€æŸ¥è¾“å…¥
        if not words or len(words) == 0:
            self.progress.emit('   âš ï¸  è¯åˆ—è¡¨ä¸ºç©ºï¼Œæ— æ³•æ–­å¥')
            return []
        
        try:
            # ä½¿ç”¨ç®€åŒ–çš„è§„åˆ™å¼•æ“
            subtitles = []
            current_words = []
            current_start = words[0]['start']
            
            sentence_ends = {'.', '!', '?', 'ã€‚', 'ï¼', 'ï¼Ÿ'}
            
            for i, word in enumerate(words):
                current_words.append(word)
                duration = word['end'] - current_start
                word_text = word['word'].strip()
                
                should_split = False
                
                # å¥å­ç»“æŸ
                if word_text and word_text[-1] in sentence_ends:
                    should_split = True
                # è¶…é™åˆ¶
                elif duration >= self.max_duration or len(current_words) >= self.max_words:
                    should_split = True
                
                if should_split and current_words:
                    subtitle = {
                        'start': current_start,
                        'end': current_words[-1]['end'],
                        'text': ''.join([w['word'] for w in current_words]).strip(),
                    }
                    subtitles.append(subtitle)
                    current_words = []
                    if i + 1 < len(words):
                        current_start = words[i + 1]['start']
            
            # å¤„ç†å‰©ä½™çš„è¯
            if current_words:
                subtitle = {
                    'start': current_start,
                    'end': current_words[-1]['end'],
                    'text': ''.join([w['word'] for w in current_words]).strip(),
                }
                subtitles.append(subtitle)
            
            self.progress.emit(f'   âœ… è§„åˆ™å¼•æ“ç”Ÿæˆ {len(subtitles)} æ¡å­—å¹•')
            return subtitles
            
        except Exception as e:
            self.progress.emit(f'   âŒ è§„åˆ™å¼•æ“å¤±è´¥: {str(e)}')
            import traceback
            self.progress.emit(f'   è¯¦ç»†é”™è¯¯: {traceback.format_exc()}')
            return []
    
    # ========== SRT æ–‡ä»¶å¤„ç†æ–¹æ³• ==========
    
    def parse_srt(self, srt_file):
        """è§£æ SRT æ–‡ä»¶"""
        try:
            with open(srt_file, 'r', encoding='utf-8') as f:
                content = f.read()
        except:
            try:
                with open(srt_file, 'r', encoding='utf-8-sig') as f:
                    content = f.read()
            except:
                return []
        
        pattern = r'(\d+)\s*\n(\d{2}:\d{2}:\d{2},\d{3})\s*-->\s*(\d{2}:\d{2}:\d{2},\d{3})\s*\n((?:.*\n)*?)(?:\n|$)'
        matches = re.findall(pattern, content)
        
        subtitles = []
        for match in matches:
            start_time = self.parse_timestamp(match[1])
            end_time = self.parse_timestamp(match[2])
            text = match[3].strip()
            
            if text:
                subtitles.append({
                    'start': start_time,
                    'end': end_time,
                    'text': text
                })
        
        return subtitles
    
    def parse_timestamp(self, timestamp_str):
        """å°† SRT æ—¶é—´æˆ³è½¬æ¢ä¸ºç§’"""
        match = re.match(r'(\d{2}):(\d{2}):(\d{2}),(\d{3})', timestamp_str)
        if match:
            h, m, s, ms = map(int, match.groups())
            return h * 3600 + m * 60 + s + ms / 1000.0
        return 0.0
    
    def map_timestamps(self, new_segments, original_subtitles):
        """å°†æ–°åˆ†æ®µæ˜ å°„åˆ°åŸå§‹å­—å¹•çš„æ—¶é—´æˆ³ï¼ˆç®€å•æ˜ å°„ï¼‰"""
        new_subtitles = []
        
        # æ„å»ºåŸå§‹æ–‡æœ¬
        original_text = ' '.join([sub['text'] for sub in original_subtitles])
        
        # ä¸ºæ¯ä¸ªæ–°åˆ†æ®µæ‰¾åˆ°åœ¨åŸå§‹æ–‡æœ¬ä¸­çš„ä½ç½®
        current_pos = 0
        
        for segment_text in new_segments:
            segment_lower = segment_text.lower().strip()
            original_lower = original_text[current_pos:].lower()
            
            # æŸ¥æ‰¾æœ€æ¥è¿‘çš„åŒ¹é…
            pos = original_lower.find(segment_lower[:min(20, len(segment_lower))])
            if pos == -1:
                continue
            
            actual_pos = current_pos + pos
            
            # æ‰¾åˆ°å¯¹åº”çš„æ—¶é—´æˆ³èŒƒå›´
            char_count = 0
            start_time = None
            end_time = None
            
            for sub in original_subtitles:
                sub_text = sub['text']
                if start_time is None and char_count + len(sub_text) >= actual_pos:
                    start_time = sub['start']
                
                char_count += len(sub_text) + 1
                
                if char_count >= actual_pos + len(segment_text):
                    end_time = sub['end']
                    break
            
            if start_time and end_time:
                new_subtitles.append({
                    'start': start_time,
                    'end': end_time,
                    'text': segment_text
                })
                current_pos = actual_pos + len(segment_text)
        
        return new_subtitles
    
    def save_srt(self, subtitles):
        """ä¿å­˜ä¸º SRT æ ¼å¼"""
        with open(self.output_file, 'w', encoding='utf-8') as f:
            for i, sub in enumerate(subtitles, 1):
                f.write(f"{i}\n")
                f.write(f"{self.format_timestamp(sub['start'])} --> {self.format_timestamp(sub['end'])}\n")
                f.write(f"{sub['text']}\n")
                f.write("\n")
    
    def format_timestamp(self, seconds):
        """è½¬æ¢ä¸º SRT æ—¶é—´æ ¼å¼"""
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = int(seconds % 60)
        milliseconds = int((seconds % 1) * 1000)
        return f"{hours:02d}:{minutes:02d}:{secs:02d},{milliseconds:03d}"

