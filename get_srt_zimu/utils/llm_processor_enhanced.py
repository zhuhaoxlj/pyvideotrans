"""
LLM æ™ºèƒ½å­—å¹•åˆ†å‰²å¤„ç†å™¨ - å¢å¼ºç‰ˆ
ä¿®å¤ï¼šæ—¶é—´æˆ³åŒ¹é…ç²¾åº¦é—®é¢˜
"""

import json
import re
import hashlib
import pickle
import time
from pathlib import Path
from PySide6.QtCore import QThread, Signal


class LLMProcessorEnhanced(QThread):
    """LLM å­—å¹•åˆ†å‰²å¤„ç†çº¿ç¨‹ - å¢å¼ºç‰ˆ"""
    progress = Signal(str)
    stream = Signal(str)
    finished_signal = Signal(str)
    error = Signal(str)

    # ... (ä¿æŒåŸæœ‰çš„ __init__ å’Œå…¶ä»–æ–¹æ³•ä¸å˜) ...

    def _match_text_to_words(self, text, words, start_idx, relax=False):
        """
        å¢å¼ºçš„æ–‡æœ¬åˆ°å•è¯æ—¶é—´æˆ³åŒ¹é…ç®—æ³• - ä¿®å¤ç‰ˆ

        ä¸»è¦æ”¹è¿›ï¼š
        1. æ·»åŠ æ—¶é—´æˆ³è¿ç»­æ€§æ£€æŸ¥
        2. ä¸¥æ ¼çš„è¾¹ç•ŒéªŒè¯
        3. æ™ºèƒ½ç»“æŸæ—¶é—´è®¡ç®—ï¼ˆé¿å…è·³è·ƒï¼‰
        """
        import re

        # æ¸…ç†å’Œåˆ†è¯
        text_clean = text.lower()
        for punct in [',', '.', '!', '?', ';', ':', '"', "'", '(', ')', '[', ']']:
            text_clean = text_clean.replace(punct, ' ')
        text_words = [w for w in text_clean.split() if w]

        if not text_words:
            return None

        # ä½¿ç”¨ä¸¥æ ¼çš„åºåˆ—å¯¹é½
        matched_indices = []
        text_idx = 0
        word_idx = start_idx
        max_lookahead = 10  # å‡å°å‰ç»èŒƒå›´ï¼Œé¿å…è·¨å¥åŒ¹é…

        # è®°å½•åŒ¹é…è¿‡ç¨‹ï¼ˆç”¨äºè°ƒè¯•ï¼‰
        match_log = []

        while text_idx < len(text_words) and word_idx < len(words):
            text_word = text_words[text_idx]
            best_match = None
            best_score = 0
            best_offset = 0

            # åœ¨å½“å‰ä½ç½®é™„è¿‘æŸ¥æ‰¾æœ€ä½³åŒ¹é…
            for offset in range(min(max_lookahead, len(words) - word_idx)):
                if word_idx + offset >= len(words):
                    break

                word_data = words[word_idx + offset]
                word_text = word_data['word'].lower().strip()

                # æ¸…ç†å•è¯
                for punct in [',', '.', '!', '?', ';', ':', '"', "'", '(', ')', '[', ']']:
                    word_text = word_text.replace(punct, '')
                word_text = word_text.strip()

                if not word_text:
                    continue

                # è®¡ç®—åŒ¹é…åˆ†æ•°
                score = self._calculate_match_score(text_word, word_text)

                # è€ƒè™‘ä½ç½®å› ç´ ï¼ˆè¶Šè¿‘è¶Šå¥½ï¼‰
                score = score - (offset * 0.15)  # å¢åŠ ä½ç½®æƒ©ç½š

                # â­ æ–°å¢ï¼šæ—¶é—´æˆ³è¿ç»­æ€§æ£€æŸ¥
                if matched_indices and offset > 0:
                    prev_match_idx = matched_indices[-1]
                    prev_end_time = words[prev_match_idx]['end']
                    current_start_time = word_data['start']
                    time_gap = current_start_time - prev_end_time

                    # å¦‚æœæ—¶é—´é—´éš”è¿‡å¤§ï¼ˆ>2ç§’ï¼‰ï¼Œé™ä½åˆ†æ•°
                    if time_gap > 2.0:
                        score -= 0.3
                        match_log.append(f"  âš ï¸  è¯ '{text_word}' å€™é€‰ '{word_text}' æ—¶é—´è·³è·ƒ {time_gap:.2f}sï¼Œé™ä½åˆ†æ•°")

                if score > best_score:
                    best_score = score
                    best_match = word_idx + offset
                    best_offset = offset

            # å¦‚æœæ‰¾åˆ°åŒ¹é…ï¼ˆé˜ˆå€¼ï¼š0.6ï¼Œæé«˜é˜ˆå€¼ï¼‰
            if best_score > 0.6:
                matched_indices.append(best_match)
                match_log.append(f"  âœ“ æ–‡æœ¬è¯ '{text_word}' åŒ¹é…åˆ° Whisper è¯ '{words[best_match]['word']}' (åˆ†æ•°: {best_score:.2f})")
                word_idx = best_match + 1
                text_idx += 1
            else:
                # æœªæ‰¾åˆ°åŒ¹é…ï¼Œå¯èƒ½æ˜¯ Whisper ç¼ºå¤±çš„è¯
                match_log.append(f"  âš ï¸  æ–‡æœ¬è¯ '{text_word}' æœªæ‰¾åˆ°åŒ¹é… (æœ€ä½³åˆ†æ•°: {best_score:.2f})")
                text_idx += 1

        if not matched_indices:
            self.progress.emit(f"   âŒ åŒ¹é…å¤±è´¥: æ–‡æœ¬ '{text[:50]}...' æ— ä»»ä½•åŒ¹é…è¯")
            return None

        # è·å–åŒ¹é…åˆ°çš„å•è¯
        matched_words = [words[i] for i in matched_indices]

        # â­ æ ¸å¿ƒæ”¹è¿›ï¼šæ™ºèƒ½è®¡ç®—ç»“æŸæ—¶é—´
        start_time = matched_words[0]['start']

        # æ–¹æ³•1ï¼šæ£€æŸ¥åŒ¹é…è¯ä¹‹é—´çš„æ—¶é—´è¿ç»­æ€§
        end_time = self._calculate_robust_end_time(matched_words, text_words)

        # æ–¹æ³•2ï¼šå¦‚æœåŒ¹é…ç‡ä½ï¼Œä½¿ç”¨ä¼°ç®—
        match_ratio = len(matched_indices) / len(text_words)
        if match_ratio < 0.6:
            self.progress.emit(f"   âš ï¸  åŒ¹é…ç‡ä½ ({match_ratio:.1%})ï¼Œä½¿ç”¨æ—¶é—´ä¼°ç®—")
            if len(matched_indices) >= 2:
                avg_word_duration = (matched_words[-1]['end'] - matched_words[0]['start']) / len(matched_indices)
                estimated_duration = avg_word_duration * len(text_words)
                end_time = min(end_time, start_time + estimated_duration)

        # â­ è¾¹ç•Œæ£€æŸ¥ï¼šç¡®ä¿ç»“æŸæ—¶é—´ä¸ä¼šè¿‡åº¦å»¶ä¼¸
        max_reasonable_duration = len(text_words) * 0.8  # å‡è®¾æœ€å¿« 1.25 è¯/ç§’
        if (end_time - start_time) > max_reasonable_duration:
            self.progress.emit(f"   âš ï¸  æŒç»­æ—¶é—´è¿‡é•¿ ({end_time - start_time:.2f}s)ï¼Œæˆªæ–­åˆ° {max_reasonable_duration:.2f}s")
            end_time = start_time + max_reasonable_duration

        # è¾“å‡ºè°ƒè¯•ä¿¡æ¯
        if len(match_log) > 0 and match_ratio < 0.8:
            self.progress.emit(f"   ğŸ” åŒ¹é…è¯¦æƒ…:")
            for log in match_log[:5]:  # åªæ˜¾ç¤ºå‰5æ¡
                self.progress.emit(log)

        return {
            'start': start_time,
            'end': end_time,
            'next_idx': word_idx,
            'match_ratio': match_ratio,
            'matched_count': len(matched_indices),
            'expected_count': len(text_words)
        }

    def _calculate_robust_end_time(self, matched_words, text_words):
        """
        è®¡ç®—ç¨³å¥çš„ç»“æŸæ—¶é—´

        ç­–ç•¥ï¼š
        1. æ£€æŸ¥åŒ¹é…è¯ä¹‹é—´çš„æ—¶é—´é—´éš”
        2. å¦‚æœå‘ç°å¤§è·³è·ƒï¼ˆ>1.5ç§’ï¼‰ï¼Œæˆªæ–­åœ¨è·³è·ƒä¹‹å‰
        3. å¦åˆ™ä½¿ç”¨æœ€åä¸€ä¸ªåŒ¹é…è¯çš„ç»“æŸæ—¶é—´
        """
        if len(matched_words) == 1:
            # åªæœ‰ä¸€ä¸ªåŒ¹é…è¯ï¼Œä½¿ç”¨å…¶ç»“æŸæ—¶é—´æˆ–ä¼°ç®—
            return matched_words[0]['end']

        # æ£€æŸ¥æ—¶é—´è¿ç»­æ€§
        for i in range(len(matched_words) - 1):
            current_end = matched_words[i]['end']
            next_start = matched_words[i + 1]['start']
            time_gap = next_start - current_end

            # å¦‚æœå‘ç°å¤§è·³è·ƒï¼ˆ>1.5ç§’ï¼‰ï¼Œæˆªæ–­
            if time_gap > 1.5:
                self.progress.emit(
                    f"   âš ï¸  æ£€æµ‹åˆ°æ—¶é—´è·³è·ƒ: "
                    f"'{matched_words[i]['word']}' ({current_end:.2f}s) -> "
                    f"'{matched_words[i+1]['word']}' ({next_start:.2f}s) "
                    f"é—´éš” {time_gap:.2f}sï¼Œæˆªæ–­ç»“æŸæ—¶é—´"
                )
                # æˆªæ–­åœ¨è·³è·ƒä¹‹å‰ï¼Œå¹¶æ·»åŠ å°ç¼“å†²
                return current_end + 0.2

        # æ²¡æœ‰å¤§è·³è·ƒï¼Œä½¿ç”¨æœ€åä¸€ä¸ªè¯çš„ç»“æŸæ—¶é—´
        # ä½†éœ€è¦éªŒè¯æ˜¯å¦åˆç†
        last_end = matched_words[-1]['end']
        first_start = matched_words[0]['start']
        total_duration = last_end - first_start

        # å¦‚æœæ€»æ—¶é•¿è¿‡é•¿ï¼ˆ> æ–‡æœ¬è¯æ•° * 1.0 ç§’ï¼‰ï¼Œå¯èƒ½æœ‰é—®é¢˜
        max_expected_duration = len(text_words) * 1.0
        if total_duration > max_expected_duration:
            # ä½¿ç”¨å€’æ•°ç¬¬äºŒä¸ªè¯çš„ç»“æŸæ—¶é—´ï¼Œæˆ–è€…ä¼°ç®—
            if len(matched_words) > 1:
                penultimate_end = matched_words[-2]['end']
                self.progress.emit(
                    f"   âš ï¸  æœ€åä¸€ä¸ªè¯æ—¶é—´å¼‚å¸¸ï¼Œä½¿ç”¨å€’æ•°ç¬¬äºŒä¸ªè¯: "
                    f"{last_end:.2f}s -> {penultimate_end:.2f}s"
                )
                return penultimate_end + 0.3

        return last_end

    def _calculate_match_score(self, text_word, whisper_word):
        """è®¡ç®—ä¸¤ä¸ªè¯çš„åŒ¹é…åˆ†æ•°ï¼ˆä¸¥æ ¼ç‰ˆæœ¬ï¼‰"""
        if not text_word or not whisper_word:
            return 0.0

        # å®Œå…¨åŒ¹é…
        if text_word == whisper_word:
            return 1.0

        # ä¸€ä¸ªåŒ…å«å¦ä¸€ä¸ª
        if text_word in whisper_word or whisper_word in text_word:
            shorter = min(len(text_word), len(whisper_word))
            longer = max(len(text_word), len(whisper_word))
            return shorter / longer * 0.95

        # ä½¿ç”¨ç¼–è¾‘è·ç¦»
        distance = self._levenshtein_distance(text_word, whisper_word)
        max_len = max(len(text_word), len(whisper_word))

        if max_len == 0:
            return 0.0

        similarity = 1.0 - (distance / max_len)

        # æé«˜é˜ˆå€¼åˆ° 0.7
        return similarity if similarity > 0.7 else 0.0

    def _levenshtein_distance(self, s1, s2):
        """è®¡ç®—ç¼–è¾‘è·ç¦»"""
        if len(s1) < len(s2):
            return self._levenshtein_distance(s2, s1)

        if len(s2) == 0:
            return len(s1)

        previous_row = range(len(s2) + 1)
        for i, c1 in enumerate(s1):
            current_row = [i + 1]
            for j, c2 in enumerate(s2):
                insertions = previous_row[j + 1] + 1
                deletions = current_row[j] + 1
                substitutions = previous_row[j] + (c1 != c2)
                current_row.append(min(insertions, deletions, substitutions))
            previous_row = current_row

        return previous_row[-1]

    def _validate_and_adjust_timestamps(self, subtitles):
        """éªŒè¯å’Œè°ƒæ•´æ—¶é—´æˆ³ - å¢å¼ºç‰ˆ"""
        if not subtitles:
            return []

        validated = []

        for i, sub in enumerate(subtitles):
            # ç¡®ä¿æ—¶é—´æˆ³åˆæ³•
            if sub['start'] >= sub['end']:
                sub['end'] = sub['start'] + 1.0

            # ç¡®ä¿ä¸ä¸å‰ä¸€æ¡é‡å 
            if i > 0 and sub['start'] < validated[-1]['end']:
                # æ·»åŠ å°é—´éš”ï¼ˆ100msï¼‰
                sub['start'] = validated[-1]['end'] + 0.1
                if sub['start'] >= sub['end']:
                    sub['end'] = sub['start'] + 1.0

            # æ£€æŸ¥æŒç»­æ—¶é—´æ˜¯å¦åˆç†
            duration = sub['end'] - sub['start']
            word_count = len(sub['text'].split())

            # â­ æ–°å¢ï¼šåŸºäºè¯æ•°çš„åŠ¨æ€é™åˆ¶
            # æ­£å¸¸è¯´è¯é€Ÿåº¦ï¼š2-4 è¯/ç§’
            min_expected_duration = word_count * 0.25  # æœ€å¿« 4 è¯/ç§’
            max_expected_duration = word_count * 1.0   # æœ€æ…¢ 1 è¯/ç§’

            if duration > max_expected_duration:
                self.progress.emit(
                    f"   âš ï¸  å­—å¹• {i+1} æ—¶é•¿è¿‡é•¿ ({duration:.2f}sï¼Œ{word_count}è¯)ï¼Œ"
                    f"è°ƒæ•´ä¸º {max_expected_duration:.2f}s"
                )
                sub['end'] = sub['start'] + max_expected_duration
            elif duration < min_expected_duration and word_count > 0:
                self.progress.emit(
                    f"   âš ï¸  å­—å¹• {i+1} æ—¶é•¿è¿‡çŸ­ ({duration:.2f}sï¼Œ{word_count}è¯)ï¼Œ"
                    f"è°ƒæ•´ä¸º {min_expected_duration:.2f}s"
                )
                sub['end'] = sub['start'] + min_expected_duration

            validated.append(sub)

        return validated
