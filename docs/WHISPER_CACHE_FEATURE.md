# Whisper 缓存功能说明

## 功能概述

为了提高处理效率，LLM 智能字幕生成工具现在支持 Whisper 处理结果的缓存功能。当再次处理相同的视频/字幕文件时，系统会自动从缓存读取词级时间戳数据，跳过耗时的 Whisper 语音识别过程。

## 工作原理

### 1. 文件识别

系统通过 **SHA-256 哈希值** 来识别文件：
- **仅视频文件模式**：使用视频文件的哈希值作为缓存键
- **视频+字幕模式**：使用视频文件和字幕文件的组合哈希值作为缓存键

### 2. 缓存内容

缓存文件包含以下信息：
```python
{
    'all_words': [
        {
            'word': '单词内容',
            'start': 开始时间(秒),
            'end': 结束时间(秒)
        },
        ...
    ],
    'language': '检测到的语言代码',
    'timestamp': 缓存创建时间戳
}
```

### 3. 缓存位置

缓存文件保存在：
```
{HOME_DIR}/whisper_cache/
```

每个缓存文件命名格式：
```
{哈希值}.pkl
```

## 使用场景

### 场景 1：重复处理同一视频

当你需要对同一个视频尝试不同的 LLM 模型或参数时，Whisper 识别过程只需要运行一次：

1. **第一次运行**：
   - 🔍 检查缓存... ❌ 未找到
   - 🎤 Whisper 处理（耗时：例如 2 分钟）
   - 💾 保存缓存
   - 🤖 LLM 断句优化

2. **第二次及后续运行**（相同视频）：
   - 🔍 检查缓存... ✅ 找到缓存！
   - 📊 直接加载缓存（耗时：<1 秒）
   - 🤖 LLM 断句优化

**时间节省**：每次可节省数分钟的 Whisper 处理时间

### 场景 2：使用现有字幕重新分割

当你有一个视频和字幕文件，想要用不同的断句策略重新分割时：

1. **第一次运行**：
   - 处理视频和字幕 A
   - Whisper 识别词级时间戳
   - 保存缓存

2. **修改字幕后再次运行**：
   - 如果字幕内容改变，哈希值不同，会重新处理
   - 如果字幕内容相同，直接使用缓存

## 工作流程示例

### 新字幕生成模式

```
用户操作：选择视频 → 启动生成
    ↓
系统检查：计算视频文件哈希值
    ↓
缓存检查：{哈希值}.pkl 是否存在？
    ├─ 是 → 加载缓存 → 跳过 Whisper → LLM 断句
    └─ 否 → Whisper 处理 → 保存缓存 → LLM 断句
```

### 字幕重新分割模式

```
用户操作：选择视频 + 字幕 → 启动生成
    ↓
系统检查：计算视频和字幕文件哈希值
    ↓
缓存检查：{视频哈希}_{字幕哈希}.pkl 是否存在？
    ├─ 是 → 加载缓存 → 跳过 Whisper → LLM 断句
    └─ 否 → Whisper 处理 → 保存缓存 → LLM 断句
```

## 性能提升

### 时间对比（以 3 分钟视频为例）

| 操作 | 无缓存 | 有缓存 | 节省时间 |
|------|--------|--------|----------|
| Whisper 处理 | ~120 秒 | <1 秒 | ~119 秒 |
| LLM 断句 | ~10 秒 | ~10 秒 | 0 秒 |
| **总计** | **~130 秒** | **~11 秒** | **~119 秒** |

**效率提升**：约 **91.5%**

## 缓存管理

### 自动管理

- 缓存文件会自动创建
- 每次成功的 Whisper 处理都会更新缓存
- 文件内容改变时，哈希值会改变，自动创建新缓存

### 手动管理

如果需要清理缓存：

1. 找到缓存目录：`{HOME_DIR}/whisper_cache/`
2. 删除不需要的 `.pkl` 文件
3. 或者删除整个目录以清空所有缓存

### 缓存大小估算

每个缓存文件的大小取决于词的数量：
- 短视频（1-3 分钟）：约 50-200 KB
- 中等视频（5-10 分钟）：约 300-600 KB
- 长视频（30 分钟+）：约 2-5 MB

## 注意事项

### 1. 文件内容变化

- 即使文件名相同，只要内容发生改变，哈希值就会不同
- 系统会自动识别并创建新缓存
- 不会混淆不同内容的相同文件名

### 2. 处理参数变化

以下参数变化 **不会** 影响缓存使用：
- ✅ LLM 提供商
- ✅ LLM 模型
- ✅ 最大持续时间
- ✅ 最大词数

以下参数变化 **会** 导致重新处理：
- ❌ Whisper 模型大小（因为可能影响识别精度）
- ❌ 语言设置（实际上不太影响，但为安全起见）
- ❌ 设备类型（CPU/GPU/MPS）

**建议**：如果发现缓存结果不理想，可以手动删除对应的缓存文件，强制重新处理。

### 3. 缓存有效性

缓存文件包含时间戳信息，未来可以根据需要实现：
- 缓存过期机制
- 缓存版本控制
- 缓存统计信息

## 实现细节

### 哈希算法

使用 SHA-256 算法计算文件哈希：
```python
def get_file_hash(filepath):
    hash_obj = hashlib.sha256()
    with open(filepath, 'rb') as f:
        for chunk in iter(lambda: f.read(8192), b''):
            hash_obj.update(chunk)
    return hash_obj.hexdigest()
```

### 缓存格式

使用 Python 的 `pickle` 模块序列化缓存数据：
```python
import pickle

# 保存
with open(cache_file, 'wb') as f:
    pickle.dump(cache_data, f)

# 读取
with open(cache_file, 'rb') as f:
    cache_data = pickle.load(f)
```

## 日志输出

### 命中缓存时

```
🔍 检查缓存...
✅ 找到缓存！直接使用缓存数据
📊 从缓存加载: 1234 个词
🌐 检测语言: en
🤖 使用 LLM 进行智能断句优化...
```

### 未命中缓存时

```
🔍 检查缓存...
❌ 未找到缓存，开始 Whisper 处理...
🔧 加载 Faster-Whisper 模型...
📥 模型: large-v3-turbo
⚙️  设备: CPU
🎤 开始识别语音...
⏳ 此过程可能需要几分钟，请耐心等待...
✅ 识别完成！检测语言: en (耗时: 123.4秒)
📊 收集词级时间戳...
✅ 收集完成！共 1234 个词
💾 缓存已保存: {哈希值}.pkl
🤖 使用 LLM 进行智能断句优化...
```

## 常见问题

### Q1: 缓存会占用多少磁盘空间？

A: 取决于处理的视频数量和长度。一般来说，100 个短视频（1-3 分钟）的缓存总大小约为 10-20 MB。

### Q2: 如何确认缓存正在工作？

A: 查看日志输出，如果看到 "✅ 找到缓存！直接使用缓存数据"，说明缓存正在工作。

### Q3: 缓存文件可以在不同电脑之间共享吗？

A: 理论上可以，但不推荐。因为：
- pickle 格式在不同 Python 版本之间可能不兼容
- 不同电脑上的文件路径可能不同

### Q4: 是否可以禁用缓存？

A: 当前版本中缓存是自动启用的。如果需要强制重新处理，可以手动删除对应的缓存文件。

## 未来改进

可能的功能增强：
- [ ] 添加缓存过期机制（例如 30 天自动清理）
- [ ] 提供 UI 界面管理缓存（查看、删除、导出）
- [ ] 缓存统计信息（命中率、节省时间）
- [ ] 支持缓存版本控制和迁移
- [ ] 压缩缓存文件以节省空间
- [ ] 支持缓存文件的导入/导出

## 总结

Whisper 缓存功能显著提升了重复处理同一视频的效率，特别适合以下场景：
- 🎯 调试和测试不同的 LLM 断句策略
- 🎯 尝试不同的 LLM 模型和参数
- 🎯 批量处理多个版本的字幕
- 🎯 开发和优化字幕处理流程

通过避免重复的 Whisper 处理，可以将处理时间缩短 **90% 以上**，大大提升工作效率！

