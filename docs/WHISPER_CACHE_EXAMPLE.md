# Whisper 缓存功能使用示例

## 示例 1: 基本使用 - 重复处理同一视频

### 场景
你有一个 5 分钟的英文演讲视频，想要尝试不同的 LLM 模型来生成最佳的字幕断句。

### 第一次处理

**操作步骤:**
1. 打开 LLM 智能字幕生成工具
2. 选择视频文件: `speech.mp4`
3. 设置参数:
   - 语言: `en=English`
   - Whisper模型: `large-v3-turbo`
   - 加速设备: `CPU`
   - LLM提供商: `SiliconFlow`
   - LLM模型: `deepseek-ai/DeepSeek-R1`
4. 点击"开始生成智能字幕"

**处理日志:**
```
🚀 开始处理...
🤖 模式: LLM智能生成新字幕
🔍 检查缓存...
❌ 未找到缓存，开始 Whisper 处理...
🔧 加载 Faster-Whisper 模型...
📥 模型: large-v3-turbo
⚙️  设备: CPU
🎤 开始识别语音...
⏳ 此过程可能需要几分钟，请耐心等待...
✅ 识别完成！检测语言: en (耗时: 186.3秒)
📊 收集词级时间戳...
   处理片段: 10...
   处理片段: 20...
   处理片段: 30...
✅ 收集完成！共 1234 个词
💾 缓存已保存: a3f5d9c...pkl
🤖 使用 LLM 进行智能断句优化...
   LLM提供商: siliconflow
   LLM模型: deepseek-ai/DeepSeek-R1
   处理文本: 1234 词
   ⏳ 正在调用 LLM API，请稍候...
   📡 LLM 响应流:
   [JSON output...]
   ✅ LLM响应完成 (耗时: 12.5秒)
   📋 解析 LLM 返回结果...
   ✅ 解析完成，生成 58 条字幕
   🔧 验证和调整时间戳...
   ✅ 时间戳调整完成
✅ 生成 58 条字幕
💾 保存完成

总耗时: 约 199 秒 (3分19秒)
```

### 第二次处理 (使用不同的 LLM 模型)

**操作步骤:**
1. 保持视频文件不变: `speech.mp4`
2. 只修改 LLM 模型: `Qwen/Qwen2.5-7B-Instruct`
3. 其他参数保持不变
4. 点击"开始生成智能字幕"

**处理日志:**
```
🚀 开始处理...
🤖 模式: LLM智能生成新字幕
🔍 检查缓存...
✅ 找到缓存！直接使用缓存数据
📊 从缓存加载: 1234 个词
🌐 检测语言: en
🤖 使用 LLM 进行智能断句优化...
   LLM提供商: siliconflow
   LLM模型: Qwen/Qwen2.5-7B-Instruct
   处理文本: 1234 词
   ⏳ 正在调用 LLM API，请稍候...
   📡 LLM 响应流:
   [JSON output...]
   ✅ LLM响应完成 (耗时: 8.3秒)
   📋 解析 LLM 返回结果...
   ✅ 解析完成，生成 62 条字幕
   🔧 验证和调整时间戳...
   ✅ 时间戳调整完成
✅ 生成 62 条字幕
💾 保存完成

总耗时: 约 9 秒
```

### 效果对比

| 项目 | 第一次 | 第二次 | 节省 |
|------|--------|--------|------|
| Whisper 处理 | 186.3秒 | 0.1秒 | 186.2秒 |
| LLM 断句 | 12.5秒 | 8.3秒 | - |
| **总耗时** | **199秒** | **9秒** | **190秒 (95.5%)** |

---

## 示例 2: 字幕重新分割

### 场景
你已经有一个视频和对应的字幕文件，但是字幕断句不够自然，想用 LLM 重新优化。

### 文件准备
- 视频: `presentation.mp4` (10分钟)
- 字幕: `presentation.srt` (原始字幕，断句较差)

### 第一次处理

**操作步骤:**
1. 打开 LLM 智能字幕生成工具
2. ✅ 勾选"使用现有字幕文件"
3. 选择视频: `presentation.mp4`
4. 选择字幕: `presentation.srt`
5. ✅ 勾选"启用 LLM 智能断句优化"
6. 设置 LLM 参数
7. 点击"开始生成智能字幕"

**处理日志:**
```
🚀 开始处理...
🤖 模式: LLM智能重新分割现有字幕
📖 读取现有字幕: presentation.srt
✅ 读取到 156 条原始字幕
📝 原始文本长度: 3456 字符
🔍 检查缓存...
❌ 未找到缓存，开始 Whisper 处理...
🔧 加载 Faster-Whisper 模型...
📥 模型: large-v3-turbo
⚙️  设备: CPU
🎤 开始识别语音（获取词级时间戳）...
✅ 识别完成！检测语言: en (耗时: 356.8秒)
📊 收集词级时间戳...
   处理片段: 10... (已收集 89 个词)
   处理片段: 20... (已收集 198 个词)
   ...
✅ 收集完成！共处理 67 个片段，2345 个词
💾 缓存已保存: b7e4f2a...pkl
🤖 使用 LLM 进行智能断句优化...
   ...
✅ 生成 98 条字幕
📊 原始字幕: 156 条 → 新字幕: 98 条
💾 保存完成

总耗时: 约 375 秒 (6分15秒)
```

### 第二次处理 (修改断句参数)

你觉得字幕还可以更好，想尝试其他 LLM 模型。

**操作步骤:**
1. 保持视频和字幕文件不变
2. 修改 LLM 模型
3. 点击"开始生成智能字幕"

**处理日志:**
```
🚀 开始处理...
🤖 模式: LLM智能重新分割现有字幕
📖 读取现有字幕: presentation.srt
✅ 读取到 156 条原始字幕
📝 原始文本长度: 3456 字符
🔍 检查缓存...
✅ 找到缓存！直接使用缓存数据
📊 从缓存加载: 2345 个词
🌐 检测语言: en
🤖 使用 LLM 进行智能断句优化...
   ...
✅ 生成 105 条字幕
📊 原始字幕: 156 条 → 新字幕: 105 条
💾 保存完成

总耗时: 约 13 秒
```

### 效果对比

| 项目 | 第一次 | 第二次 | 节省 |
|------|--------|--------|------|
| Whisper 处理 | 356.8秒 | 0.1秒 | 356.7秒 |
| LLM 断句 | 18.2秒 | 12.9秒 | - |
| **总耗时** | **375秒** | **13秒** | **362秒 (96.5%)** |

---

## 示例 3: 批量测试不同参数

### 场景
你想找到最佳的字幕生成参数，需要测试多种 LLM 模型组合。

### 测试矩阵

| 测试编号 | LLM 提供商 | LLM 模型 | 预期风格 |
|----------|-----------|----------|----------|
| 1 | SiliconFlow | DeepSeek-R1 | 精确 |
| 2 | SiliconFlow | Qwen2.5-7B | 平衡 |
| 3 | SiliconFlow | Llama-3.3-70B | 自然 |
| 4 | OpenAI | gpt-4o-mini | 智能 |

### 第一次测试（DeepSeek-R1）

```
视频: tutorial.mp4 (3分钟)
参数: SiliconFlow + DeepSeek-R1

处理时间:
- Whisper: 123秒
- LLM: 8秒
- 总计: 131秒

结果: 35条字幕
```

### 第二次测试（Qwen2.5-7B）

```
视频: tutorial.mp4 (相同)
参数: SiliconFlow + Qwen2.5-7B

处理时间:
- Whisper: <1秒 (缓存)
- LLM: 6秒
- 总计: 7秒

结果: 38条字幕
```

### 第三次测试（Llama-3.3-70B）

```
视频: tutorial.mp4 (相同)
参数: SiliconFlow + Llama-3.3-70B

处理时间:
- Whisper: <1秒 (缓存)
- LLM: 15秒
- 总计: 16秒

结果: 32条字幕
```

### 第四次测试（gpt-4o-mini）

```
视频: tutorial.mp4 (相同)
参数: OpenAI + gpt-4o-mini

处理时间:
- Whisper: <1秒 (缓存)
- LLM: 5秒
- 总计: 6秒

结果: 36条字幕
```

### 总时间对比

| 场景 | 无缓存 | 有缓存 | 节省 |
|------|--------|--------|------|
| 单次测试 | 131秒 | 131秒 | 0秒 |
| 4次测试 | 524秒 | 160秒 | 364秒 |
| 10次测试 | 1310秒 | 301秒 | 1009秒 |

**结论**: 测试次数越多，缓存的优势越明显！

---

## 示例 4: 开发调试场景

### 场景
你是开发者，正在优化 LLM 断句算法，需要频繁修改代码并测试结果。

### 开发流程

#### 迭代 1: 初始版本
```python
# 修改断句逻辑
def llm_smart_split(...):
    # 实现版本 1
    ...

# 测试
运行程序 → Whisper处理(120秒) → LLM断句 → 查看结果
```

#### 迭代 2-10: 优化版本
```python
# 修改断句逻辑
def llm_smart_split(...):
    # 实现版本 2-10
    ...

# 测试（每次都使用缓存）
运行程序 → 缓存读取(<1秒) → LLM断句 → 查看结果
```

### 时间节省

| 项目 | 无缓存 | 有缓存 |
|------|--------|--------|
| 单次迭代 | 130秒 | 10秒 |
| 10次迭代 | 1300秒 | 100秒 |
| **节省时间** | - | **20分钟** |

### 开发效率提升

- 🚀 快速验证想法
- 🚀 更多测试机会
- 🚀 更快的开发周期
- 🚀 更好的代码质量

---

## 示例 5: 缓存管理

### 查看缓存文件

**位置:**
```
{HOME_DIR}/whisper_cache/
```

**示例:**
```bash
$ cd ~/pyvideotrans_data/whisper_cache/
$ ls -lh

-rw-r--r--  1 user  staff   156K  Oct 27 10:23 a3f5d9c...pkl
-rw-r--r--  1 user  staff   298K  Oct 27 11:45 b7e4f2a...pkl
-rw-r--r--  1 user  staff   423K  Oct 27 14:12 c9d8e3b...pkl

总大小: 877K
```

### 清理缓存

**方式 1: 删除特定缓存**
```bash
# 删除特定视频的缓存
rm a3f5d9c...pkl
```

**方式 2: 清理所有缓存**
```bash
# 删除所有缓存文件
rm *.pkl
```

**方式 3: 清理旧缓存**
```bash
# 删除 7 天前的缓存
find . -name "*.pkl" -mtime +7 -delete
```

### 缓存统计

```bash
# 查看缓存文件数量
ls -1 *.pkl | wc -l

# 查看缓存总大小
du -sh .
```

---

## 实用技巧

### 技巧 1: 预处理视频库

如果你有一批视频需要处理，可以先运行一次生成缓存：

```
第一轮: 为所有视频生成缓存
video1.mp4 → 生成缓存
video2.mp4 → 生成缓存
video3.mp4 → 生成缓存

第二轮: 快速测试不同参数
video1.mp4 → 使用缓存 + LLM模型A
video1.mp4 → 使用缓存 + LLM模型B
video2.mp4 → 使用缓存 + LLM模型A
...
```

### 技巧 2: 版本对比

为同一视频生成多个版本：

```
tutorial.mp4 + DeepSeek-R1    → tutorial_llm_smart_v1.srt
tutorial.mp4 + Qwen2.5-7B     → tutorial_llm_smart_v2.srt
tutorial.mp4 + gpt-4o-mini    → tutorial_llm_smart_v3.srt

# 对比结果，选择最佳版本
```

### 技巧 3: A/B 测试

对比不同 Whisper 模型的效果：

```
第一组: large-v3-turbo + LLM
第二组: medium + LLM

# 注意：不同 Whisper 模型会生成不同的缓存
```

---

## 常见问题

### Q: 如何知道缓存是否被使用？

**A:** 查看日志输出，如果看到：
```
✅ 找到缓存！直接使用缓存数据
```
就说明缓存被成功使用了。

### Q: 为什么有时候缓存没有被使用？

**A:** 可能的原因：
1. 视频文件内容改变了
2. 使用了不同的字幕文件
3. 缓存文件被删除了
4. 第一次处理该文件

### Q: 缓存会占用多少空间？

**A:** 
- 短视频（1-3分钟）: 50-200 KB
- 中等视频（5-10分钟）: 300-600 KB
- 长视频（30分钟+）: 2-5 MB

### Q: 如何强制重新生成缓存？

**A:** 删除对应的缓存文件，程序会自动重新处理。

---

## 总结

Whisper 缓存功能通过智能识别文件内容，避免重复处理，大幅提升了：

- ✅ 开发效率
- ✅ 测试速度
- ✅ 用户体验
- ✅ 资源利用

特别适合需要反复调整参数、对比效果的场景！

🎉 **享受更快的字幕生成速度！**

